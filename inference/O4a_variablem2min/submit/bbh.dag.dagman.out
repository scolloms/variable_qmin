04/30/24 10:51:42 ******************************************************
04/30/24 10:51:42 ** condor_scheduniv_exec.140409954.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 10:51:42 ** /usr/bin/condor_dagman
04/30/24 10:51:42 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 10:51:42 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 10:51:42 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 10:51:42 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 10:51:42 ** PID = 1612083
04/30/24 10:51:42 ** Log last touched time unavailable (No such file or directory)
04/30/24 10:51:42 ******************************************************
04/30/24 10:51:42 Using config source: /etc/condor/condor_config
04/30/24 10:51:42 Using local config sources: 
04/30/24 10:51:42    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 10:51:42    /etc/condor/config.d/00-ldas
04/30/24 10:51:42    /etc/condor/config.d/02-scheduler
04/30/24 10:51:42    /etc/condor/config.d/10-security
04/30/24 10:51:42    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 10:51:42    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 10:51:42    /etc/condor/config.d/30-scratch-mount
04/30/24 10:51:42    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 10:51:42    /etc/condor/config.d/50-transfer-limits
04/30/24 10:51:42    /etc/condor/config.d/65-system-periodic-hold
04/30/24 10:51:42    /etc/condor/config.d/93-dagman-use-direct
04/30/24 10:51:42    /etc/condor/config.d/99-memory
04/30/24 10:51:42    /etc/condor/config.d/99-request-disk
04/30/24 10:51:42    /etc/condor/config.d/99-request-missing-units
04/30/24 10:51:42    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 10:51:42    /etc/condor/config.d/99-transform
04/30/24 10:51:42    /etc/condor/condor_config.local
04/30/24 10:51:42 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 10:51:42 CLASSAD_CACHING is ENABLED
04/30/24 10:51:42 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 10:51:42 DaemonCore: No command port requested.
04/30/24 10:51:42 DAGMAN_USE_STRICT setting: 1
04/30/24 10:51:42 DAGMAN_VERBOSITY setting: 3
04/30/24 10:51:42 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 10:51:42 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 10:51:42 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 10:51:42 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 10:51:42 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 10:51:42 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 10:51:42 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 10:51:42 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 10:51:42 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 10:51:42 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 10:51:42 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 10:51:42 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 10:51:42 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 10:51:42 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 10:51:42 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 10:51:42 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 10:51:42 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 10:51:42 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 10:51:42 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 10:51:42 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 10:51:42 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 10:51:42 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 10:51:42 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 10:51:42 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 10:51:42 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 10:51:42 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 10:51:42 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 10:51:42 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 10:51:42 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 10:51:42 DAGMAN_AUTO_RESCUE setting: True
04/30/24 10:51:42 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 10:51:42 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 10:51:42 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 10:51:42 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 10:51:42 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 10:51:42 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 10:51:42 ALL_DEBUG setting: 
04/30/24 10:51:42 DAGMAN_DEBUG setting: 
04/30/24 10:51:42 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 10:51:42 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 10:51:42 DAGMAN will adjust edges after parsing
04/30/24 10:51:42 Enabling log line cache for increased NFS performance.
04/30/24 10:51:42 argv[0] == "condor_scheduniv_exec.140409954.0"
04/30/24 10:51:42 argv[1] == "-Lockfile"
04/30/24 10:51:42 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 10:51:42 argv[3] == "-Dag"
04/30/24 10:51:42 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 10:51:42 argv[5] == "-CsdVersion"
04/30/24 10:51:42 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 10:51:42 argv[7] == "-dagman"
04/30/24 10:51:42 argv[8] == "/usr/bin/condor_dagman"
04/30/24 10:51:42 argv[9] == "-AutoRescue"
04/30/24 10:51:42 argv[10] == "1"
04/30/24 10:51:42 argv[11] == "-DoRescueFrom"
04/30/24 10:51:42 argv[12] == "0"
04/30/24 10:51:42 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 10:51:42 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 10:51:42 Workflow batch-id: <140409954.0>
04/30/24 10:51:42 Workflow batch-name: <bbh.dag+140409954>
04/30/24 10:51:42 Workflow accounting_group: <>
04/30/24 10:51:42 Workflow accounting_group_user: <>
04/30/24 10:51:42 Warning: failed to get attribute DAGNodeName
04/30/24 10:51:42 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 10:51:42 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 10:51:42 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 10:51:42 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 10:51:42 Parsing 1 dagfiles
04/30/24 10:51:42 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 10:51:42 Adjusting edges
04/30/24 10:51:42 Dag contains 5 total jobs
04/30/24 10:51:42 Bootstrapping...
04/30/24 10:51:42 Number of pre-completed nodes: 0
04/30/24 10:51:42 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 10:51:42 DAG status: 0 (DAG_STATUS_OK)
04/30/24 10:51:42 Of 5 nodes total:
04/30/24 10:51:42  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 10:51:42   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 10:51:42     0       0        0       0       1          4        0        0
04/30/24 10:51:42 0 job proc(s) currently held
04/30/24 10:51:42 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 10:51:42 Registering condor_event_timer...
04/30/24 10:51:43 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 job(s)...
04/30/24 10:51:43 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 10:51:43 Masking the events recorded in the DAGMAN workflow log
04/30/24 10:51:43 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 10:51:43 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 -a My.DAGManJobId=140409954 -a DAGManJobId=140409954 -batch-name bbh.dag+140409954 -batch-id 140409954.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 -a label=bbh DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection.sub
04/30/24 10:51:43 From submit: Submitting job(s).
04/30/24 10:51:43 From submit: 1 job(s) submitted to cluster 140409955.
04/30/24 10:51:43 	assigned HTCondor ID (140409955.0.0)
04/30/24 10:51:43 Just submitted 1 job this cycle...
04/30/24 10:51:43 DAG status: 0 (DAG_STATUS_OK)
04/30/24 10:51:43 Of 5 nodes total:
04/30/24 10:51:43  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 10:51:43   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 10:51:43     0       0        1       0       0          4        0        0
04/30/24 10:51:43 0 job proc(s) currently held
04/30/24 10:51:43 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03464603424072266; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03464603424072266; SubmitCycleTimeMin = 0.03464603424072266; SubmitCycleTimeStd = 0.03464603424072266; SubmitCycleTimeSum = 0.03464603424072266; ]
04/30/24 10:51:48 Currently monitoring 1 HTCondor log file(s)
04/30/24 10:51:48 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 from (140409955.0.0) to (140409955.0.0)
04/30/24 10:51:48 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 (140409955.0.0) {04/30/24 10:51:43}
04/30/24 10:51:48 Number of idle job procs: 1
04/30/24 10:52:48 Currently monitoring 1 HTCondor log file(s)
04/30/24 10:52:48 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 (140409955.0.0) {04/30/24 10:52:47}
04/30/24 10:52:48 Number of idle job procs: 0
04/30/24 11:02:49 601 seconds since last log event
04/30/24 11:02:49 Pending DAG nodes:
04/30/24 11:02:49   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0, HTCondor ID 140409955, status STATUS_SUBMITTED
04/30/24 11:08:44 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:08:44 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 (140409955.0.0) {04/30/24 11:08:41}
04/30/24 11:08:44 Number of idle job procs: 0
04/30/24 11:08:44 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 job proc (140409955.0.0) completed successfully.
04/30/24 11:08:44 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 job completed
04/30/24 11:08:44 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:08:44 Of 5 nodes total:
04/30/24 11:08:44  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:08:44   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:08:44     1       0        0       0       1          3        0        0
04/30/24 11:08:44 0 job proc(s) currently held
04/30/24 11:08:44 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0003532884167689903; EventCycleTimeCount = 204.0; EventCycleTimeMax = 0.03476619720458984; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.00246178964934358; EventCycleTimeSum = 0.07207083702087402; LogProcessCycleTimeAvg = 0.0002530415852864583; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 0.0001850128173828125; LogProcessCycleTimeStd = 0.0001100764232503718; LogProcessCycleTimeSum = 0.000759124755859375; SleepCycleTimeAvg = 5.004991726548064; SleepCycleTimeCount = 204.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004935962017858032; SleepCycleTimeSum = 1021.018312215805; SubmitCycleTimeAvg = 0.0002641201019287109; SubmitCycleTimeCount = 205.0; SubmitCycleTimeMax = 0.03464603424072266; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.002419866700842865; SubmitCycleTimeSum = 0.05414462089538574; ]
04/30/24 11:08:49 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 11:08:49 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 11:08:49 Masking the events recorded in the DAGMAN workflow log
04/30/24 11:08:49 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 11:08:49 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140409954 -a DAGManJobId=140409954 -batch-name bbh.dag+140409954 -batch-id 140409954.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_variable_m2min_redshift_powerlaw -a models=--models' 'mass:variable_m2min' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_m2min' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 11:08:49 From submit: Submitting job(s).
04/30/24 11:08:49 From submit: 1 job(s) submitted to cluster 140409956.
04/30/24 11:08:49 	assigned HTCondor ID (140409956.0.0)
04/30/24 11:08:49 Just submitted 1 job this cycle...
04/30/24 11:08:49 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:08:49 Of 5 nodes total:
04/30/24 11:08:49  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:08:49   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:08:49     1       0        1       0       0          3        0        0
04/30/24 11:08:49 0 job proc(s) currently held
04/30/24 11:08:49 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0003540236775468036; EventCycleTimeCount = 205.0; EventCycleTimeMax = 0.03476619720458984; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.002455771002888039; EventCycleTimeSum = 0.07257485389709473; LogProcessCycleTimeAvg = 0.0002530415852864583; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 0.0001850128173828125; LogProcessCycleTimeStd = 0.0001100764232503718; LogProcessCycleTimeSum = 0.000759124755859375; SleepCycleTimeAvg = 5.004989308845706; SleepCycleTimeCount = 205.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004936002304184239; SleepCycleTimeSum = 1026.02280831337; SubmitCycleTimeAvg = 0.0005146438635668709; SubmitCycleTimeCount = 206.0; SubmitCycleTimeMax = 0.05187201499938965; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.004330842198924213; SubmitCycleTimeSum = 0.1060166358947754; ]
04/30/24 11:08:54 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:08:54 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140409956.0.0) to (140409956.0.0)
04/30/24 11:08:54 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140409956.0.0) {04/30/24 11:08:49}
04/30/24 11:08:54 Number of idle job procs: 1
04/30/24 11:09:39 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:09:39 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140409956.0.0) {04/30/24 11:09:38}
04/30/24 11:09:39 Number of idle job procs: 1
04/30/24 11:09:39 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140409956.0.0) {04/30/24 11:09:38}
04/30/24 11:09:39   Hold reason: Transfer input files failure at access point ldas-pcdev2 while sending files to execution point slot1_7@node1827.cluster.ldas.cit. Details: Error from slot1_7@node1827.cluster.ldas.cit: SHADOW at 10.14.0.160 failed to send file(s) to <10.14.8.77:39275>: |Error: reading from file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/result/bbh_mass_variable_m2min_redshift_powerlaw_dynesty.pickle: (errno 2) No such file or directory; STARTER failed to receive file(s) from <10.14.0.160:9618>
04/30/24 11:09:39 Number of idle job procs: 1
04/30/24 11:09:39 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:09:39 Of 5 nodes total:
04/30/24 11:09:39  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:09:39   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:09:39     1       0        1       0       0          3        0        0
04/30/24 11:09:39 1 job proc(s) currently held
04/30/24 11:09:39 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.000582555282947629; EventCycleTimeCount = 215.0; EventCycleTimeMax = 0.05214691162109375; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.004270289277136016; EventCycleTimeSum = 0.1252493858337402; LogProcessCycleTimeAvg = 0.0002332210540771484; LogProcessCycleTimeCount = 5.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 0.0001590251922607422; LogProcessCycleTimeStd = 8.822460378655271E-05; LogProcessCycleTimeSum = 0.001166105270385742; SleepCycleTimeAvg = 5.00498727754105; SleepCycleTimeCount = 215.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004837355559510952; SleepCycleTimeSum = 1076.072264671326; SubmitCycleTimeAvg = 0.0004919756341863562; SubmitCycleTimeCount = 216.0; SubmitCycleTimeMax = 0.05187201499938965; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.004230182983037843; SubmitCycleTimeSum = 0.1062667369842529; ]
04/30/24 11:17:25 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:17:25 Event: ULOG_JOB_RELEASED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140409956.0.0) {04/30/24 11:17:20}
04/30/24 11:17:25 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:17:25 Of 5 nodes total:
04/30/24 11:17:25  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:17:25   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:17:25     1       0        1       0       0          3        0        0
04/30/24 11:17:25 0 job proc(s) currently held
04/30/24 11:17:25 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.000459931113503196; EventCycleTimeCount = 308.0; EventCycleTimeMax = 0.05214691162109375; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.003580856029412716; EventCycleTimeSum = 0.1416587829589844; LogProcessCycleTimeAvg = 0.0002088546752929688; LogProcessCycleTimeCount = 6.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 8.702278137207031E-05; LogProcessCycleTimeStd = 9.894032070374597E-05; LogProcessCycleTimeSum = 0.001253128051757812; SleepCycleTimeAvg = 5.004992605029763; SleepCycleTimeCount = 308.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004339738452713701; SleepCycleTimeSum = 1541.537722349167; SubmitCycleTimeAvg = 0.0003654432142436698; SubmitCycleTimeCount = 309.0; SubmitCycleTimeMax = 0.05187201499938965; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.003540752520106876; SubmitCycleTimeSum = 0.1129219532012939; ]
04/30/24 11:18:00 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:18:00 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140409956.0.0) {04/30/24 11:17:55}
04/30/24 11:18:00 Number of idle job procs: 0
04/30/24 11:18:15 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:18:15 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140409956.0.0) {04/30/24 11:18:11}
04/30/24 11:18:15 Number of idle job procs: 0
04/30/24 11:18:15 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140409956.0.0) failed with status 1.
04/30/24 11:18:15 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 11:18:15 Of 5 nodes total:
04/30/24 11:18:15  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:18:15   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:18:15     1       0        0       0       0          0        1        3
04/30/24 11:18:15 0 job proc(s) currently held
04/30/24 11:18:15 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0004498096382093129; EventCycleTimeCount = 318.0; EventCycleTimeMax = 0.05214691162109375; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.003524548083484528; EventCycleTimeSum = 0.1430394649505615; LogProcessCycleTimeAvg = 0.0002043843269348145; LogProcessCycleTimeCount = 8.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 8.702278137207031E-05; LogProcessCycleTimeStd = 8.769885496611749E-05; LogProcessCycleTimeSum = 0.001635074615478516; SleepCycleTimeAvg = 5.00496972506901; SleepCycleTimeCount = 318.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004972627105386852; SleepCycleTimeSum = 1591.580372571945; SubmitCycleTimeAvg = 0.0003575987202994128; SubmitCycleTimeCount = 319.0; SubmitCycleTimeMax = 0.05187201499938965; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.003485095928644492; SubmitCycleTimeSum = 0.1140739917755127; ]
04/30/24 11:18:15 ERROR: the following job(s) failed:
04/30/24 11:18:15 ---------------------- Job ----------------------
04/30/24 11:18:15       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 11:18:15            Noop: false
04/30/24 11:18:15          NodeID: 1
04/30/24 11:18:15     Node Status: STATUS_ERROR    
04/30/24 11:18:15 Node return val: 1
04/30/24 11:18:15           Error: Job proc (140409956.0.0) failed with status 1
04/30/24 11:18:15 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 11:18:15  HTCondor Job ID: (140409956.0.0)
04/30/24 11:18:15 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0
04/30/24 11:18:15 ---------------------------------------	<END>
04/30/24 11:18:15 Aborting DAG...
04/30/24 11:18:15 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue001...
04/30/24 11:18:15 Removing submitted jobs...
04/30/24 11:18:15 Removing any/all submitted HTCondor jobs...
04/30/24 11:18:15 Running: /usr/bin/condor_rm -const DAGManJobId==140409954 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 11:18:15 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 11:18:15 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 11:18:15 Note: 0 total job deferrals because of node category throttles
04/30/24 11:18:15 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 11:18:15 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 11:18:15 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 11:18:15 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 11:18:15 Of 5 nodes total:
04/30/24 11:18:15  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:18:15   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:18:15     1       0        0       0       0          0        1        3
04/30/24 11:18:15 0 job proc(s) currently held
04/30/24 11:18:15 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0004498096382093129; EventCycleTimeCount = 318.0; EventCycleTimeMax = 0.05214691162109375; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.003524548083484528; EventCycleTimeSum = 0.1430394649505615; LogProcessCycleTimeAvg = 0.0002043843269348145; LogProcessCycleTimeCount = 8.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 8.702278137207031E-05; LogProcessCycleTimeStd = 8.769885496611749E-05; LogProcessCycleTimeSum = 0.001635074615478516; SleepCycleTimeAvg = 5.00496972506901; SleepCycleTimeCount = 318.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004972627105386852; SleepCycleTimeSum = 1591.580372571945; SubmitCycleTimeAvg = 0.0003575987202994128; SubmitCycleTimeCount = 319.0; SubmitCycleTimeMax = 0.05187201499938965; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.003485095928644492; SubmitCycleTimeSum = 0.1140739917755127; ]
04/30/24 11:18:15 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 11:18:15 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0004498096382093129; EventCycleTimeCount = 318.0; EventCycleTimeMax = 0.05214691162109375; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.003524548083484528; EventCycleTimeSum = 0.1430394649505615; LogProcessCycleTimeAvg = 0.0002043843269348145; LogProcessCycleTimeCount = 8.0; LogProcessCycleTimeMax = 0.0003800392150878906; LogProcessCycleTimeMin = 8.702278137207031E-05; LogProcessCycleTimeStd = 8.769885496611749E-05; LogProcessCycleTimeSum = 0.001635074615478516; SleepCycleTimeAvg = 5.00496972506901; SleepCycleTimeCount = 318.0; SleepCycleTimeMax = 5.006155014038086; SleepCycleTimeMin = 5.001231908798218; SleepCycleTimeStd = 0.0004972627105386852; SleepCycleTimeSum = 1591.580372571945; SubmitCycleTimeAvg = 0.0003575987202994128; SubmitCycleTimeCount = 319.0; SubmitCycleTimeMax = 0.05187201499938965; SubmitCycleTimeMin = 1.382827758789062E-05; SubmitCycleTimeStd = 0.003485095928644492; SubmitCycleTimeSum = 0.1140739917755127; ]
04/30/24 11:18:15 **** condor_scheduniv_exec.140409954.0 (condor_DAGMAN) pid 1612083 EXITING WITH STATUS 1
04/30/24 11:44:30 ******************************************************
04/30/24 11:44:30 ** condor_scheduniv_exec.140411140.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 11:44:30 ** /usr/bin/condor_dagman
04/30/24 11:44:30 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 11:44:30 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 11:44:30 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 11:44:30 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 11:44:30 ** PID = 1747921
04/30/24 11:44:30 ** Log last touched 4/30 11:18:15
04/30/24 11:44:30 ******************************************************
04/30/24 11:44:30 Using config source: /etc/condor/condor_config
04/30/24 11:44:30 Using local config sources: 
04/30/24 11:44:30    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 11:44:30    /etc/condor/config.d/00-ldas
04/30/24 11:44:30    /etc/condor/config.d/02-scheduler
04/30/24 11:44:30    /etc/condor/config.d/10-security
04/30/24 11:44:30    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 11:44:30    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 11:44:30    /etc/condor/config.d/30-scratch-mount
04/30/24 11:44:30    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 11:44:30    /etc/condor/config.d/50-transfer-limits
04/30/24 11:44:30    /etc/condor/config.d/65-system-periodic-hold
04/30/24 11:44:30    /etc/condor/config.d/93-dagman-use-direct
04/30/24 11:44:30    /etc/condor/config.d/99-memory
04/30/24 11:44:30    /etc/condor/config.d/99-request-disk
04/30/24 11:44:30    /etc/condor/config.d/99-request-missing-units
04/30/24 11:44:30    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 11:44:30    /etc/condor/config.d/99-transform
04/30/24 11:44:30    /etc/condor/condor_config.local
04/30/24 11:44:30 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 11:44:30 CLASSAD_CACHING is ENABLED
04/30/24 11:44:30 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 11:44:30 DaemonCore: No command port requested.
04/30/24 11:44:30 DAGMAN_USE_STRICT setting: 1
04/30/24 11:44:30 DAGMAN_VERBOSITY setting: 3
04/30/24 11:44:30 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 11:44:30 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 11:44:30 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 11:44:30 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 11:44:30 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 11:44:30 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 11:44:30 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 11:44:30 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 11:44:30 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 11:44:30 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 11:44:30 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 11:44:30 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 11:44:30 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 11:44:30 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 11:44:30 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 11:44:30 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 11:44:30 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 11:44:30 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 11:44:30 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 11:44:30 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 11:44:30 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 11:44:30 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 11:44:30 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 11:44:30 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 11:44:30 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 11:44:30 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 11:44:30 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 11:44:30 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 11:44:30 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 11:44:30 DAGMAN_AUTO_RESCUE setting: True
04/30/24 11:44:30 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 11:44:30 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 11:44:30 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 11:44:30 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 11:44:30 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 11:44:30 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 11:44:30 ALL_DEBUG setting: 
04/30/24 11:44:30 DAGMAN_DEBUG setting: 
04/30/24 11:44:30 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 11:44:30 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 11:44:30 DAGMAN will adjust edges after parsing
04/30/24 11:44:30 Enabling log line cache for increased NFS performance.
04/30/24 11:44:30 argv[0] == "condor_scheduniv_exec.140411140.0"
04/30/24 11:44:30 argv[1] == "-Lockfile"
04/30/24 11:44:30 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 11:44:30 argv[3] == "-Dag"
04/30/24 11:44:30 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 11:44:30 argv[5] == "-CsdVersion"
04/30/24 11:44:30 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 11:44:30 argv[7] == "-dagman"
04/30/24 11:44:30 argv[8] == "/usr/bin/condor_dagman"
04/30/24 11:44:30 argv[9] == "-AutoRescue"
04/30/24 11:44:30 argv[10] == "1"
04/30/24 11:44:30 argv[11] == "-DoRescueFrom"
04/30/24 11:44:30 argv[12] == "0"
04/30/24 11:44:30 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 11:44:30 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 11:44:30 Workflow batch-id: <140411140.0>
04/30/24 11:44:30 Workflow batch-name: <bbh.dag+140411140>
04/30/24 11:44:30 Workflow accounting_group: <>
04/30/24 11:44:30 Workflow accounting_group_user: <>
04/30/24 11:44:30 Warning: failed to get attribute DAGNodeName
04/30/24 11:44:30 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 11:44:30 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 11:44:30 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 11:44:30 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 11:44:30 Parsing 1 dagfiles
04/30/24 11:44:30 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 11:44:30 Adjusting edges
04/30/24 11:44:30 Found rescue DAG number 1; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue001 in combination with normal DAG file
04/30/24 11:44:30 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 11:44:30 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue001
04/30/24 11:44:30 Dag contains 5 total jobs
04/30/24 11:44:30 Bootstrapping...
04/30/24 11:44:30 Number of pre-completed nodes: 1
04/30/24 11:44:30 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 11:44:30 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:44:30 Of 5 nodes total:
04/30/24 11:44:30  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:44:30   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:44:30     1       0        0       0       1          3        0        0
04/30/24 11:44:30 0 job proc(s) currently held
04/30/24 11:44:30 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 11:44:30 Registering condor_event_timer...
04/30/24 11:44:31 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 11:44:31 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 11:44:31 Masking the events recorded in the DAGMAN workflow log
04/30/24 11:44:31 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 11:44:31 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411140 -a DAGManJobId=140411140 -batch-name bbh.dag+140411140 -batch-id 140411140.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_variable_m2min_redshift_powerlaw -a models=--models' 'mass:variable_m2min' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_m2min' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 11:44:31 From submit: Submitting job(s).
04/30/24 11:44:31 From submit: 1 job(s) submitted to cluster 140411141.
04/30/24 11:44:31 	assigned HTCondor ID (140411141.0.0)
04/30/24 11:44:31 Just submitted 1 job this cycle...
04/30/24 11:44:31 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:44:31 Of 5 nodes total:
04/30/24 11:44:31  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:44:31   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:44:31     1       0        1       0       0          3        0        0
04/30/24 11:44:31 0 job proc(s) currently held
04/30/24 11:44:31 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03304600715637207; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03304600715637207; SubmitCycleTimeMin = 0.03304600715637207; SubmitCycleTimeStd = 0.03304600715637207; SubmitCycleTimeSum = 0.03304600715637207; ]
04/30/24 11:44:36 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:44:36 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411141.0.0) to (140411141.0.0)
04/30/24 11:44:36 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411141.0.0) {04/30/24 11:44:31}
04/30/24 11:44:36 Number of idle job procs: 1
04/30/24 11:45:16 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:45:16 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411141.0.0) {04/30/24 11:45:15}
04/30/24 11:45:16 Number of idle job procs: 0
04/30/24 11:45:31 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:45:31 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411141.0.0) {04/30/24 11:45:28}
04/30/24 11:45:31 Number of idle job procs: 0
04/30/24 11:45:31 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140411141.0.0) failed with status 1.
04/30/24 11:45:31 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 11:45:31 Of 5 nodes total:
04/30/24 11:45:31  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:45:31   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:45:31     1       0        0       0       0          0        1        3
04/30/24 11:45:31 0 job proc(s) currently held
04/30/24 11:45:31 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002846300601959229; EventCycleTimeCount = 12.0; EventCycleTimeMax = 0.03316807746887207; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.009549276994518813; EventCycleTimeSum = 0.03415560722351074; LogProcessCycleTimeAvg = 0.0002137025197347005; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002779960632324219; LogProcessCycleTimeMin = 0.0001811981201171875; LogProcessCycleTimeStd = 5.568099046633845E-05; LogProcessCycleTimeSum = 0.0006411075592041016; SleepCycleTimeAvg = 5.004843195279439; SleepCycleTimeCount = 12.0; SleepCycleTimeMax = 5.005457878112793; SleepCycleTimeMin = 5.003700971603394; SleepCycleTimeStd = 0.0004806016124919418; SleepCycleTimeSum = 60.05811834335327; SubmitCycleTimeAvg = 0.002579615666316106; SubmitCycleTimeCount = 13.0; SubmitCycleTimeMax = 0.03304600715637207; SubmitCycleTimeMin = 1.788139343261719E-05; SubmitCycleTimeStd = 0.00915422322381957; SubmitCycleTimeSum = 0.03353500366210938; ]
04/30/24 11:45:31 ERROR: the following job(s) failed:
04/30/24 11:45:31 ---------------------- Job ----------------------
04/30/24 11:45:31       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 11:45:31            Noop: false
04/30/24 11:45:31          NodeID: 1
04/30/24 11:45:31     Node Status: STATUS_ERROR    
04/30/24 11:45:31 Node return val: 1
04/30/24 11:45:31           Error: Job proc (140411141.0.0) failed with status 1
04/30/24 11:45:31 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 11:45:31  HTCondor Job ID: (140411141.0.0)
04/30/24 11:45:31 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0
04/30/24 11:45:31 ---------------------------------------	<END>
04/30/24 11:45:31 Aborting DAG...
04/30/24 11:45:31 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue002...
04/30/24 11:45:31 Removing submitted jobs...
04/30/24 11:45:31 Removing any/all submitted HTCondor jobs...
04/30/24 11:45:31 Running: /usr/bin/condor_rm -const DAGManJobId==140411140 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 11:45:32 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 11:45:32 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 11:45:32 Note: 0 total job deferrals because of node category throttles
04/30/24 11:45:32 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 11:45:32 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 11:45:32 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 11:45:32 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 11:45:32 Of 5 nodes total:
04/30/24 11:45:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:45:32   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:45:32     1       0        0       0       0          0        1        3
04/30/24 11:45:32 0 job proc(s) currently held
04/30/24 11:45:32 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002846300601959229; EventCycleTimeCount = 12.0; EventCycleTimeMax = 0.03316807746887207; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.009549276994518813; EventCycleTimeSum = 0.03415560722351074; LogProcessCycleTimeAvg = 0.0002137025197347005; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002779960632324219; LogProcessCycleTimeMin = 0.0001811981201171875; LogProcessCycleTimeStd = 5.568099046633845E-05; LogProcessCycleTimeSum = 0.0006411075592041016; SleepCycleTimeAvg = 5.004843195279439; SleepCycleTimeCount = 12.0; SleepCycleTimeMax = 5.005457878112793; SleepCycleTimeMin = 5.003700971603394; SleepCycleTimeStd = 0.0004806016124919418; SleepCycleTimeSum = 60.05811834335327; SubmitCycleTimeAvg = 0.002579615666316106; SubmitCycleTimeCount = 13.0; SubmitCycleTimeMax = 0.03304600715637207; SubmitCycleTimeMin = 1.788139343261719E-05; SubmitCycleTimeStd = 0.00915422322381957; SubmitCycleTimeSum = 0.03353500366210938; ]
04/30/24 11:45:32 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 11:45:32 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002846300601959229; EventCycleTimeCount = 12.0; EventCycleTimeMax = 0.03316807746887207; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.009549276994518813; EventCycleTimeSum = 0.03415560722351074; LogProcessCycleTimeAvg = 0.0002137025197347005; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002779960632324219; LogProcessCycleTimeMin = 0.0001811981201171875; LogProcessCycleTimeStd = 5.568099046633845E-05; LogProcessCycleTimeSum = 0.0006411075592041016; SleepCycleTimeAvg = 5.004843195279439; SleepCycleTimeCount = 12.0; SleepCycleTimeMax = 5.005457878112793; SleepCycleTimeMin = 5.003700971603394; SleepCycleTimeStd = 0.0004806016124919418; SleepCycleTimeSum = 60.05811834335327; SubmitCycleTimeAvg = 0.002579615666316106; SubmitCycleTimeCount = 13.0; SubmitCycleTimeMax = 0.03304600715637207; SubmitCycleTimeMin = 1.788139343261719E-05; SubmitCycleTimeStd = 0.00915422322381957; SubmitCycleTimeSum = 0.03353500366210938; ]
04/30/24 11:45:32 **** condor_scheduniv_exec.140411140.0 (condor_DAGMAN) pid 1747921 EXITING WITH STATUS 1
04/30/24 11:49:27 ******************************************************
04/30/24 11:49:27 ** condor_scheduniv_exec.140411142.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 11:49:27 ** /usr/bin/condor_dagman
04/30/24 11:49:27 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 11:49:27 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 11:49:27 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 11:49:27 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 11:49:27 ** PID = 1757553
04/30/24 11:49:27 ** Log last touched 4/30 11:45:32
04/30/24 11:49:27 ******************************************************
04/30/24 11:49:27 Using config source: /etc/condor/condor_config
04/30/24 11:49:27 Using local config sources: 
04/30/24 11:49:27    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 11:49:27    /etc/condor/config.d/00-ldas
04/30/24 11:49:27    /etc/condor/config.d/02-scheduler
04/30/24 11:49:27    /etc/condor/config.d/10-security
04/30/24 11:49:27    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 11:49:27    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 11:49:27    /etc/condor/config.d/30-scratch-mount
04/30/24 11:49:27    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 11:49:27    /etc/condor/config.d/50-transfer-limits
04/30/24 11:49:27    /etc/condor/config.d/65-system-periodic-hold
04/30/24 11:49:27    /etc/condor/config.d/93-dagman-use-direct
04/30/24 11:49:27    /etc/condor/config.d/99-memory
04/30/24 11:49:27    /etc/condor/config.d/99-request-disk
04/30/24 11:49:27    /etc/condor/config.d/99-request-missing-units
04/30/24 11:49:27    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 11:49:27    /etc/condor/config.d/99-transform
04/30/24 11:49:27    /etc/condor/condor_config.local
04/30/24 11:49:27 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 11:49:27 CLASSAD_CACHING is ENABLED
04/30/24 11:49:27 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 11:49:27 DaemonCore: No command port requested.
04/30/24 11:49:27 DAGMAN_USE_STRICT setting: 1
04/30/24 11:49:27 DAGMAN_VERBOSITY setting: 3
04/30/24 11:49:27 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 11:49:27 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 11:49:27 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 11:49:27 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 11:49:27 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 11:49:27 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 11:49:27 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 11:49:27 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 11:49:27 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 11:49:27 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 11:49:27 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 11:49:27 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 11:49:27 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 11:49:27 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 11:49:27 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 11:49:27 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 11:49:27 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 11:49:27 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 11:49:27 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 11:49:27 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 11:49:27 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 11:49:27 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 11:49:27 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 11:49:27 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 11:49:27 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 11:49:27 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 11:49:27 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 11:49:27 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 11:49:27 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 11:49:27 DAGMAN_AUTO_RESCUE setting: True
04/30/24 11:49:27 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 11:49:27 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 11:49:27 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 11:49:27 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 11:49:27 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 11:49:27 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 11:49:27 ALL_DEBUG setting: 
04/30/24 11:49:27 DAGMAN_DEBUG setting: 
04/30/24 11:49:27 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 11:49:27 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 11:49:27 DAGMAN will adjust edges after parsing
04/30/24 11:49:27 Enabling log line cache for increased NFS performance.
04/30/24 11:49:27 argv[0] == "condor_scheduniv_exec.140411142.0"
04/30/24 11:49:27 argv[1] == "-Lockfile"
04/30/24 11:49:27 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 11:49:27 argv[3] == "-Dag"
04/30/24 11:49:27 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 11:49:27 argv[5] == "-CsdVersion"
04/30/24 11:49:27 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 11:49:27 argv[7] == "-dagman"
04/30/24 11:49:27 argv[8] == "/usr/bin/condor_dagman"
04/30/24 11:49:27 argv[9] == "-AutoRescue"
04/30/24 11:49:27 argv[10] == "1"
04/30/24 11:49:27 argv[11] == "-DoRescueFrom"
04/30/24 11:49:27 argv[12] == "0"
04/30/24 11:49:27 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 11:49:27 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 11:49:27 Workflow batch-id: <140411142.0>
04/30/24 11:49:27 Workflow batch-name: <bbh.dag+140411142>
04/30/24 11:49:27 Workflow accounting_group: <>
04/30/24 11:49:27 Workflow accounting_group_user: <>
04/30/24 11:49:27 Warning: failed to get attribute DAGNodeName
04/30/24 11:49:27 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 11:49:27 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 11:49:27 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 11:49:27 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 11:49:27 Parsing 1 dagfiles
04/30/24 11:49:27 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 11:49:27 Adjusting edges
04/30/24 11:49:27 Found rescue DAG number 2; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue002 in combination with normal DAG file
04/30/24 11:49:27 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 11:49:27 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue002
04/30/24 11:49:27 Dag contains 5 total jobs
04/30/24 11:49:27 Bootstrapping...
04/30/24 11:49:27 Number of pre-completed nodes: 1
04/30/24 11:49:27 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 11:49:27 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:49:27 Of 5 nodes total:
04/30/24 11:49:27  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:49:27   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:49:27     1       0        0       0       1          3        0        0
04/30/24 11:49:27 0 job proc(s) currently held
04/30/24 11:49:27 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 11:49:27 Registering condor_event_timer...
04/30/24 11:49:28 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 11:49:28 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 11:49:28 Masking the events recorded in the DAGMAN workflow log
04/30/24 11:49:28 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 11:49:28 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411142 -a DAGManJobId=140411142 -batch-name bbh.dag+140411142 -batch-id 140411142.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 11:49:28 From submit: Submitting job(s).
04/30/24 11:49:28 From submit: 1 job(s) submitted to cluster 140411143.
04/30/24 11:49:28 	assigned HTCondor ID (140411143.0.0)
04/30/24 11:49:28 Just submitted 1 job this cycle...
04/30/24 11:49:28 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:49:28 Of 5 nodes total:
04/30/24 11:49:28  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:49:28   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:49:28     1       0        1       0       0          3        0        0
04/30/24 11:49:28 0 job proc(s) currently held
04/30/24 11:49:28 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03519296646118164; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03519296646118164; SubmitCycleTimeMin = 0.03519296646118164; SubmitCycleTimeStd = 0.03519296646118164; SubmitCycleTimeSum = 0.03519296646118164; ]
04/30/24 11:49:33 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:49:33 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411143.0.0) to (140411143.0.0)
04/30/24 11:49:33 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411143.0.0) {04/30/24 11:49:28}
04/30/24 11:49:33 Number of idle job procs: 1
04/30/24 11:51:09 Currently monitoring 1 HTCondor log file(s)
04/30/24 11:51:09 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411143.0.0) {04/30/24 11:51:08}
04/30/24 11:51:09 Number of idle job procs: 1
04/30/24 11:51:09 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411143.0.0) {04/30/24 11:51:08}
04/30/24 11:51:09   Hold reason: Transfer input files failure at access point ldas-pcdev2 while sending files to execution point slot1_22@node831.cluster.ldas.cit. Details: Error from slot1_22@node831.cluster.ldas.cit: SHADOW at 10.14.0.160 failed to send file(s) to <10.14.4.81:43565>: |Error: reading from file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/result/bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw_dynesty.pickle: (errno 2) No such file or directory; STARTER failed to receive file(s) from <10.14.0.160:9618>
04/30/24 11:51:09 Number of idle job procs: 1
04/30/24 11:51:09 DAG status: 0 (DAG_STATUS_OK)
04/30/24 11:51:09 Of 5 nodes total:
04/30/24 11:51:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 11:51:09   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 11:51:09     1       0        1       0       0          3        0        0
04/30/24 11:51:09 1 job proc(s) currently held
04/30/24 11:51:09 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001834642887115479; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.03531289100646973; EventCycleTimeMin = 3.004074096679688E-05; EventCycleTimeStd = 0.007880258582008777; EventCycleTimeSum = 0.03669285774230957; LogProcessCycleTimeAvg = 0.0001416206359863281; LogProcessCycleTimeCount = 2.0; LogProcessCycleTimeMax = 0.0001671314239501953; LogProcessCycleTimeMin = 0.0001161098480224609; LogProcessCycleTimeStd = 3.607770232532529E-05; LogProcessCycleTimeSum = 0.0002832412719726562; SleepCycleTimeAvg = 5.004904651641846; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006371974945068; SleepCycleTimeMin = 5.00249981880188; SleepCycleTimeStd = 0.0006655107580399676; SleepCycleTimeSum = 100.0980930328369; SubmitCycleTimeAvg = 0.001716273171561105; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.03519296646118164; SubmitCycleTimeMin = 1.001358032226562E-05; SubmitCycleTimeStd = 0.007670708039807664; SubmitCycleTimeSum = 0.0360417366027832; ]
04/30/24 12:01:09 600 seconds since last log event
04/30/24 12:01:09 Pending DAG nodes:
04/30/24 12:01:09   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0, HTCondor ID 140411143, status STATUS_SUBMITTED
04/30/24 12:11:10 1201 seconds since last log event
04/30/24 12:11:10 Pending DAG nodes:
04/30/24 12:11:10   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0, HTCondor ID 140411143, status STATUS_SUBMITTED
04/30/24 12:13:37 Received SIGUSR1
04/30/24 12:13:37 Aborting DAG...
04/30/24 12:13:37 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue003...
04/30/24 12:13:37 Removing submitted jobs...
04/30/24 12:13:37 Removing any/all submitted HTCondor jobs...
04/30/24 12:13:37 Running: /usr/bin/condor_rm -const DAGManJobId==140411142 -reason DAG' 'Removed:' 'User' 'removed' 'scheduler' 'job' 'from' 'queue.
04/30/24 12:13:37 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 12:13:37 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 12:13:37 Note: 0 total job deferrals because of node category throttles
04/30/24 12:13:37 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 12:13:37 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 12:13:37 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 12:13:37 DAG status: 4 (DAG_STATUS_RM)
04/30/24 12:13:37 Of 5 nodes total:
04/30/24 12:13:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:13:37   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:13:37     1       0        1       0       0          3        0        0
04/30/24 12:13:37 1 job proc(s) currently held
04/30/24 12:13:37 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.000308701909821609; EventCycleTimeCount = 290.0; EventCycleTimeMax = 0.03531289100646973; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.002183458049147218; EventCycleTimeSum = 0.0895235538482666; LogProcessCycleTimeAvg = 0.0001416206359863281; LogProcessCycleTimeCount = 2.0; LogProcessCycleTimeMax = 0.0001671314239501953; LogProcessCycleTimeMin = 0.0001161098480224609; LogProcessCycleTimeStd = 3.607770232532529E-05; LogProcessCycleTimeSum = 0.0002832412719726562; SleepCycleTimeAvg = 5.004904710710255; SleepCycleTimeCount = 289.0; SleepCycleTimeMax = 5.012960910797119; SleepCycleTimeMin = 5.000524997711182; SleepCycleTimeStd = 0.0008440895859543317; SleepCycleTimeSum = 1446.417461395264; SubmitCycleTimeAvg = 0.0002260980934932314; SubmitCycleTimeCount = 290.0; SubmitCycleTimeMax = 0.03519296646118164; SubmitCycleTimeMin = 1.001358032226562E-05; SubmitCycleTimeStd = 0.002116540495164679; SubmitCycleTimeSum = 0.06556844711303711; ]
04/30/24 12:13:37 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 12:13:37 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.000308701909821609; EventCycleTimeCount = 290.0; EventCycleTimeMax = 0.03531289100646973; EventCycleTimeMin = 2.288818359375E-05; EventCycleTimeStd = 0.002183458049147218; EventCycleTimeSum = 0.0895235538482666; LogProcessCycleTimeAvg = 0.0001416206359863281; LogProcessCycleTimeCount = 2.0; LogProcessCycleTimeMax = 0.0001671314239501953; LogProcessCycleTimeMin = 0.0001161098480224609; LogProcessCycleTimeStd = 3.607770232532529E-05; LogProcessCycleTimeSum = 0.0002832412719726562; SleepCycleTimeAvg = 5.004904710710255; SleepCycleTimeCount = 289.0; SleepCycleTimeMax = 5.012960910797119; SleepCycleTimeMin = 5.000524997711182; SleepCycleTimeStd = 0.0008440895859543317; SleepCycleTimeSum = 1446.417461395264; SubmitCycleTimeAvg = 0.0002260980934932314; SubmitCycleTimeCount = 290.0; SubmitCycleTimeMax = 0.03519296646118164; SubmitCycleTimeMin = 1.001358032226562E-05; SubmitCycleTimeStd = 0.002116540495164679; SubmitCycleTimeSum = 0.06556844711303711; ]
04/30/24 12:13:37 **** condor_scheduniv_exec.140411142.0 (condor_DAGMAN) pid 1757553 EXITING WITH STATUS 2
04/30/24 12:13:56 ******************************************************
04/30/24 12:13:56 ** condor_scheduniv_exec.140411160.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 12:13:56 ** /usr/bin/condor_dagman
04/30/24 12:13:56 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 12:13:56 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 12:13:56 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 12:13:56 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 12:13:56 ** PID = 1804046
04/30/24 12:13:56 ** Log last touched 4/30 12:13:37
04/30/24 12:13:56 ******************************************************
04/30/24 12:13:56 Using config source: /etc/condor/condor_config
04/30/24 12:13:56 Using local config sources: 
04/30/24 12:13:56    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 12:13:56    /etc/condor/config.d/00-ldas
04/30/24 12:13:56    /etc/condor/config.d/02-scheduler
04/30/24 12:13:56    /etc/condor/config.d/10-security
04/30/24 12:13:56    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 12:13:56    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 12:13:56    /etc/condor/config.d/30-scratch-mount
04/30/24 12:13:56    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 12:13:56    /etc/condor/config.d/50-transfer-limits
04/30/24 12:13:56    /etc/condor/config.d/65-system-periodic-hold
04/30/24 12:13:56    /etc/condor/config.d/93-dagman-use-direct
04/30/24 12:13:56    /etc/condor/config.d/99-memory
04/30/24 12:13:56    /etc/condor/config.d/99-request-disk
04/30/24 12:13:56    /etc/condor/config.d/99-request-missing-units
04/30/24 12:13:56    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 12:13:56    /etc/condor/config.d/99-transform
04/30/24 12:13:56    /etc/condor/condor_config.local
04/30/24 12:13:56 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 12:13:56 CLASSAD_CACHING is ENABLED
04/30/24 12:13:56 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 12:13:56 DaemonCore: No command port requested.
04/30/24 12:13:56 DAGMAN_USE_STRICT setting: 1
04/30/24 12:13:56 DAGMAN_VERBOSITY setting: 3
04/30/24 12:13:56 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 12:13:56 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 12:13:56 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 12:13:56 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 12:13:56 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 12:13:56 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 12:13:56 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 12:13:56 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 12:13:56 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 12:13:56 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 12:13:56 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 12:13:56 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 12:13:56 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 12:13:56 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 12:13:56 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 12:13:56 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 12:13:56 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 12:13:56 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 12:13:56 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 12:13:56 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 12:13:56 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 12:13:56 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 12:13:56 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 12:13:56 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 12:13:56 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 12:13:56 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 12:13:56 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 12:13:56 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 12:13:56 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 12:13:56 DAGMAN_AUTO_RESCUE setting: True
04/30/24 12:13:56 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 12:13:56 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 12:13:56 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 12:13:56 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 12:13:56 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 12:13:56 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 12:13:56 ALL_DEBUG setting: 
04/30/24 12:13:56 DAGMAN_DEBUG setting: 
04/30/24 12:13:56 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 12:13:56 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 12:13:56 DAGMAN will adjust edges after parsing
04/30/24 12:13:56 Enabling log line cache for increased NFS performance.
04/30/24 12:13:56 argv[0] == "condor_scheduniv_exec.140411160.0"
04/30/24 12:13:56 argv[1] == "-Lockfile"
04/30/24 12:13:56 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 12:13:56 argv[3] == "-Dag"
04/30/24 12:13:56 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 12:13:56 argv[5] == "-CsdVersion"
04/30/24 12:13:56 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 12:13:56 argv[7] == "-dagman"
04/30/24 12:13:56 argv[8] == "/usr/bin/condor_dagman"
04/30/24 12:13:56 argv[9] == "-AutoRescue"
04/30/24 12:13:56 argv[10] == "1"
04/30/24 12:13:56 argv[11] == "-DoRescueFrom"
04/30/24 12:13:56 argv[12] == "0"
04/30/24 12:13:56 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:13:56 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:13:56 Workflow batch-id: <140411160.0>
04/30/24 12:13:56 Workflow batch-name: <bbh.dag+140411160>
04/30/24 12:13:56 Workflow accounting_group: <>
04/30/24 12:13:56 Workflow accounting_group_user: <>
04/30/24 12:13:56 Warning: failed to get attribute DAGNodeName
04/30/24 12:13:56 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 12:13:56 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 12:13:56 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 12:13:56 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 12:13:56 Parsing 1 dagfiles
04/30/24 12:13:56 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 12:13:56 Adjusting edges
04/30/24 12:13:56 Found rescue DAG number 3; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue003 in combination with normal DAG file
04/30/24 12:13:56 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 12:13:56 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue003
04/30/24 12:13:56 Dag contains 5 total jobs
04/30/24 12:13:56 Bootstrapping...
04/30/24 12:13:56 Number of pre-completed nodes: 1
04/30/24 12:13:56 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:13:56 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:13:56 Of 5 nodes total:
04/30/24 12:13:56  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:13:56   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:13:56     1       0        0       0       1          3        0        0
04/30/24 12:13:56 0 job proc(s) currently held
04/30/24 12:13:56 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 12:13:56 Registering condor_event_timer...
04/30/24 12:13:57 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 12:13:57 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:13:57 Masking the events recorded in the DAGMAN workflow log
04/30/24 12:13:57 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 12:13:57 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411160 -a DAGManJobId=140411160 -batch-name bbh.dag+140411160 -batch-id 140411160.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:13:57 From submit: Submitting job(s).
04/30/24 12:13:57 From submit: 1 job(s) submitted to cluster 140411161.
04/30/24 12:13:57 	assigned HTCondor ID (140411161.0.0)
04/30/24 12:13:57 Just submitted 1 job this cycle...
04/30/24 12:13:57 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:13:57 Of 5 nodes total:
04/30/24 12:13:57  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:13:57   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:13:57     1       0        1       0       0          3        0        0
04/30/24 12:13:57 0 job proc(s) currently held
04/30/24 12:13:57 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03524518013000488; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03524518013000488; SubmitCycleTimeMin = 0.03524518013000488; SubmitCycleTimeStd = 0.03524518013000488; SubmitCycleTimeSum = 0.03524518013000488; ]
04/30/24 12:14:02 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:14:02 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411161.0.0) to (140411161.0.0)
04/30/24 12:14:02 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411161.0.0) {04/30/24 12:13:57}
04/30/24 12:14:02 Number of idle job procs: 1
04/30/24 12:15:47 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:15:47 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411161.0.0) {04/30/24 12:15:44}
04/30/24 12:15:47 Number of idle job procs: 1
04/30/24 12:15:47 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411161.0.0) {04/30/24 12:15:44}
04/30/24 12:15:47   Hold reason: Transfer input files failure at access point ldas-pcdev2 while sending files to execution point slot1_22@node2072.cluster.ldas.cit. Details: Error from slot1_22@node2072.cluster.ldas.cit: SHADOW at 10.14.0.160 failed to send file(s) to <10.14.9.72:32873>: |Error: reading from file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/result/bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw_dynesty.pickle: (errno 2) No such file or directory; STARTER failed to receive file(s) from <10.14.0.160:9618>
04/30/24 12:15:47 Number of idle job procs: 1
04/30/24 12:15:47 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:15:47 Of 5 nodes total:
04/30/24 12:15:47  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:15:47   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:15:47     1       0        1       0       0          3        0        0
04/30/24 12:15:47 1 job proc(s) currently held
04/30/24 12:15:47 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001665570519187234; EventCycleTimeCount = 22.0; EventCycleTimeMax = 0.03536605834960938; EventCycleTimeMin = 2.694129943847656E-05; EventCycleTimeStd = 0.007527402888892978; EventCycleTimeSum = 0.03664255142211914; LogProcessCycleTimeAvg = 0.0001970529556274414; LogProcessCycleTimeCount = 2.0; LogProcessCycleTimeMax = 0.00026702880859375; LogProcessCycleTimeMin = 0.0001270771026611328; LogProcessCycleTimeStd = 9.896080030357919E-05; LogProcessCycleTimeSum = 0.0003941059112548828; SleepCycleTimeAvg = 5.004860477014021; SleepCycleTimeCount = 22.0; SleepCycleTimeMax = 5.005742073059082; SleepCycleTimeMin = 5.001527786254883; SleepCycleTimeStd = 0.0008342791791512314; SleepCycleTimeSum = 110.1069304943085; SubmitCycleTimeAvg = 0.001561672791190769; SubmitCycleTimeCount = 23.0; SubmitCycleTimeMax = 0.03524518013000488; SubmitCycleTimeMin = 1.502037048339844E-05; SubmitCycleTimeStd = 0.007342788867105858; SubmitCycleTimeSum = 0.0359184741973877; ]
04/30/24 12:17:47 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:17:47 Event: ULOG_JOB_RELEASED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411161.0.0) {04/30/24 12:17:45}
04/30/24 12:17:47 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:17:47 Of 5 nodes total:
04/30/24 12:17:47  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:17:47   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:17:47     1       0        1       0       0          3        0        0
04/30/24 12:17:47 0 job proc(s) currently held
04/30/24 12:17:47 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0008543988932733951; EventCycleTimeCount = 46.0; EventCycleTimeMax = 0.03536605834960938; EventCycleTimeMin = 2.694129943847656E-05; EventCycleTimeStd = 0.00520490399514363; EventCycleTimeSum = 0.03930234909057617; LogProcessCycleTimeAvg = 0.000177303949991862; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.00026702880859375; LogProcessCycleTimeMin = 0.0001270771026611328; LogProcessCycleTimeStd = 7.788895729912479E-05; LogProcessCycleTimeSum = 0.0005319118499755859; SleepCycleTimeAvg = 5.004889975423398; SleepCycleTimeCount = 46.0; SleepCycleTimeMax = 5.005742073059082; SleepCycleTimeMin = 5.001527786254883; SleepCycleTimeStd = 0.0006832509328975784; SleepCycleTimeSum = 230.2249388694763; SubmitCycleTimeAvg = 0.0008121044077771775; SubmitCycleTimeCount = 47.0; SubmitCycleTimeMax = 0.03524518013000488; SubmitCycleTimeMin = 1.502037048339844E-05; SubmitCycleTimeStd = 0.005134469263328788; SubmitCycleTimeSum = 0.03816890716552734; ]
04/30/24 12:20:13 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:20:13 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411161.0.0) {04/30/24 12:20:10}
04/30/24 12:20:13 Number of idle job procs: 0
04/30/24 12:20:23 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:20:23 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411161.0.0) {04/30/24 12:20:18}
04/30/24 12:20:23 Number of idle job procs: 0
04/30/24 12:20:23 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140411161.0.0) failed with status 1.
04/30/24 12:20:23 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:20:23 Of 5 nodes total:
04/30/24 12:20:23  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:20:23   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:20:23     1       0        0       0       0          0        1        3
04/30/24 12:20:23 0 job proc(s) currently held
04/30/24 12:20:23 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006084813700093851; EventCycleTimeCount = 77.0; EventCycleTimeMax = 0.03536605834960938; EventCycleTimeMin = 2.694129943847656E-05; EventCycleTimeStd = 0.004035700409558902; EventCycleTimeSum = 0.04685306549072266; LogProcessCycleTimeAvg = 0.0001885890960693359; LogProcessCycleTimeCount = 5.0; LogProcessCycleTimeMax = 0.00026702880859375; LogProcessCycleTimeMin = 0.0001270771026611328; LogProcessCycleTimeStd = 6.428553677164456E-05; LogProcessCycleTimeSum = 0.0009429454803466797; SleepCycleTimeAvg = 5.004932830860088; SleepCycleTimeCount = 77.0; SleepCycleTimeMax = 5.005742073059082; SleepCycleTimeMin = 5.001527786254883; SleepCycleTimeStd = 0.0005595000747794779; SleepCycleTimeSum = 385.3798279762268; SubmitCycleTimeAvg = 0.0005173224669236403; SubmitCycleTimeCount = 78.0; SubmitCycleTimeMax = 0.03524518013000488; SubmitCycleTimeMin = 1.502037048339844E-05; SubmitCycleTimeStd = 0.003986315786126245; SubmitCycleTimeSum = 0.04035115242004395; ]
04/30/24 12:20:23 ERROR: the following job(s) failed:
04/30/24 12:20:23 ---------------------- Job ----------------------
04/30/24 12:20:23       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 12:20:23            Noop: false
04/30/24 12:20:23          NodeID: 1
04/30/24 12:20:23     Node Status: STATUS_ERROR    
04/30/24 12:20:23 Node return val: 1
04/30/24 12:20:23           Error: Job proc (140411161.0.0) failed with status 1
04/30/24 12:20:23 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:20:23  HTCondor Job ID: (140411161.0.0)
04/30/24 12:20:23 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
04/30/24 12:20:23 ---------------------------------------	<END>
04/30/24 12:20:23 Aborting DAG...
04/30/24 12:20:23 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue004...
04/30/24 12:20:23 Removing submitted jobs...
04/30/24 12:20:23 Removing any/all submitted HTCondor jobs...
04/30/24 12:20:23 Running: /usr/bin/condor_rm -const DAGManJobId==140411160 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 12:20:23 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 12:20:23 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 12:20:23 Note: 0 total job deferrals because of node category throttles
04/30/24 12:20:23 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 12:20:23 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 12:20:23 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 12:20:23 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:20:23 Of 5 nodes total:
04/30/24 12:20:23  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:20:23   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:20:23     1       0        0       0       0          0        1        3
04/30/24 12:20:23 0 job proc(s) currently held
04/30/24 12:20:23 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006084813700093851; EventCycleTimeCount = 77.0; EventCycleTimeMax = 0.03536605834960938; EventCycleTimeMin = 2.694129943847656E-05; EventCycleTimeStd = 0.004035700409558902; EventCycleTimeSum = 0.04685306549072266; LogProcessCycleTimeAvg = 0.0001885890960693359; LogProcessCycleTimeCount = 5.0; LogProcessCycleTimeMax = 0.00026702880859375; LogProcessCycleTimeMin = 0.0001270771026611328; LogProcessCycleTimeStd = 6.428553677164456E-05; LogProcessCycleTimeSum = 0.0009429454803466797; SleepCycleTimeAvg = 5.004932830860088; SleepCycleTimeCount = 77.0; SleepCycleTimeMax = 5.005742073059082; SleepCycleTimeMin = 5.001527786254883; SleepCycleTimeStd = 0.0005595000747794779; SleepCycleTimeSum = 385.3798279762268; SubmitCycleTimeAvg = 0.0005173224669236403; SubmitCycleTimeCount = 78.0; SubmitCycleTimeMax = 0.03524518013000488; SubmitCycleTimeMin = 1.502037048339844E-05; SubmitCycleTimeStd = 0.003986315786126245; SubmitCycleTimeSum = 0.04035115242004395; ]
04/30/24 12:20:23 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 12:20:23 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006084813700093851; EventCycleTimeCount = 77.0; EventCycleTimeMax = 0.03536605834960938; EventCycleTimeMin = 2.694129943847656E-05; EventCycleTimeStd = 0.004035700409558902; EventCycleTimeSum = 0.04685306549072266; LogProcessCycleTimeAvg = 0.0001885890960693359; LogProcessCycleTimeCount = 5.0; LogProcessCycleTimeMax = 0.00026702880859375; LogProcessCycleTimeMin = 0.0001270771026611328; LogProcessCycleTimeStd = 6.428553677164456E-05; LogProcessCycleTimeSum = 0.0009429454803466797; SleepCycleTimeAvg = 5.004932830860088; SleepCycleTimeCount = 77.0; SleepCycleTimeMax = 5.005742073059082; SleepCycleTimeMin = 5.001527786254883; SleepCycleTimeStd = 0.0005595000747794779; SleepCycleTimeSum = 385.3798279762268; SubmitCycleTimeAvg = 0.0005173224669236403; SubmitCycleTimeCount = 78.0; SubmitCycleTimeMax = 0.03524518013000488; SubmitCycleTimeMin = 1.502037048339844E-05; SubmitCycleTimeStd = 0.003986315786126245; SubmitCycleTimeSum = 0.04035115242004395; ]
04/30/24 12:20:23 **** condor_scheduniv_exec.140411160.0 (condor_DAGMAN) pid 1804046 EXITING WITH STATUS 1
04/30/24 12:27:49 ******************************************************
04/30/24 12:27:49 ** condor_scheduniv_exec.140411164.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 12:27:49 ** /usr/bin/condor_dagman
04/30/24 12:27:49 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 12:27:49 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 12:27:49 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 12:27:49 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 12:27:49 ** PID = 1828828
04/30/24 12:27:49 ** Log last touched 4/30 12:20:23
04/30/24 12:27:49 ******************************************************
04/30/24 12:27:49 Using config source: /etc/condor/condor_config
04/30/24 12:27:49 Using local config sources: 
04/30/24 12:27:49    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 12:27:49    /etc/condor/config.d/00-ldas
04/30/24 12:27:49    /etc/condor/config.d/02-scheduler
04/30/24 12:27:49    /etc/condor/config.d/10-security
04/30/24 12:27:49    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 12:27:49    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 12:27:49    /etc/condor/config.d/30-scratch-mount
04/30/24 12:27:49    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 12:27:49    /etc/condor/config.d/50-transfer-limits
04/30/24 12:27:49    /etc/condor/config.d/65-system-periodic-hold
04/30/24 12:27:49    /etc/condor/config.d/93-dagman-use-direct
04/30/24 12:27:49    /etc/condor/config.d/99-memory
04/30/24 12:27:49    /etc/condor/config.d/99-request-disk
04/30/24 12:27:49    /etc/condor/config.d/99-request-missing-units
04/30/24 12:27:49    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 12:27:49    /etc/condor/config.d/99-transform
04/30/24 12:27:49    /etc/condor/condor_config.local
04/30/24 12:27:49 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 12:27:49 CLASSAD_CACHING is ENABLED
04/30/24 12:27:49 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 12:27:49 DaemonCore: No command port requested.
04/30/24 12:27:49 DAGMAN_USE_STRICT setting: 1
04/30/24 12:27:49 DAGMAN_VERBOSITY setting: 3
04/30/24 12:27:49 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 12:27:49 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 12:27:49 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 12:27:49 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 12:27:49 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 12:27:49 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 12:27:49 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 12:27:49 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 12:27:49 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 12:27:49 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 12:27:49 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 12:27:49 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 12:27:49 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 12:27:49 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 12:27:49 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 12:27:49 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 12:27:49 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 12:27:49 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 12:27:49 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 12:27:49 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 12:27:49 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 12:27:49 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 12:27:49 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 12:27:49 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 12:27:49 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 12:27:49 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 12:27:49 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 12:27:49 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 12:27:49 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 12:27:49 DAGMAN_AUTO_RESCUE setting: True
04/30/24 12:27:49 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 12:27:49 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 12:27:49 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 12:27:49 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 12:27:49 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 12:27:49 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 12:27:49 ALL_DEBUG setting: 
04/30/24 12:27:49 DAGMAN_DEBUG setting: 
04/30/24 12:27:49 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 12:27:49 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 12:27:49 DAGMAN will adjust edges after parsing
04/30/24 12:27:49 Enabling log line cache for increased NFS performance.
04/30/24 12:27:49 argv[0] == "condor_scheduniv_exec.140411164.0"
04/30/24 12:27:49 argv[1] == "-Lockfile"
04/30/24 12:27:49 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 12:27:49 argv[3] == "-Dag"
04/30/24 12:27:49 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 12:27:49 argv[5] == "-CsdVersion"
04/30/24 12:27:49 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 12:27:49 argv[7] == "-dagman"
04/30/24 12:27:49 argv[8] == "/usr/bin/condor_dagman"
04/30/24 12:27:49 argv[9] == "-AutoRescue"
04/30/24 12:27:49 argv[10] == "1"
04/30/24 12:27:49 argv[11] == "-DoRescueFrom"
04/30/24 12:27:49 argv[12] == "0"
04/30/24 12:27:49 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:27:49 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:27:49 Workflow batch-id: <140411164.0>
04/30/24 12:27:49 Workflow batch-name: <bbh.dag+140411164>
04/30/24 12:27:49 Workflow accounting_group: <>
04/30/24 12:27:49 Workflow accounting_group_user: <>
04/30/24 12:27:49 Warning: failed to get attribute DAGNodeName
04/30/24 12:27:49 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 12:27:49 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 12:27:49 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 12:27:49 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 12:27:49 Parsing 1 dagfiles
04/30/24 12:27:49 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 12:27:49 Adjusting edges
04/30/24 12:27:49 Found rescue DAG number 4; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue004 in combination with normal DAG file
04/30/24 12:27:49 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 12:27:49 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue004
04/30/24 12:27:49 Dag contains 5 total jobs
04/30/24 12:27:49 Bootstrapping...
04/30/24 12:27:49 Number of pre-completed nodes: 1
04/30/24 12:27:49 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:27:49 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:27:49 Of 5 nodes total:
04/30/24 12:27:49  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:27:49   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:27:49     1       0        0       0       1          3        0        0
04/30/24 12:27:49 0 job proc(s) currently held
04/30/24 12:27:49 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 12:27:49 Registering condor_event_timer...
04/30/24 12:27:50 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 12:27:50 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:27:50 Masking the events recorded in the DAGMAN workflow log
04/30/24 12:27:50 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 12:27:50 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411164 -a DAGManJobId=140411164 -batch-name bbh.dag+140411164 -batch-id 140411164.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:27:50 From submit: Submitting job(s).
04/30/24 12:27:50 From submit: 1 job(s) submitted to cluster 140411165.
04/30/24 12:27:50 	assigned HTCondor ID (140411165.0.0)
04/30/24 12:27:50 Just submitted 1 job this cycle...
04/30/24 12:27:50 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:27:50 Of 5 nodes total:
04/30/24 12:27:50  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:27:50   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:27:50     1       0        1       0       0          3        0        0
04/30/24 12:27:50 0 job proc(s) currently held
04/30/24 12:27:50 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03682804107666016; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03682804107666016; SubmitCycleTimeMin = 0.03682804107666016; SubmitCycleTimeStd = 0.03682804107666016; SubmitCycleTimeSum = 0.03682804107666016; ]
04/30/24 12:27:55 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:27:55 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411165.0.0) to (140411165.0.0)
04/30/24 12:27:55 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411165.0.0) {04/30/24 12:27:50}
04/30/24 12:27:55 Number of idle job procs: 1
04/30/24 12:28:15 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:28:15 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411165.0.0) {04/30/24 12:28:11}
04/30/24 12:28:15 Number of idle job procs: 0
04/30/24 12:28:20 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:28:20 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411165.0.0) {04/30/24 12:28:18}
04/30/24 12:28:20 Number of idle job procs: 0
04/30/24 12:28:20 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140411165.0.0) failed with status 1.
04/30/24 12:28:20 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:28:20 Of 5 nodes total:
04/30/24 12:28:20  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:28:20   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:28:20     1       0        0       0       0          0        1        3
04/30/24 12:28:20 0 job proc(s) currently held
04/30/24 12:28:20 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.006234010060628255; EventCycleTimeCount = 6.0; EventCycleTimeMax = 0.03697800636291504; EventCycleTimeMin = 2.503395080566406E-05; EventCycleTimeStd = 0.01506158309720558; EventCycleTimeSum = 0.03740406036376953; LogProcessCycleTimeAvg = 0.0001498063405354818; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0001721382141113281; LogProcessCycleTimeMin = 0.0001311302185058594; LogProcessCycleTimeStd = 2.074698328481326E-05; LogProcessCycleTimeSum = 0.0004494190216064453; SleepCycleTimeAvg = 5.004808982213338; SleepCycleTimeCount = 6.0; SleepCycleTimeMax = 5.005131006240845; SleepCycleTimeMin = 5.004088878631592; SleepCycleTimeStd = 0.0004164894776559638; SleepCycleTimeSum = 30.02885389328003; SubmitCycleTimeAvg = 0.005276577813284737; SubmitCycleTimeCount = 7.0; SubmitCycleTimeMax = 0.03682804107666016; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.01391288812508903; SubmitCycleTimeSum = 0.03693604469299316; ]
04/30/24 12:28:20 ERROR: the following job(s) failed:
04/30/24 12:28:20 ---------------------- Job ----------------------
04/30/24 12:28:20       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 12:28:20            Noop: false
04/30/24 12:28:20          NodeID: 1
04/30/24 12:28:20     Node Status: STATUS_ERROR    
04/30/24 12:28:20 Node return val: 1
04/30/24 12:28:20           Error: Job proc (140411165.0.0) failed with status 1
04/30/24 12:28:20 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:28:20  HTCondor Job ID: (140411165.0.0)
04/30/24 12:28:20 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
04/30/24 12:28:20 ---------------------------------------	<END>
04/30/24 12:28:20 Aborting DAG...
04/30/24 12:28:20 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue005...
04/30/24 12:28:20 Removing submitted jobs...
04/30/24 12:28:20 Removing any/all submitted HTCondor jobs...
04/30/24 12:28:20 Running: /usr/bin/condor_rm -const DAGManJobId==140411164 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 12:28:20 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 12:28:20 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 12:28:20 Note: 0 total job deferrals because of node category throttles
04/30/24 12:28:20 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 12:28:20 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 12:28:20 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 12:28:20 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:28:20 Of 5 nodes total:
04/30/24 12:28:20  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:28:20   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:28:20     1       0        0       0       0          0        1        3
04/30/24 12:28:20 0 job proc(s) currently held
04/30/24 12:28:20 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.006234010060628255; EventCycleTimeCount = 6.0; EventCycleTimeMax = 0.03697800636291504; EventCycleTimeMin = 2.503395080566406E-05; EventCycleTimeStd = 0.01506158309720558; EventCycleTimeSum = 0.03740406036376953; LogProcessCycleTimeAvg = 0.0001498063405354818; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0001721382141113281; LogProcessCycleTimeMin = 0.0001311302185058594; LogProcessCycleTimeStd = 2.074698328481326E-05; LogProcessCycleTimeSum = 0.0004494190216064453; SleepCycleTimeAvg = 5.004808982213338; SleepCycleTimeCount = 6.0; SleepCycleTimeMax = 5.005131006240845; SleepCycleTimeMin = 5.004088878631592; SleepCycleTimeStd = 0.0004164894776559638; SleepCycleTimeSum = 30.02885389328003; SubmitCycleTimeAvg = 0.005276577813284737; SubmitCycleTimeCount = 7.0; SubmitCycleTimeMax = 0.03682804107666016; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.01391288812508903; SubmitCycleTimeSum = 0.03693604469299316; ]
04/30/24 12:28:20 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 12:28:20 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.006234010060628255; EventCycleTimeCount = 6.0; EventCycleTimeMax = 0.03697800636291504; EventCycleTimeMin = 2.503395080566406E-05; EventCycleTimeStd = 0.01506158309720558; EventCycleTimeSum = 0.03740406036376953; LogProcessCycleTimeAvg = 0.0001498063405354818; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0001721382141113281; LogProcessCycleTimeMin = 0.0001311302185058594; LogProcessCycleTimeStd = 2.074698328481326E-05; LogProcessCycleTimeSum = 0.0004494190216064453; SleepCycleTimeAvg = 5.004808982213338; SleepCycleTimeCount = 6.0; SleepCycleTimeMax = 5.005131006240845; SleepCycleTimeMin = 5.004088878631592; SleepCycleTimeStd = 0.0004164894776559638; SleepCycleTimeSum = 30.02885389328003; SubmitCycleTimeAvg = 0.005276577813284737; SubmitCycleTimeCount = 7.0; SubmitCycleTimeMax = 0.03682804107666016; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.01391288812508903; SubmitCycleTimeSum = 0.03693604469299316; ]
04/30/24 12:28:20 **** condor_scheduniv_exec.140411164.0 (condor_DAGMAN) pid 1828828 EXITING WITH STATUS 1
04/30/24 12:33:19 ******************************************************
04/30/24 12:33:19 ** condor_scheduniv_exec.140411167.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 12:33:19 ** /usr/bin/condor_dagman
04/30/24 12:33:19 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 12:33:19 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 12:33:19 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 12:33:19 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 12:33:19 ** PID = 1839677
04/30/24 12:33:19 ** Log last touched 4/30 12:28:20
04/30/24 12:33:19 ******************************************************
04/30/24 12:33:19 Using config source: /etc/condor/condor_config
04/30/24 12:33:19 Using local config sources: 
04/30/24 12:33:19    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 12:33:19    /etc/condor/config.d/00-ldas
04/30/24 12:33:19    /etc/condor/config.d/02-scheduler
04/30/24 12:33:19    /etc/condor/config.d/10-security
04/30/24 12:33:19    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 12:33:19    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 12:33:19    /etc/condor/config.d/30-scratch-mount
04/30/24 12:33:19    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 12:33:19    /etc/condor/config.d/50-transfer-limits
04/30/24 12:33:19    /etc/condor/config.d/65-system-periodic-hold
04/30/24 12:33:19    /etc/condor/config.d/93-dagman-use-direct
04/30/24 12:33:19    /etc/condor/config.d/99-memory
04/30/24 12:33:19    /etc/condor/config.d/99-request-disk
04/30/24 12:33:19    /etc/condor/config.d/99-request-missing-units
04/30/24 12:33:19    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 12:33:19    /etc/condor/config.d/99-transform
04/30/24 12:33:19    /etc/condor/condor_config.local
04/30/24 12:33:19 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 12:33:19 CLASSAD_CACHING is ENABLED
04/30/24 12:33:19 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 12:33:19 DaemonCore: No command port requested.
04/30/24 12:33:19 DAGMAN_USE_STRICT setting: 1
04/30/24 12:33:19 DAGMAN_VERBOSITY setting: 3
04/30/24 12:33:19 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 12:33:19 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 12:33:19 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 12:33:19 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 12:33:19 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 12:33:19 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 12:33:19 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 12:33:19 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 12:33:19 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 12:33:19 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 12:33:19 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 12:33:19 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 12:33:19 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 12:33:19 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 12:33:19 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 12:33:19 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 12:33:19 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 12:33:19 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 12:33:19 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 12:33:19 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 12:33:19 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 12:33:19 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 12:33:19 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 12:33:19 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 12:33:19 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 12:33:19 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 12:33:19 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 12:33:19 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 12:33:19 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 12:33:19 DAGMAN_AUTO_RESCUE setting: True
04/30/24 12:33:19 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 12:33:19 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 12:33:19 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 12:33:19 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 12:33:19 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 12:33:19 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 12:33:19 ALL_DEBUG setting: 
04/30/24 12:33:19 DAGMAN_DEBUG setting: 
04/30/24 12:33:19 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 12:33:19 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 12:33:19 DAGMAN will adjust edges after parsing
04/30/24 12:33:19 Enabling log line cache for increased NFS performance.
04/30/24 12:33:19 argv[0] == "condor_scheduniv_exec.140411167.0"
04/30/24 12:33:19 argv[1] == "-Lockfile"
04/30/24 12:33:19 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 12:33:19 argv[3] == "-Dag"
04/30/24 12:33:19 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 12:33:19 argv[5] == "-CsdVersion"
04/30/24 12:33:19 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 12:33:19 argv[7] == "-dagman"
04/30/24 12:33:19 argv[8] == "/usr/bin/condor_dagman"
04/30/24 12:33:19 argv[9] == "-AutoRescue"
04/30/24 12:33:19 argv[10] == "1"
04/30/24 12:33:19 argv[11] == "-DoRescueFrom"
04/30/24 12:33:19 argv[12] == "0"
04/30/24 12:33:19 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:33:19 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:33:19 Workflow batch-id: <140411167.0>
04/30/24 12:33:19 Workflow batch-name: <bbh.dag+140411167>
04/30/24 12:33:19 Workflow accounting_group: <>
04/30/24 12:33:19 Workflow accounting_group_user: <>
04/30/24 12:33:19 Warning: failed to get attribute DAGNodeName
04/30/24 12:33:19 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 12:33:19 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 12:33:19 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 12:33:19 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 12:33:19 Parsing 1 dagfiles
04/30/24 12:33:19 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 12:33:19 Adjusting edges
04/30/24 12:33:19 Found rescue DAG number 5; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue005 in combination with normal DAG file
04/30/24 12:33:19 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 12:33:19 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue005
04/30/24 12:33:19 Dag contains 5 total jobs
04/30/24 12:33:19 Bootstrapping...
04/30/24 12:33:19 Number of pre-completed nodes: 1
04/30/24 12:33:19 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:33:19 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:33:19 Of 5 nodes total:
04/30/24 12:33:19  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:33:19   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:33:19     1       0        0       0       1          3        0        0
04/30/24 12:33:19 0 job proc(s) currently held
04/30/24 12:33:19 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 12:33:19 Registering condor_event_timer...
04/30/24 12:33:20 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 12:33:20 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:33:20 Masking the events recorded in the DAGMAN workflow log
04/30/24 12:33:20 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 12:33:20 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411167 -a DAGManJobId=140411167 -batch-name bbh.dag+140411167 -batch-id 140411167.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:33:20 From submit: Submitting job(s).
04/30/24 12:33:20 From submit: 1 job(s) submitted to cluster 140411168.
04/30/24 12:33:20 	assigned HTCondor ID (140411168.0.0)
04/30/24 12:33:20 Just submitted 1 job this cycle...
04/30/24 12:33:20 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:33:20 Of 5 nodes total:
04/30/24 12:33:20  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:33:20   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:33:20     1       0        1       0       0          3        0        0
04/30/24 12:33:20 0 job proc(s) currently held
04/30/24 12:33:20 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03486490249633789; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03486490249633789; SubmitCycleTimeMin = 0.03486490249633789; SubmitCycleTimeStd = 0.03486490249633789; SubmitCycleTimeSum = 0.03486490249633789; ]
04/30/24 12:33:25 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:33:25 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411168.0.0) to (140411168.0.0)
04/30/24 12:33:25 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411168.0.0) {04/30/24 12:33:20}
04/30/24 12:33:25 Number of idle job procs: 1
04/30/24 12:34:50 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:34:50 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411168.0.0) {04/30/24 12:34:47}
04/30/24 12:34:50 Number of idle job procs: 0
04/30/24 12:34:55 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:34:55 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411168.0.0) {04/30/24 12:34:52}
04/30/24 12:34:55 Number of idle job procs: 0
04/30/24 12:34:55 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140411168.0.0) failed with status 1.
04/30/24 12:34:55 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:34:55 Of 5 nodes total:
04/30/24 12:34:55  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:34:55   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:34:55     1       0        0       0       0          0        1        3
04/30/24 12:34:55 0 job proc(s) currently held
04/30/24 12:34:55 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001913284000597502; EventCycleTimeCount = 19.0; EventCycleTimeMax = 0.0350041389465332; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.008013695918520108; EventCycleTimeSum = 0.03635239601135254; LogProcessCycleTimeAvg = 0.0002245903015136719; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003008842468261719; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 6.651151952424124E-05; LogProcessCycleTimeSum = 0.0006737709045410156; SleepCycleTimeAvg = 5.004910456506829; SleepCycleTimeCount = 19.0; SleepCycleTimeMax = 5.005868911743164; SleepCycleTimeMin = 5.001044034957886; SleepCycleTimeStd = 0.0009538959023884865; SleepCycleTimeSum = 95.09329867362976; SubmitCycleTimeAvg = 0.001767599582672119; SubmitCycleTimeCount = 20.0; SubmitCycleTimeMax = 0.03486490249633789; SubmitCycleTimeMin = 1.9073486328125E-05; SubmitCycleTimeStd = 0.007790297871126972; SubmitCycleTimeSum = 0.03535199165344238; ]
04/30/24 12:34:55 ERROR: the following job(s) failed:
04/30/24 12:34:55 ---------------------- Job ----------------------
04/30/24 12:34:55       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 12:34:55            Noop: false
04/30/24 12:34:55          NodeID: 1
04/30/24 12:34:55     Node Status: STATUS_ERROR    
04/30/24 12:34:55 Node return val: 1
04/30/24 12:34:55           Error: Job proc (140411168.0.0) failed with status 1
04/30/24 12:34:55 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:34:55  HTCondor Job ID: (140411168.0.0)
04/30/24 12:34:55 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
04/30/24 12:34:55 ---------------------------------------	<END>
04/30/24 12:34:55 Aborting DAG...
04/30/24 12:34:55 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue006...
04/30/24 12:34:55 Removing submitted jobs...
04/30/24 12:34:55 Removing any/all submitted HTCondor jobs...
04/30/24 12:34:55 Running: /usr/bin/condor_rm -const DAGManJobId==140411167 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 12:34:55 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 12:34:55 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 12:34:55 Note: 0 total job deferrals because of node category throttles
04/30/24 12:34:55 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 12:34:55 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 12:34:55 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 12:34:55 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:34:55 Of 5 nodes total:
04/30/24 12:34:55  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:34:55   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:34:55     1       0        0       0       0          0        1        3
04/30/24 12:34:55 0 job proc(s) currently held
04/30/24 12:34:55 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001913284000597502; EventCycleTimeCount = 19.0; EventCycleTimeMax = 0.0350041389465332; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.008013695918520108; EventCycleTimeSum = 0.03635239601135254; LogProcessCycleTimeAvg = 0.0002245903015136719; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003008842468261719; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 6.651151952424124E-05; LogProcessCycleTimeSum = 0.0006737709045410156; SleepCycleTimeAvg = 5.004910456506829; SleepCycleTimeCount = 19.0; SleepCycleTimeMax = 5.005868911743164; SleepCycleTimeMin = 5.001044034957886; SleepCycleTimeStd = 0.0009538959023884865; SleepCycleTimeSum = 95.09329867362976; SubmitCycleTimeAvg = 0.001767599582672119; SubmitCycleTimeCount = 20.0; SubmitCycleTimeMax = 0.03486490249633789; SubmitCycleTimeMin = 1.9073486328125E-05; SubmitCycleTimeStd = 0.007790297871126972; SubmitCycleTimeSum = 0.03535199165344238; ]
04/30/24 12:34:55 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 12:34:55 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001913284000597502; EventCycleTimeCount = 19.0; EventCycleTimeMax = 0.0350041389465332; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.008013695918520108; EventCycleTimeSum = 0.03635239601135254; LogProcessCycleTimeAvg = 0.0002245903015136719; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003008842468261719; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 6.651151952424124E-05; LogProcessCycleTimeSum = 0.0006737709045410156; SleepCycleTimeAvg = 5.004910456506829; SleepCycleTimeCount = 19.0; SleepCycleTimeMax = 5.005868911743164; SleepCycleTimeMin = 5.001044034957886; SleepCycleTimeStd = 0.0009538959023884865; SleepCycleTimeSum = 95.09329867362976; SubmitCycleTimeAvg = 0.001767599582672119; SubmitCycleTimeCount = 20.0; SubmitCycleTimeMax = 0.03486490249633789; SubmitCycleTimeMin = 1.9073486328125E-05; SubmitCycleTimeStd = 0.007790297871126972; SubmitCycleTimeSum = 0.03535199165344238; ]
04/30/24 12:34:55 **** condor_scheduniv_exec.140411167.0 (condor_DAGMAN) pid 1839677 EXITING WITH STATUS 1
04/30/24 12:41:05 ******************************************************
04/30/24 12:41:05 ** condor_scheduniv_exec.140411169.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 12:41:05 ** /usr/bin/condor_dagman
04/30/24 12:41:05 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 12:41:05 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 12:41:05 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 12:41:05 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 12:41:05 ** PID = 1854552
04/30/24 12:41:05 ** Log last touched 4/30 12:34:55
04/30/24 12:41:05 ******************************************************
04/30/24 12:41:05 Using config source: /etc/condor/condor_config
04/30/24 12:41:05 Using local config sources: 
04/30/24 12:41:05    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 12:41:05    /etc/condor/config.d/00-ldas
04/30/24 12:41:05    /etc/condor/config.d/02-scheduler
04/30/24 12:41:05    /etc/condor/config.d/10-security
04/30/24 12:41:05    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 12:41:05    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 12:41:05    /etc/condor/config.d/30-scratch-mount
04/30/24 12:41:05    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 12:41:05    /etc/condor/config.d/50-transfer-limits
04/30/24 12:41:05    /etc/condor/config.d/65-system-periodic-hold
04/30/24 12:41:05    /etc/condor/config.d/93-dagman-use-direct
04/30/24 12:41:05    /etc/condor/config.d/99-memory
04/30/24 12:41:05    /etc/condor/config.d/99-request-disk
04/30/24 12:41:05    /etc/condor/config.d/99-request-missing-units
04/30/24 12:41:05    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 12:41:05    /etc/condor/config.d/99-transform
04/30/24 12:41:05    /etc/condor/condor_config.local
04/30/24 12:41:05 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 12:41:05 CLASSAD_CACHING is ENABLED
04/30/24 12:41:05 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 12:41:05 DaemonCore: No command port requested.
04/30/24 12:41:05 DAGMAN_USE_STRICT setting: 1
04/30/24 12:41:05 DAGMAN_VERBOSITY setting: 3
04/30/24 12:41:05 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 12:41:05 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 12:41:05 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 12:41:05 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 12:41:05 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 12:41:05 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 12:41:05 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 12:41:05 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 12:41:05 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 12:41:05 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 12:41:05 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 12:41:05 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 12:41:05 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 12:41:05 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 12:41:05 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 12:41:05 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 12:41:05 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 12:41:05 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 12:41:05 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 12:41:05 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 12:41:05 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 12:41:05 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 12:41:05 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 12:41:05 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 12:41:05 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 12:41:05 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 12:41:05 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 12:41:05 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 12:41:05 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 12:41:05 DAGMAN_AUTO_RESCUE setting: True
04/30/24 12:41:05 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 12:41:05 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 12:41:05 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 12:41:05 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 12:41:05 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 12:41:05 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 12:41:05 ALL_DEBUG setting: 
04/30/24 12:41:05 DAGMAN_DEBUG setting: 
04/30/24 12:41:05 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 12:41:05 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 12:41:05 DAGMAN will adjust edges after parsing
04/30/24 12:41:05 Enabling log line cache for increased NFS performance.
04/30/24 12:41:05 argv[0] == "condor_scheduniv_exec.140411169.0"
04/30/24 12:41:05 argv[1] == "-Lockfile"
04/30/24 12:41:05 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 12:41:05 argv[3] == "-Dag"
04/30/24 12:41:05 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 12:41:05 argv[5] == "-CsdVersion"
04/30/24 12:41:05 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 12:41:05 argv[7] == "-dagman"
04/30/24 12:41:05 argv[8] == "/usr/bin/condor_dagman"
04/30/24 12:41:05 argv[9] == "-AutoRescue"
04/30/24 12:41:05 argv[10] == "1"
04/30/24 12:41:05 argv[11] == "-DoRescueFrom"
04/30/24 12:41:05 argv[12] == "0"
04/30/24 12:41:05 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:41:05 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 12:41:05 Workflow batch-id: <140411169.0>
04/30/24 12:41:05 Workflow batch-name: <bbh.dag+140411169>
04/30/24 12:41:05 Workflow accounting_group: <>
04/30/24 12:41:05 Workflow accounting_group_user: <>
04/30/24 12:41:05 Warning: failed to get attribute DAGNodeName
04/30/24 12:41:05 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 12:41:05 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 12:41:05 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 12:41:05 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 12:41:05 Parsing 1 dagfiles
04/30/24 12:41:05 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 12:41:05 Adjusting edges
04/30/24 12:41:05 Found rescue DAG number 6; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue006 in combination with normal DAG file
04/30/24 12:41:05 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 12:41:05 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue006
04/30/24 12:41:05 Dag contains 5 total jobs
04/30/24 12:41:05 Bootstrapping...
04/30/24 12:41:05 Number of pre-completed nodes: 1
04/30/24 12:41:05 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:41:05 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:41:05 Of 5 nodes total:
04/30/24 12:41:05  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:41:05   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:41:05     1       0        0       0       1          3        0        0
04/30/24 12:41:05 0 job proc(s) currently held
04/30/24 12:41:05 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 12:41:05 Registering condor_event_timer...
04/30/24 12:41:06 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 12:41:06 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 12:41:06 Masking the events recorded in the DAGMAN workflow log
04/30/24 12:41:06 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 12:41:06 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411169 -a DAGManJobId=140411169 -batch-name bbh.dag+140411169 -batch-id 140411169.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:41:06 From submit: Submitting job(s).
04/30/24 12:41:06 From submit: 1 job(s) submitted to cluster 140411170.
04/30/24 12:41:06 	assigned HTCondor ID (140411170.0.0)
04/30/24 12:41:06 Just submitted 1 job this cycle...
04/30/24 12:41:06 DAG status: 0 (DAG_STATUS_OK)
04/30/24 12:41:06 Of 5 nodes total:
04/30/24 12:41:06  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:41:06   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:41:06     1       0        1       0       0          3        0        0
04/30/24 12:41:06 0 job proc(s) currently held
04/30/24 12:41:06 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.0352318286895752; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.0352318286895752; SubmitCycleTimeMin = 0.0352318286895752; SubmitCycleTimeStd = 0.0352318286895752; SubmitCycleTimeSum = 0.0352318286895752; ]
04/30/24 12:41:11 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:41:11 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411170.0.0) to (140411170.0.0)
04/30/24 12:41:11 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411170.0.0) {04/30/24 12:41:06}
04/30/24 12:41:11 Number of idle job procs: 1
04/30/24 12:42:36 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:42:36 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411170.0.0) {04/30/24 12:42:34}
04/30/24 12:42:36 Number of idle job procs: 0
04/30/24 12:42:46 Currently monitoring 1 HTCondor log file(s)
04/30/24 12:42:46 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411170.0.0) {04/30/24 12:42:46}
04/30/24 12:42:46 Number of idle job procs: 0
04/30/24 12:42:46 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140411170.0.0) failed with status 1.
04/30/24 12:42:46 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:42:46 Of 5 nodes total:
04/30/24 12:42:46  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:42:46   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:42:46     1       0        0       0       0          0        1        3
04/30/24 12:42:46 0 job proc(s) currently held
04/30/24 12:42:46 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001843154430389404; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.03535294532775879; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.007888165062525253; EventCycleTimeSum = 0.03686308860778809; LogProcessCycleTimeAvg = 0.0002129872639973958; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002808570861816406; LogProcessCycleTimeMin = 0.0001771450042724609; LogProcessCycleTimeStd = 5.880792932333056E-05; LogProcessCycleTimeSum = 0.0006389617919921875; SleepCycleTimeAvg = 5.005142343044281; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006256103515625; SleepCycleTimeMin = 5.005043983459473; SleepCycleTimeStd = 0.0002637177740339052; SleepCycleTimeSum = 100.1028468608856; SubmitCycleTimeAvg = 0.001708314532325381; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.0352318286895752; SubmitCycleTimeMin = 1.978874206542969E-05; SubmitCycleTimeStd = 0.007681300296801236; SubmitCycleTimeSum = 0.03587460517883301; ]
04/30/24 12:42:46 ERROR: the following job(s) failed:
04/30/24 12:42:46 ---------------------- Job ----------------------
04/30/24 12:42:46       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 12:42:46            Noop: false
04/30/24 12:42:46          NodeID: 1
04/30/24 12:42:46     Node Status: STATUS_ERROR    
04/30/24 12:42:46 Node return val: 1
04/30/24 12:42:46           Error: Job proc (140411170.0.0) failed with status 1
04/30/24 12:42:46 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 12:42:46  HTCondor Job ID: (140411170.0.0)
04/30/24 12:42:46 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
04/30/24 12:42:46 ---------------------------------------	<END>
04/30/24 12:42:46 Aborting DAG...
04/30/24 12:42:46 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue007...
04/30/24 12:42:46 Removing submitted jobs...
04/30/24 12:42:46 Removing any/all submitted HTCondor jobs...
04/30/24 12:42:46 Running: /usr/bin/condor_rm -const DAGManJobId==140411169 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 12:42:46 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 12:42:46 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 12:42:46 Note: 0 total job deferrals because of node category throttles
04/30/24 12:42:46 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 12:42:46 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 12:42:46 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 12:42:46 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 12:42:46 Of 5 nodes total:
04/30/24 12:42:46  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 12:42:46   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 12:42:46     1       0        0       0       0          0        1        3
04/30/24 12:42:46 0 job proc(s) currently held
04/30/24 12:42:46 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001843154430389404; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.03535294532775879; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.007888165062525253; EventCycleTimeSum = 0.03686308860778809; LogProcessCycleTimeAvg = 0.0002129872639973958; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002808570861816406; LogProcessCycleTimeMin = 0.0001771450042724609; LogProcessCycleTimeStd = 5.880792932333056E-05; LogProcessCycleTimeSum = 0.0006389617919921875; SleepCycleTimeAvg = 5.005142343044281; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006256103515625; SleepCycleTimeMin = 5.005043983459473; SleepCycleTimeStd = 0.0002637177740339052; SleepCycleTimeSum = 100.1028468608856; SubmitCycleTimeAvg = 0.001708314532325381; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.0352318286895752; SubmitCycleTimeMin = 1.978874206542969E-05; SubmitCycleTimeStd = 0.007681300296801236; SubmitCycleTimeSum = 0.03587460517883301; ]
04/30/24 12:42:46 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 12:42:46 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001843154430389404; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.03535294532775879; EventCycleTimeMin = 3.194808959960938E-05; EventCycleTimeStd = 0.007888165062525253; EventCycleTimeSum = 0.03686308860778809; LogProcessCycleTimeAvg = 0.0002129872639973958; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002808570861816406; LogProcessCycleTimeMin = 0.0001771450042724609; LogProcessCycleTimeStd = 5.880792932333056E-05; LogProcessCycleTimeSum = 0.0006389617919921875; SleepCycleTimeAvg = 5.005142343044281; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006256103515625; SleepCycleTimeMin = 5.005043983459473; SleepCycleTimeStd = 0.0002637177740339052; SleepCycleTimeSum = 100.1028468608856; SubmitCycleTimeAvg = 0.001708314532325381; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.0352318286895752; SubmitCycleTimeMin = 1.978874206542969E-05; SubmitCycleTimeStd = 0.007681300296801236; SubmitCycleTimeSum = 0.03587460517883301; ]
04/30/24 12:42:46 **** condor_scheduniv_exec.140411169.0 (condor_DAGMAN) pid 1854552 EXITING WITH STATUS 1
04/30/24 13:49:22 ******************************************************
04/30/24 13:49:22 ** condor_scheduniv_exec.140411179.0 (CONDOR_DAGMAN) STARTING UP
04/30/24 13:49:22 ** /usr/bin/condor_dagman
04/30/24 13:49:22 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
04/30/24 13:49:22 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
04/30/24 13:49:22 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
04/30/24 13:49:22 ** $CondorPlatform: x86_64_AlmaLinux8 $
04/30/24 13:49:22 ** PID = 1956931
04/30/24 13:49:22 ** Log last touched 4/30 12:42:46
04/30/24 13:49:22 ******************************************************
04/30/24 13:49:22 Using config source: /etc/condor/condor_config
04/30/24 13:49:22 Using local config sources: 
04/30/24 13:49:22    /etc/condor/config.d/00-htcondor-9.0.config
04/30/24 13:49:22    /etc/condor/config.d/00-ldas
04/30/24 13:49:22    /etc/condor/config.d/02-scheduler
04/30/24 13:49:22    /etc/condor/config.d/10-security
04/30/24 13:49:22    /etc/condor/config.d/10-stash-plugin.conf
04/30/24 13:49:22    /etc/condor/config.d/15-dagman-default-append-vars
04/30/24 13:49:22    /etc/condor/config.d/30-scratch-mount
04/30/24 13:49:22    /etc/condor/config.d/40-vault-credmon.conf
04/30/24 13:49:22    /etc/condor/config.d/50-transfer-limits
04/30/24 13:49:22    /etc/condor/config.d/65-system-periodic-hold
04/30/24 13:49:22    /etc/condor/config.d/93-dagman-use-direct
04/30/24 13:49:22    /etc/condor/config.d/99-memory
04/30/24 13:49:22    /etc/condor/config.d/99-request-disk
04/30/24 13:49:22    /etc/condor/config.d/99-request-missing-units
04/30/24 13:49:22    /etc/condor/config.d/99-shared-port-descriptor
04/30/24 13:49:22    /etc/condor/config.d/99-transform
04/30/24 13:49:22    /etc/condor/condor_config.local
04/30/24 13:49:22 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
04/30/24 13:49:22 CLASSAD_CACHING is ENABLED
04/30/24 13:49:22 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
04/30/24 13:49:22 DaemonCore: No command port requested.
04/30/24 13:49:22 DAGMAN_USE_STRICT setting: 1
04/30/24 13:49:22 DAGMAN_VERBOSITY setting: 3
04/30/24 13:49:22 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/30/24 13:49:22 DAGMAN_DEBUG_CACHE_ENABLE setting: True
04/30/24 13:49:22 DAGMAN_SUBMIT_DELAY setting: 0
04/30/24 13:49:22 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/30/24 13:49:22 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/30/24 13:49:22 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
04/30/24 13:49:22 DAGMAN_AGGRESSIVE_SUBMIT setting: False
04/30/24 13:49:22 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/30/24 13:49:22 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
04/30/24 13:49:22 DAGMAN_DEFAULT_PRIORITY setting: 0
04/30/24 13:49:22 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/30/24 13:49:22 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/30/24 13:49:22 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/30/24 13:49:22 DAGMAN_RETRY_NODE_FIRST setting: False
04/30/24 13:49:22 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/30/24 13:49:22 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
04/30/24 13:49:22 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/30/24 13:49:22 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/30/24 13:49:22 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
04/30/24 13:49:22 DAGMAN_MUNGE_NODE_NAMES setting: True
04/30/24 13:49:22 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/30/24 13:49:22 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
04/30/24 13:49:22 DAGMAN_ALWAYS_RUN_POST setting: False
04/30/24 13:49:22 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
04/30/24 13:49:22 DAGMAN_USE_DIRECT_SUBMIT setting: False
04/30/24 13:49:22 DAGMAN_DEFAULT_APPEND_VARS setting: True
04/30/24 13:49:22 DAGMAN_ABORT_DUPLICATES setting: True
04/30/24 13:49:22 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/30/24 13:49:22 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/30/24 13:49:22 DAGMAN_AUTO_RESCUE setting: True
04/30/24 13:49:22 DAGMAN_MAX_RESCUE_NUM setting: 100
04/30/24 13:49:22 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/30/24 13:49:22 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/30/24 13:49:22 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/30/24 13:49:22 DAGMAN_MAX_JOB_HOLDS setting: 100
04/30/24 13:49:22 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/30/24 13:49:22 ALL_DEBUG setting: 
04/30/24 13:49:22 DAGMAN_DEBUG setting: 
04/30/24 13:49:22 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/30/24 13:49:22 DAGMAN_REMOVE_NODE_JOBS setting: True
04/30/24 13:49:22 DAGMAN will adjust edges after parsing
04/30/24 13:49:22 Enabling log line cache for increased NFS performance.
04/30/24 13:49:22 argv[0] == "condor_scheduniv_exec.140411179.0"
04/30/24 13:49:22 argv[1] == "-Lockfile"
04/30/24 13:49:22 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
04/30/24 13:49:22 argv[3] == "-Dag"
04/30/24 13:49:22 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
04/30/24 13:49:22 argv[5] == "-CsdVersion"
04/30/24 13:49:22 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
04/30/24 13:49:22 argv[7] == "-dagman"
04/30/24 13:49:22 argv[8] == "/usr/bin/condor_dagman"
04/30/24 13:49:22 argv[9] == "-AutoRescue"
04/30/24 13:49:22 argv[10] == "1"
04/30/24 13:49:22 argv[11] == "-DoRescueFrom"
04/30/24 13:49:22 argv[12] == "0"
04/30/24 13:49:22 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 13:49:22 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
04/30/24 13:49:23 Workflow batch-id: <140411179.0>
04/30/24 13:49:23 Workflow batch-name: <bbh.dag+140411179>
04/30/24 13:49:23 Workflow accounting_group: <>
04/30/24 13:49:23 Workflow accounting_group_user: <>
04/30/24 13:49:23 Warning: failed to get attribute DAGNodeName
04/30/24 13:49:23 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/30/24 13:49:23 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
04/30/24 13:49:23 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
04/30/24 13:49:23 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
04/30/24 13:49:23 Parsing 1 dagfiles
04/30/24 13:49:23 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
04/30/24 13:49:23 Adjusting edges
04/30/24 13:49:23 Found rescue DAG number 7; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue007 in combination with normal DAG file
04/30/24 13:49:23 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
04/30/24 13:49:23 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue007
04/30/24 13:49:23 Dag contains 5 total jobs
04/30/24 13:49:23 Bootstrapping...
04/30/24 13:49:23 Number of pre-completed nodes: 1
04/30/24 13:49:23 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 13:49:23 DAG status: 0 (DAG_STATUS_OK)
04/30/24 13:49:23 Of 5 nodes total:
04/30/24 13:49:23  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 13:49:23   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 13:49:23     1       0        0       0       1          3        0        0
04/30/24 13:49:23 0 job proc(s) currently held
04/30/24 13:49:23 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
04/30/24 13:49:23 Registering condor_event_timer...
04/30/24 13:49:24 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
04/30/24 13:49:24 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
04/30/24 13:49:24 Masking the events recorded in the DAGMAN workflow log
04/30/24 13:49:24 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
04/30/24 13:49:24 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140411179 -a DAGManJobId=140411179 -batch-name bbh.dag+140411179 -batch-id 140411179.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 13:49:24 From submit: Submitting job(s).
04/30/24 13:49:24 From submit: 1 job(s) submitted to cluster 140411180.
04/30/24 13:49:24 	assigned HTCondor ID (140411180.0.0)
04/30/24 13:49:24 Just submitted 1 job this cycle...
04/30/24 13:49:24 DAG status: 0 (DAG_STATUS_OK)
04/30/24 13:49:24 Of 5 nodes total:
04/30/24 13:49:24  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 13:49:24   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 13:49:24     1       0        1       0       0          3        0        0
04/30/24 13:49:24 0 job proc(s) currently held
04/30/24 13:49:24 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03446006774902344; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03446006774902344; SubmitCycleTimeMin = 0.03446006774902344; SubmitCycleTimeStd = 0.03446006774902344; SubmitCycleTimeSum = 0.03446006774902344; ]
04/30/24 13:49:29 Currently monitoring 1 HTCondor log file(s)
04/30/24 13:49:29 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140411180.0.0) to (140411180.0.0)
04/30/24 13:49:29 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411180.0.0) {04/30/24 13:49:24}
04/30/24 13:49:29 Number of idle job procs: 1
04/30/24 13:49:59 Currently monitoring 1 HTCondor log file(s)
04/30/24 13:49:59 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411180.0.0) {04/30/24 13:49:55}
04/30/24 13:49:59 Number of idle job procs: 0
04/30/24 13:50:09 Currently monitoring 1 HTCondor log file(s)
04/30/24 13:50:09 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140411180.0.0) {04/30/24 13:50:08}
04/30/24 13:50:09 Number of idle job procs: 0
04/30/24 13:50:09 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140411180.0.0) failed with status 1.
04/30/24 13:50:09 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 13:50:09 Of 5 nodes total:
04/30/24 13:50:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 13:50:09   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 13:50:09     1       0        0       0       0          0        1        3
04/30/24 13:50:09 0 job proc(s) currently held
04/30/24 13:50:09 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.003908395767211914; EventCycleTimeCount = 9.0; EventCycleTimeMax = 0.03457283973693848; EventCycleTimeMin = 2.193450927734375E-05; EventCycleTimeStd = 0.01149944450126638; EventCycleTimeSum = 0.03517556190490723; LogProcessCycleTimeAvg = 0.0002073446909586588; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002701282501220703; LogProcessCycleTimeMin = 0.0001728534698486328; LogProcessCycleTimeStd = 5.446042612490904E-05; LogProcessCycleTimeSum = 0.0006220340728759766; SleepCycleTimeAvg = 5.005019929673937; SleepCycleTimeCount = 9.0; SleepCycleTimeMax = 5.005145072937012; SleepCycleTimeMin = 5.004768133163452; SleepCycleTimeStd = 0.0001199447031171907; SleepCycleTimeSum = 45.04517936706543; SubmitCycleTimeAvg = 0.003463125228881836; SubmitCycleTimeCount = 10.0; SubmitCycleTimeMax = 0.03446006774902344; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.01089121594543268; SubmitCycleTimeSum = 0.03463125228881836; ]
04/30/24 13:50:09 ERROR: the following job(s) failed:
04/30/24 13:50:09 ---------------------- Job ----------------------
04/30/24 13:50:09       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
04/30/24 13:50:09            Noop: false
04/30/24 13:50:09          NodeID: 1
04/30/24 13:50:09     Node Status: STATUS_ERROR    
04/30/24 13:50:09 Node return val: 1
04/30/24 13:50:09           Error: Job proc (140411180.0.0) failed with status 1
04/30/24 13:50:09 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
04/30/24 13:50:09  HTCondor Job ID: (140411180.0.0)
04/30/24 13:50:09 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
04/30/24 13:50:09 ---------------------------------------	<END>
04/30/24 13:50:09 Aborting DAG...
04/30/24 13:50:09 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue008...
04/30/24 13:50:09 Removing submitted jobs...
04/30/24 13:50:09 Removing any/all submitted HTCondor jobs...
04/30/24 13:50:09 Running: /usr/bin/condor_rm -const DAGManJobId==140411179 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
04/30/24 13:50:09 Note: 0 total job deferrals because of -MaxJobs limit (12000)
04/30/24 13:50:09 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/30/24 13:50:09 Note: 0 total job deferrals because of node category throttles
04/30/24 13:50:09 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/30/24 13:50:09 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/30/24 13:50:09 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
04/30/24 13:50:09 DAG status: 2 (DAG_STATUS_NODE_FAILED)
04/30/24 13:50:09 Of 5 nodes total:
04/30/24 13:50:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
04/30/24 13:50:09   ===     ===      ===     ===     ===        ===      ===      ===
04/30/24 13:50:09     1       0        0       0       0          0        1        3
04/30/24 13:50:09 0 job proc(s) currently held
04/30/24 13:50:09 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.003908395767211914; EventCycleTimeCount = 9.0; EventCycleTimeMax = 0.03457283973693848; EventCycleTimeMin = 2.193450927734375E-05; EventCycleTimeStd = 0.01149944450126638; EventCycleTimeSum = 0.03517556190490723; LogProcessCycleTimeAvg = 0.0002073446909586588; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002701282501220703; LogProcessCycleTimeMin = 0.0001728534698486328; LogProcessCycleTimeStd = 5.446042612490904E-05; LogProcessCycleTimeSum = 0.0006220340728759766; SleepCycleTimeAvg = 5.005019929673937; SleepCycleTimeCount = 9.0; SleepCycleTimeMax = 5.005145072937012; SleepCycleTimeMin = 5.004768133163452; SleepCycleTimeStd = 0.0001199447031171907; SleepCycleTimeSum = 45.04517936706543; SubmitCycleTimeAvg = 0.003463125228881836; SubmitCycleTimeCount = 10.0; SubmitCycleTimeMax = 0.03446006774902344; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.01089121594543268; SubmitCycleTimeSum = 0.03463125228881836; ]
04/30/24 13:50:09 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
04/30/24 13:50:09 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.003908395767211914; EventCycleTimeCount = 9.0; EventCycleTimeMax = 0.03457283973693848; EventCycleTimeMin = 2.193450927734375E-05; EventCycleTimeStd = 0.01149944450126638; EventCycleTimeSum = 0.03517556190490723; LogProcessCycleTimeAvg = 0.0002073446909586588; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002701282501220703; LogProcessCycleTimeMin = 0.0001728534698486328; LogProcessCycleTimeStd = 5.446042612490904E-05; LogProcessCycleTimeSum = 0.0006220340728759766; SleepCycleTimeAvg = 5.005019929673937; SleepCycleTimeCount = 9.0; SleepCycleTimeMax = 5.005145072937012; SleepCycleTimeMin = 5.004768133163452; SleepCycleTimeStd = 0.0001199447031171907; SleepCycleTimeSum = 45.04517936706543; SubmitCycleTimeAvg = 0.003463125228881836; SubmitCycleTimeCount = 10.0; SubmitCycleTimeMax = 0.03446006774902344; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.01089121594543268; SubmitCycleTimeSum = 0.03463125228881836; ]
04/30/24 13:50:09 **** condor_scheduniv_exec.140411179.0 (condor_DAGMAN) pid 1956931 EXITING WITH STATUS 1
05/01/24 08:33:53 ******************************************************
05/01/24 08:33:53 ** condor_scheduniv_exec.140419821.0 (CONDOR_DAGMAN) STARTING UP
05/01/24 08:33:53 ** /usr/bin/condor_dagman
05/01/24 08:33:53 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/01/24 08:33:53 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/01/24 08:33:53 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/01/24 08:33:53 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/01/24 08:33:53 ** PID = 1558049
05/01/24 08:33:53 ** Log last touched 4/30 13:50:09
05/01/24 08:33:53 ******************************************************
05/01/24 08:33:53 Using config source: /etc/condor/condor_config
05/01/24 08:33:53 Using local config sources: 
05/01/24 08:33:53    /etc/condor/config.d/00-htcondor-9.0.config
05/01/24 08:33:53    /etc/condor/config.d/00-ldas
05/01/24 08:33:53    /etc/condor/config.d/02-scheduler
05/01/24 08:33:53    /etc/condor/config.d/10-security
05/01/24 08:33:53    /etc/condor/config.d/10-stash-plugin.conf
05/01/24 08:33:53    /etc/condor/config.d/15-dagman-default-append-vars
05/01/24 08:33:53    /etc/condor/config.d/30-scratch-mount
05/01/24 08:33:53    /etc/condor/config.d/40-vault-credmon.conf
05/01/24 08:33:53    /etc/condor/config.d/50-transfer-limits
05/01/24 08:33:53    /etc/condor/config.d/65-system-periodic-hold
05/01/24 08:33:53    /etc/condor/config.d/93-dagman-use-direct
05/01/24 08:33:53    /etc/condor/config.d/99-memory
05/01/24 08:33:53    /etc/condor/config.d/99-request-disk
05/01/24 08:33:53    /etc/condor/config.d/99-request-missing-units
05/01/24 08:33:53    /etc/condor/config.d/99-shared-port-descriptor
05/01/24 08:33:53    /etc/condor/config.d/99-transform
05/01/24 08:33:53    /etc/condor/condor_config.local
05/01/24 08:33:53 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/01/24 08:33:53 CLASSAD_CACHING is ENABLED
05/01/24 08:33:53 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/01/24 08:33:53 DaemonCore: No command port requested.
05/01/24 08:33:53 DAGMAN_USE_STRICT setting: 1
05/01/24 08:33:53 DAGMAN_VERBOSITY setting: 3
05/01/24 08:33:53 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/01/24 08:33:53 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/01/24 08:33:53 DAGMAN_SUBMIT_DELAY setting: 0
05/01/24 08:33:53 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/01/24 08:33:53 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/01/24 08:33:53 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/01/24 08:33:53 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/01/24 08:33:53 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/01/24 08:33:53 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/01/24 08:33:53 DAGMAN_DEFAULT_PRIORITY setting: 0
05/01/24 08:33:53 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/01/24 08:33:53 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/01/24 08:33:53 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/01/24 08:33:53 DAGMAN_RETRY_NODE_FIRST setting: False
05/01/24 08:33:53 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/01/24 08:33:53 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/01/24 08:33:53 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/01/24 08:33:53 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/01/24 08:33:53 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/01/24 08:33:53 DAGMAN_MUNGE_NODE_NAMES setting: True
05/01/24 08:33:53 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/01/24 08:33:53 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/01/24 08:33:53 DAGMAN_ALWAYS_RUN_POST setting: False
05/01/24 08:33:53 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/01/24 08:33:53 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/01/24 08:33:53 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/01/24 08:33:53 DAGMAN_ABORT_DUPLICATES setting: True
05/01/24 08:33:53 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/01/24 08:33:53 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/01/24 08:33:53 DAGMAN_AUTO_RESCUE setting: True
05/01/24 08:33:53 DAGMAN_MAX_RESCUE_NUM setting: 100
05/01/24 08:33:53 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/01/24 08:33:53 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/01/24 08:33:53 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/01/24 08:33:53 DAGMAN_MAX_JOB_HOLDS setting: 100
05/01/24 08:33:53 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/01/24 08:33:53 ALL_DEBUG setting: 
05/01/24 08:33:53 DAGMAN_DEBUG setting: 
05/01/24 08:33:53 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/01/24 08:33:53 DAGMAN_REMOVE_NODE_JOBS setting: True
05/01/24 08:33:53 DAGMAN will adjust edges after parsing
05/01/24 08:33:53 Enabling log line cache for increased NFS performance.
05/01/24 08:33:53 argv[0] == "condor_scheduniv_exec.140419821.0"
05/01/24 08:33:53 argv[1] == "-Lockfile"
05/01/24 08:33:53 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/01/24 08:33:53 argv[3] == "-Dag"
05/01/24 08:33:53 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/01/24 08:33:53 argv[5] == "-CsdVersion"
05/01/24 08:33:53 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/01/24 08:33:53 argv[7] == "-dagman"
05/01/24 08:33:53 argv[8] == "/usr/bin/condor_dagman"
05/01/24 08:33:53 argv[9] == "-AutoRescue"
05/01/24 08:33:53 argv[10] == "1"
05/01/24 08:33:53 argv[11] == "-DoRescueFrom"
05/01/24 08:33:53 argv[12] == "0"
05/01/24 08:33:53 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:33:53 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:33:54 Workflow batch-id: <140419821.0>
05/01/24 08:33:54 Workflow batch-name: <bbh.dag+140419821>
05/01/24 08:33:54 Workflow accounting_group: <>
05/01/24 08:33:54 Workflow accounting_group_user: <>
05/01/24 08:33:54 Warning: failed to get attribute DAGNodeName
05/01/24 08:33:54 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/01/24 08:33:54 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/01/24 08:33:54 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/01/24 08:33:54 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/01/24 08:33:54 Parsing 1 dagfiles
05/01/24 08:33:54 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/01/24 08:33:54 Adjusting edges
05/01/24 08:33:54 Found rescue DAG number 8; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue008 in combination with normal DAG file
05/01/24 08:33:54 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/01/24 08:33:54 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue008
05/01/24 08:33:54 Dag contains 5 total jobs
05/01/24 08:33:54 Bootstrapping...
05/01/24 08:33:54 Number of pre-completed nodes: 1
05/01/24 08:33:54 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:33:54 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:33:54 Of 5 nodes total:
05/01/24 08:33:54  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:33:54   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:33:54     1       0        0       0       1          3        0        0
05/01/24 08:33:54 0 job proc(s) currently held
05/01/24 08:33:54 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/01/24 08:33:54 Registering condor_event_timer...
05/01/24 08:33:55 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
05/01/24 08:33:55 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:33:55 Masking the events recorded in the DAGMAN workflow log
05/01/24 08:33:55 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 08:33:55 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140419821 -a DAGManJobId=140419821 -batch-name bbh.dag+140419821 -batch-id 140419821.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:33:55 From submit: Submitting job(s).
05/01/24 08:33:55 From submit: 1 job(s) submitted to cluster 140419822.
05/01/24 08:33:55 	assigned HTCondor ID (140419822.0.0)
05/01/24 08:33:55 Just submitted 1 job this cycle...
05/01/24 08:33:55 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:33:55 Of 5 nodes total:
05/01/24 08:33:55  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:33:55   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:33:55     1       0        1       0       0          3        0        0
05/01/24 08:33:55 0 job proc(s) currently held
05/01/24 08:33:55 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.05429291725158691; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.05429291725158691; SubmitCycleTimeMin = 0.05429291725158691; SubmitCycleTimeStd = 0.05429291725158691; SubmitCycleTimeSum = 0.05429291725158691; ]
05/01/24 08:34:00 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:34:00 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140419822.0.0) to (140419822.0.0)
05/01/24 08:34:00 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419822.0.0) {05/01/24 08:33:55}
05/01/24 08:34:00 Number of idle job procs: 1
05/01/24 08:35:20 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:35:20 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419822.0.0) {05/01/24 08:35:19}
05/01/24 08:35:20 Number of idle job procs: 0
05/01/24 08:35:35 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:35:35 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419822.0.0) {05/01/24 08:35:32}
05/01/24 08:35:35 Number of idle job procs: 0
05/01/24 08:35:35 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140419822.0.0) failed with status 1.
05/01/24 08:35:35 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:35:35 Of 5 nodes total:
05/01/24 08:35:35  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:35:35   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:35:35     1       0        0       0       0          0        1        3
05/01/24 08:35:35 0 job proc(s) currently held
05/01/24 08:35:35 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002796018123626709; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.05441093444824219; EventCycleTimeMin = 3.409385681152344E-05; EventCycleTimeStd = 0.01214929875679466; EventCycleTimeSum = 0.05592036247253418; LogProcessCycleTimeAvg = 0.00022125244140625; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002870559692382812; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 5.777999373946813E-05; LogProcessCycleTimeSum = 0.00066375732421875; SleepCycleTimeAvg = 5.005098676681518; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006322860717773; SleepCycleTimeMin = 5.004580020904541; SleepCycleTimeStd = 0.0003197241149132345; SleepCycleTimeSum = 100.1019735336304; SubmitCycleTimeAvg = 0.002615088508242653; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.05429291725158691; SubmitCycleTimeMin = 1.811981201171875E-05; SubmitCycleTimeStd = 0.01184093598714797; SubmitCycleTimeSum = 0.0549168586730957; ]
05/01/24 08:35:35 ERROR: the following job(s) failed:
05/01/24 08:35:35 ---------------------- Job ----------------------
05/01/24 08:35:35       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
05/01/24 08:35:35            Noop: false
05/01/24 08:35:35          NodeID: 1
05/01/24 08:35:35     Node Status: STATUS_ERROR    
05/01/24 08:35:35 Node return val: 1
05/01/24 08:35:35           Error: Job proc (140419822.0.0) failed with status 1
05/01/24 08:35:35 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:35:35  HTCondor Job ID: (140419822.0.0)
05/01/24 08:35:35 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
05/01/24 08:35:35 ---------------------------------------	<END>
05/01/24 08:35:35 Aborting DAG...
05/01/24 08:35:35 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue009...
05/01/24 08:35:35 Removing submitted jobs...
05/01/24 08:35:35 Removing any/all submitted HTCondor jobs...
05/01/24 08:35:35 Running: /usr/bin/condor_rm -const DAGManJobId==140419821 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
05/01/24 08:35:35 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/01/24 08:35:35 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/01/24 08:35:35 Note: 0 total job deferrals because of node category throttles
05/01/24 08:35:35 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/01/24 08:35:35 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/01/24 08:35:35 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/01/24 08:35:35 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:35:35 Of 5 nodes total:
05/01/24 08:35:35  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:35:35   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:35:35     1       0        0       0       0          0        1        3
05/01/24 08:35:35 0 job proc(s) currently held
05/01/24 08:35:35 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002796018123626709; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.05441093444824219; EventCycleTimeMin = 3.409385681152344E-05; EventCycleTimeStd = 0.01214929875679466; EventCycleTimeSum = 0.05592036247253418; LogProcessCycleTimeAvg = 0.00022125244140625; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002870559692382812; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 5.777999373946813E-05; LogProcessCycleTimeSum = 0.00066375732421875; SleepCycleTimeAvg = 5.005098676681518; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006322860717773; SleepCycleTimeMin = 5.004580020904541; SleepCycleTimeStd = 0.0003197241149132345; SleepCycleTimeSum = 100.1019735336304; SubmitCycleTimeAvg = 0.002615088508242653; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.05429291725158691; SubmitCycleTimeMin = 1.811981201171875E-05; SubmitCycleTimeStd = 0.01184093598714797; SubmitCycleTimeSum = 0.0549168586730957; ]
05/01/24 08:35:35 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/01/24 08:35:35 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002796018123626709; EventCycleTimeCount = 20.0; EventCycleTimeMax = 0.05441093444824219; EventCycleTimeMin = 3.409385681152344E-05; EventCycleTimeStd = 0.01214929875679466; EventCycleTimeSum = 0.05592036247253418; LogProcessCycleTimeAvg = 0.00022125244140625; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002870559692382812; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 5.777999373946813E-05; LogProcessCycleTimeSum = 0.00066375732421875; SleepCycleTimeAvg = 5.005098676681518; SleepCycleTimeCount = 20.0; SleepCycleTimeMax = 5.006322860717773; SleepCycleTimeMin = 5.004580020904541; SleepCycleTimeStd = 0.0003197241149132345; SleepCycleTimeSum = 100.1019735336304; SubmitCycleTimeAvg = 0.002615088508242653; SubmitCycleTimeCount = 21.0; SubmitCycleTimeMax = 0.05429291725158691; SubmitCycleTimeMin = 1.811981201171875E-05; SubmitCycleTimeStd = 0.01184093598714797; SubmitCycleTimeSum = 0.0549168586730957; ]
05/01/24 08:35:35 **** condor_scheduniv_exec.140419821.0 (condor_DAGMAN) pid 1558049 EXITING WITH STATUS 1
05/01/24 08:40:15 ******************************************************
05/01/24 08:40:15 ** condor_scheduniv_exec.140419823.0 (CONDOR_DAGMAN) STARTING UP
05/01/24 08:40:15 ** /usr/bin/condor_dagman
05/01/24 08:40:15 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/01/24 08:40:15 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/01/24 08:40:15 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/01/24 08:40:15 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/01/24 08:40:15 ** PID = 1567516
05/01/24 08:40:15 ** Log last touched 5/1 08:35:35
05/01/24 08:40:15 ******************************************************
05/01/24 08:40:15 Using config source: /etc/condor/condor_config
05/01/24 08:40:15 Using local config sources: 
05/01/24 08:40:15    /etc/condor/config.d/00-htcondor-9.0.config
05/01/24 08:40:15    /etc/condor/config.d/00-ldas
05/01/24 08:40:15    /etc/condor/config.d/02-scheduler
05/01/24 08:40:15    /etc/condor/config.d/10-security
05/01/24 08:40:15    /etc/condor/config.d/10-stash-plugin.conf
05/01/24 08:40:15    /etc/condor/config.d/15-dagman-default-append-vars
05/01/24 08:40:15    /etc/condor/config.d/30-scratch-mount
05/01/24 08:40:15    /etc/condor/config.d/40-vault-credmon.conf
05/01/24 08:40:15    /etc/condor/config.d/50-transfer-limits
05/01/24 08:40:15    /etc/condor/config.d/65-system-periodic-hold
05/01/24 08:40:15    /etc/condor/config.d/93-dagman-use-direct
05/01/24 08:40:15    /etc/condor/config.d/99-memory
05/01/24 08:40:15    /etc/condor/config.d/99-request-disk
05/01/24 08:40:15    /etc/condor/config.d/99-request-missing-units
05/01/24 08:40:15    /etc/condor/config.d/99-shared-port-descriptor
05/01/24 08:40:15    /etc/condor/config.d/99-transform
05/01/24 08:40:15    /etc/condor/condor_config.local
05/01/24 08:40:15 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/01/24 08:40:15 CLASSAD_CACHING is ENABLED
05/01/24 08:40:15 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/01/24 08:40:15 DaemonCore: No command port requested.
05/01/24 08:40:15 DAGMAN_USE_STRICT setting: 1
05/01/24 08:40:15 DAGMAN_VERBOSITY setting: 3
05/01/24 08:40:15 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/01/24 08:40:15 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/01/24 08:40:15 DAGMAN_SUBMIT_DELAY setting: 0
05/01/24 08:40:15 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/01/24 08:40:15 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/01/24 08:40:15 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/01/24 08:40:15 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/01/24 08:40:15 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/01/24 08:40:15 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/01/24 08:40:15 DAGMAN_DEFAULT_PRIORITY setting: 0
05/01/24 08:40:15 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/01/24 08:40:15 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/01/24 08:40:15 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/01/24 08:40:15 DAGMAN_RETRY_NODE_FIRST setting: False
05/01/24 08:40:15 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/01/24 08:40:15 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/01/24 08:40:15 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/01/24 08:40:15 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/01/24 08:40:15 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/01/24 08:40:15 DAGMAN_MUNGE_NODE_NAMES setting: True
05/01/24 08:40:15 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/01/24 08:40:15 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/01/24 08:40:15 DAGMAN_ALWAYS_RUN_POST setting: False
05/01/24 08:40:15 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/01/24 08:40:15 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/01/24 08:40:15 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/01/24 08:40:15 DAGMAN_ABORT_DUPLICATES setting: True
05/01/24 08:40:15 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/01/24 08:40:15 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/01/24 08:40:15 DAGMAN_AUTO_RESCUE setting: True
05/01/24 08:40:15 DAGMAN_MAX_RESCUE_NUM setting: 100
05/01/24 08:40:15 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/01/24 08:40:15 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/01/24 08:40:15 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/01/24 08:40:15 DAGMAN_MAX_JOB_HOLDS setting: 100
05/01/24 08:40:15 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/01/24 08:40:15 ALL_DEBUG setting: 
05/01/24 08:40:15 DAGMAN_DEBUG setting: 
05/01/24 08:40:15 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/01/24 08:40:15 DAGMAN_REMOVE_NODE_JOBS setting: True
05/01/24 08:40:15 DAGMAN will adjust edges after parsing
05/01/24 08:40:15 Enabling log line cache for increased NFS performance.
05/01/24 08:40:15 argv[0] == "condor_scheduniv_exec.140419823.0"
05/01/24 08:40:15 argv[1] == "-Lockfile"
05/01/24 08:40:15 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/01/24 08:40:15 argv[3] == "-Dag"
05/01/24 08:40:15 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/01/24 08:40:15 argv[5] == "-CsdVersion"
05/01/24 08:40:15 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/01/24 08:40:15 argv[7] == "-dagman"
05/01/24 08:40:15 argv[8] == "/usr/bin/condor_dagman"
05/01/24 08:40:15 argv[9] == "-AutoRescue"
05/01/24 08:40:15 argv[10] == "1"
05/01/24 08:40:15 argv[11] == "-DoRescueFrom"
05/01/24 08:40:15 argv[12] == "0"
05/01/24 08:40:15 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:40:15 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:40:15 Workflow batch-id: <140419823.0>
05/01/24 08:40:15 Workflow batch-name: <bbh.dag+140419823>
05/01/24 08:40:15 Workflow accounting_group: <>
05/01/24 08:40:15 Workflow accounting_group_user: <>
05/01/24 08:40:15 Warning: failed to get attribute DAGNodeName
05/01/24 08:40:15 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/01/24 08:40:15 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/01/24 08:40:15 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/01/24 08:40:15 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/01/24 08:40:15 Parsing 1 dagfiles
05/01/24 08:40:15 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/01/24 08:40:15 Adjusting edges
05/01/24 08:40:15 Found rescue DAG number 9; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue009 in combination with normal DAG file
05/01/24 08:40:15 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/01/24 08:40:15 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue009
05/01/24 08:40:15 Dag contains 5 total jobs
05/01/24 08:40:15 Bootstrapping...
05/01/24 08:40:15 Number of pre-completed nodes: 1
05/01/24 08:40:15 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:40:15 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:40:15 Of 5 nodes total:
05/01/24 08:40:15  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:40:15   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:40:15     1       0        0       0       1          3        0        0
05/01/24 08:40:15 0 job proc(s) currently held
05/01/24 08:40:15 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/01/24 08:40:15 Registering condor_event_timer...
05/01/24 08:40:16 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
05/01/24 08:40:16 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:40:16 Masking the events recorded in the DAGMAN workflow log
05/01/24 08:40:16 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 08:40:16 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140419823 -a DAGManJobId=140419823 -batch-name bbh.dag+140419823 -batch-id 140419823.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:40:16 From submit: Submitting job(s).
05/01/24 08:40:16 From submit: 1 job(s) submitted to cluster 140419824.
05/01/24 08:40:16 	assigned HTCondor ID (140419824.0.0)
05/01/24 08:40:16 Just submitted 1 job this cycle...
05/01/24 08:40:16 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:40:16 Of 5 nodes total:
05/01/24 08:40:16  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:40:16   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:40:16     1       0        1       0       0          3        0        0
05/01/24 08:40:16 0 job proc(s) currently held
05/01/24 08:40:16 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03618907928466797; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03618907928466797; SubmitCycleTimeMin = 0.03618907928466797; SubmitCycleTimeStd = 0.03618907928466797; SubmitCycleTimeSum = 0.03618907928466797; ]
05/01/24 08:40:21 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:40:21 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140419824.0.0) to (140419824.0.0)
05/01/24 08:40:21 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419824.0.0) {05/01/24 08:40:16}
05/01/24 08:40:21 Number of idle job procs: 1
05/01/24 08:41:06 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:41:06 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419824.0.0) {05/01/24 08:41:04}
05/01/24 08:41:06 Number of idle job procs: 0
05/01/24 08:42:11 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:42:11 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419824.0.0) {05/01/24 08:42:10}
05/01/24 08:42:11 Number of idle job procs: 0
05/01/24 08:42:11 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140419824.0.0) failed with status 1.
05/01/24 08:42:11 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:42:11 Of 5 nodes total:
05/01/24 08:42:11  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:42:11   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:42:11     1       0        0       0       0          0        1        3
05/01/24 08:42:11 0 job proc(s) currently held
05/01/24 08:42:11 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001701023267663043; EventCycleTimeCount = 23.0; EventCycleTimeMax = 0.03630995750427246; EventCycleTimeMin = 3.695487976074219E-05; EventCycleTimeStd = 0.007547939077970542; EventCycleTimeSum = 0.03912353515625; LogProcessCycleTimeAvg = 0.0002427101135253906; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002789497375488281; LogProcessCycleTimeMin = 0.0002160072326660156; LogProcessCycleTimeStd = 3.253693029257198E-05; LogProcessCycleTimeSum = 0.0007281303405761719; SleepCycleTimeAvg = 5.005035452220751; SleepCycleTimeCount = 23.0; SleepCycleTimeMax = 5.005198955535889; SleepCycleTimeMin = 5.004554986953735; SleepCycleTimeStd = 0.0001372590745912193; SleepCycleTimeSum = 115.1158154010773; SubmitCycleTimeAvg = 0.001577864090601603; SubmitCycleTimeCount = 24.0; SubmitCycleTimeMax = 0.03618907928466797; SubmitCycleTimeMin = 2.09808349609375E-05; SubmitCycleTimeStd = 0.007373888991878495; SubmitCycleTimeSum = 0.03786873817443848; ]
05/01/24 08:42:11 ERROR: the following job(s) failed:
05/01/24 08:42:11 ---------------------- Job ----------------------
05/01/24 08:42:11       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
05/01/24 08:42:11            Noop: false
05/01/24 08:42:11          NodeID: 1
05/01/24 08:42:11     Node Status: STATUS_ERROR    
05/01/24 08:42:11 Node return val: 1
05/01/24 08:42:11           Error: Job proc (140419824.0.0) failed with status 1
05/01/24 08:42:11 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:42:11  HTCondor Job ID: (140419824.0.0)
05/01/24 08:42:11 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0
05/01/24 08:42:11 ---------------------------------------	<END>
05/01/24 08:42:11 Aborting DAG...
05/01/24 08:42:11 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue010...
05/01/24 08:42:11 Removing submitted jobs...
05/01/24 08:42:11 Removing any/all submitted HTCondor jobs...
05/01/24 08:42:11 Running: /usr/bin/condor_rm -const DAGManJobId==140419823 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
05/01/24 08:42:11 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/01/24 08:42:11 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/01/24 08:42:11 Note: 0 total job deferrals because of node category throttles
05/01/24 08:42:11 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/01/24 08:42:11 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/01/24 08:42:11 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/01/24 08:42:11 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:42:11 Of 5 nodes total:
05/01/24 08:42:11  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:42:11   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:42:11     1       0        0       0       0          0        1        3
05/01/24 08:42:11 0 job proc(s) currently held
05/01/24 08:42:11 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001701023267663043; EventCycleTimeCount = 23.0; EventCycleTimeMax = 0.03630995750427246; EventCycleTimeMin = 3.695487976074219E-05; EventCycleTimeStd = 0.007547939077970542; EventCycleTimeSum = 0.03912353515625; LogProcessCycleTimeAvg = 0.0002427101135253906; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002789497375488281; LogProcessCycleTimeMin = 0.0002160072326660156; LogProcessCycleTimeStd = 3.253693029257198E-05; LogProcessCycleTimeSum = 0.0007281303405761719; SleepCycleTimeAvg = 5.005035452220751; SleepCycleTimeCount = 23.0; SleepCycleTimeMax = 5.005198955535889; SleepCycleTimeMin = 5.004554986953735; SleepCycleTimeStd = 0.0001372590745912193; SleepCycleTimeSum = 115.1158154010773; SubmitCycleTimeAvg = 0.001577864090601603; SubmitCycleTimeCount = 24.0; SubmitCycleTimeMax = 0.03618907928466797; SubmitCycleTimeMin = 2.09808349609375E-05; SubmitCycleTimeStd = 0.007373888991878495; SubmitCycleTimeSum = 0.03786873817443848; ]
05/01/24 08:42:11 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/01/24 08:42:11 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001701023267663043; EventCycleTimeCount = 23.0; EventCycleTimeMax = 0.03630995750427246; EventCycleTimeMin = 3.695487976074219E-05; EventCycleTimeStd = 0.007547939077970542; EventCycleTimeSum = 0.03912353515625; LogProcessCycleTimeAvg = 0.0002427101135253906; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002789497375488281; LogProcessCycleTimeMin = 0.0002160072326660156; LogProcessCycleTimeStd = 3.253693029257198E-05; LogProcessCycleTimeSum = 0.0007281303405761719; SleepCycleTimeAvg = 5.005035452220751; SleepCycleTimeCount = 23.0; SleepCycleTimeMax = 5.005198955535889; SleepCycleTimeMin = 5.004554986953735; SleepCycleTimeStd = 0.0001372590745912193; SleepCycleTimeSum = 115.1158154010773; SubmitCycleTimeAvg = 0.001577864090601603; SubmitCycleTimeCount = 24.0; SubmitCycleTimeMax = 0.03618907928466797; SubmitCycleTimeMin = 2.09808349609375E-05; SubmitCycleTimeStd = 0.007373888991878495; SubmitCycleTimeSum = 0.03786873817443848; ]
05/01/24 08:42:11 **** condor_scheduniv_exec.140419823.0 (condor_DAGMAN) pid 1567516 EXITING WITH STATUS 1
05/01/24 08:46:19 ******************************************************
05/01/24 08:46:19 ** condor_scheduniv_exec.140419825.0 (CONDOR_DAGMAN) STARTING UP
05/01/24 08:46:19 ** /usr/bin/condor_dagman
05/01/24 08:46:19 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/01/24 08:46:19 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/01/24 08:46:19 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/01/24 08:46:19 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/01/24 08:46:19 ** PID = 1575925
05/01/24 08:46:19 ** Log last touched 5/1 08:42:12
05/01/24 08:46:19 ******************************************************
05/01/24 08:46:19 Using config source: /etc/condor/condor_config
05/01/24 08:46:19 Using local config sources: 
05/01/24 08:46:19    /etc/condor/config.d/00-htcondor-9.0.config
05/01/24 08:46:19    /etc/condor/config.d/00-ldas
05/01/24 08:46:19    /etc/condor/config.d/02-scheduler
05/01/24 08:46:19    /etc/condor/config.d/10-security
05/01/24 08:46:19    /etc/condor/config.d/10-stash-plugin.conf
05/01/24 08:46:19    /etc/condor/config.d/15-dagman-default-append-vars
05/01/24 08:46:19    /etc/condor/config.d/30-scratch-mount
05/01/24 08:46:19    /etc/condor/config.d/40-vault-credmon.conf
05/01/24 08:46:19    /etc/condor/config.d/50-transfer-limits
05/01/24 08:46:19    /etc/condor/config.d/65-system-periodic-hold
05/01/24 08:46:19    /etc/condor/config.d/93-dagman-use-direct
05/01/24 08:46:19    /etc/condor/config.d/99-memory
05/01/24 08:46:19    /etc/condor/config.d/99-request-disk
05/01/24 08:46:19    /etc/condor/config.d/99-request-missing-units
05/01/24 08:46:19    /etc/condor/config.d/99-shared-port-descriptor
05/01/24 08:46:19    /etc/condor/config.d/99-transform
05/01/24 08:46:19    /etc/condor/condor_config.local
05/01/24 08:46:19 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/01/24 08:46:19 CLASSAD_CACHING is ENABLED
05/01/24 08:46:19 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/01/24 08:46:19 DaemonCore: No command port requested.
05/01/24 08:46:19 DAGMAN_USE_STRICT setting: 1
05/01/24 08:46:19 DAGMAN_VERBOSITY setting: 3
05/01/24 08:46:19 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/01/24 08:46:19 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/01/24 08:46:19 DAGMAN_SUBMIT_DELAY setting: 0
05/01/24 08:46:19 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/01/24 08:46:19 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/01/24 08:46:19 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/01/24 08:46:19 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/01/24 08:46:19 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/01/24 08:46:19 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/01/24 08:46:19 DAGMAN_DEFAULT_PRIORITY setting: 0
05/01/24 08:46:19 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/01/24 08:46:19 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/01/24 08:46:19 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/01/24 08:46:19 DAGMAN_RETRY_NODE_FIRST setting: False
05/01/24 08:46:19 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/01/24 08:46:19 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/01/24 08:46:19 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/01/24 08:46:19 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/01/24 08:46:19 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/01/24 08:46:19 DAGMAN_MUNGE_NODE_NAMES setting: True
05/01/24 08:46:19 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/01/24 08:46:19 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/01/24 08:46:19 DAGMAN_ALWAYS_RUN_POST setting: False
05/01/24 08:46:19 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/01/24 08:46:19 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/01/24 08:46:19 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/01/24 08:46:19 DAGMAN_ABORT_DUPLICATES setting: True
05/01/24 08:46:19 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/01/24 08:46:19 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/01/24 08:46:19 DAGMAN_AUTO_RESCUE setting: True
05/01/24 08:46:19 DAGMAN_MAX_RESCUE_NUM setting: 100
05/01/24 08:46:19 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/01/24 08:46:19 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/01/24 08:46:19 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/01/24 08:46:19 DAGMAN_MAX_JOB_HOLDS setting: 100
05/01/24 08:46:19 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/01/24 08:46:19 ALL_DEBUG setting: 
05/01/24 08:46:19 DAGMAN_DEBUG setting: 
05/01/24 08:46:19 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/01/24 08:46:19 DAGMAN_REMOVE_NODE_JOBS setting: True
05/01/24 08:46:19 DAGMAN will adjust edges after parsing
05/01/24 08:46:19 Enabling log line cache for increased NFS performance.
05/01/24 08:46:19 argv[0] == "condor_scheduniv_exec.140419825.0"
05/01/24 08:46:19 argv[1] == "-Lockfile"
05/01/24 08:46:19 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/01/24 08:46:19 argv[3] == "-Dag"
05/01/24 08:46:19 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/01/24 08:46:19 argv[5] == "-CsdVersion"
05/01/24 08:46:19 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/01/24 08:46:19 argv[7] == "-dagman"
05/01/24 08:46:19 argv[8] == "/usr/bin/condor_dagman"
05/01/24 08:46:19 argv[9] == "-AutoRescue"
05/01/24 08:46:19 argv[10] == "1"
05/01/24 08:46:19 argv[11] == "-DoRescueFrom"
05/01/24 08:46:19 argv[12] == "0"
05/01/24 08:46:19 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:46:19 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:46:19 Workflow batch-id: <140419825.0>
05/01/24 08:46:19 Workflow batch-name: <bbh.dag+140419825>
05/01/24 08:46:19 Workflow accounting_group: <>
05/01/24 08:46:19 Workflow accounting_group_user: <>
05/01/24 08:46:19 Warning: failed to get attribute DAGNodeName
05/01/24 08:46:19 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/01/24 08:46:19 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/01/24 08:46:19 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/01/24 08:46:19 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/01/24 08:46:19 Parsing 1 dagfiles
05/01/24 08:46:19 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/01/24 08:46:19 Adjusting edges
05/01/24 08:46:19 Found rescue DAG number 10; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue010 in combination with normal DAG file
05/01/24 08:46:19 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/01/24 08:46:19 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue010
05/01/24 08:46:19 Dag contains 5 total jobs
05/01/24 08:46:19 Bootstrapping...
05/01/24 08:46:19 Number of pre-completed nodes: 1
05/01/24 08:46:19 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:46:19 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:46:19 Of 5 nodes total:
05/01/24 08:46:19  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:46:19   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:46:19     1       0        0       0       1          3        0        0
05/01/24 08:46:19 0 job proc(s) currently held
05/01/24 08:46:19 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/01/24 08:46:19 Registering condor_event_timer...
05/01/24 08:46:20 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
05/01/24 08:46:20 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:46:20 Masking the events recorded in the DAGMAN workflow log
05/01/24 08:46:20 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 08:46:20 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140419825 -a DAGManJobId=140419825 -batch-name bbh.dag+140419825 -batch-id 140419825.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:46:20 From submit: Submitting job(s).
05/01/24 08:46:20 From submit: 1 job(s) submitted to cluster 140419826.
05/01/24 08:46:20 	assigned HTCondor ID (140419826.0.0)
05/01/24 08:46:20 Just submitted 1 job this cycle...
05/01/24 08:46:20 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:46:20 Of 5 nodes total:
05/01/24 08:46:20  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:46:20   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:46:20     1       0        1       0       0          3        0        0
05/01/24 08:46:20 0 job proc(s) currently held
05/01/24 08:46:20 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03721809387207031; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03721809387207031; SubmitCycleTimeMin = 0.03721809387207031; SubmitCycleTimeStd = 0.03721809387207031; SubmitCycleTimeSum = 0.03721809387207031; ]
05/01/24 08:46:25 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:46:25 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140419826.0.0) to (140419826.0.0)
05/01/24 08:46:25 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419826.0.0) {05/01/24 08:46:20}
05/01/24 08:46:25 Number of idle job procs: 1
05/01/24 08:48:15 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:48:15 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419826.0.0) {05/01/24 08:48:11}
05/01/24 08:48:15 Number of idle job procs: 0
05/01/24 08:48:20 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:48:20 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419826.0.0) {05/01/24 08:48:17}
05/01/24 08:48:20 Number of idle job procs: 0
05/01/24 08:48:20 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140419826.0.0) failed with status 1.
05/01/24 08:48:20 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:48:20 Of 5 nodes total:
05/01/24 08:48:20  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:48:20   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:48:20     1       0        0       0       0          0        1        3
05/01/24 08:48:20 0 job proc(s) currently held
05/01/24 08:48:20 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001626630624135335; EventCycleTimeCount = 24.0; EventCycleTimeMax = 0.0373389720916748; EventCycleTimeMin = 2.598762512207031E-05; EventCycleTimeStd = 0.007607286628478686; EventCycleTimeSum = 0.03903913497924805; LogProcessCycleTimeAvg = 0.0002168814341227213; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002858638763427734; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 5.984749593947778E-05; LogProcessCycleTimeSum = 0.0006506443023681641; SleepCycleTimeAvg = 5.005151202281316; SleepCycleTimeCount = 24.0; SleepCycleTimeMax = 5.006194114685059; SleepCycleTimeMin = 5.004396915435791; SleepCycleTimeStd = 0.0003334808806013267; SleepCycleTimeSum = 120.1236288547516; SubmitCycleTimeAvg = 0.001516866683959961; SubmitCycleTimeCount = 25.0; SubmitCycleTimeMax = 0.03721809387207031; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.00743779649296086; SubmitCycleTimeSum = 0.03792166709899902; ]
05/01/24 08:48:20 ERROR: the following job(s) failed:
05/01/24 08:48:20 ---------------------- Job ----------------------
05/01/24 08:48:20       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
05/01/24 08:48:20            Noop: false
05/01/24 08:48:20          NodeID: 1
05/01/24 08:48:20     Node Status: STATUS_ERROR    
05/01/24 08:48:20 Node return val: 1
05/01/24 08:48:20           Error: Job proc (140419826.0.0) failed with status 1
05/01/24 08:48:20 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:48:20  HTCondor Job ID: (140419826.0.0)
05/01/24 08:48:20 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0
05/01/24 08:48:20 ---------------------------------------	<END>
05/01/24 08:48:20 Aborting DAG...
05/01/24 08:48:20 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue011...
05/01/24 08:48:20 Removing submitted jobs...
05/01/24 08:48:20 Removing any/all submitted HTCondor jobs...
05/01/24 08:48:20 Running: /usr/bin/condor_rm -const DAGManJobId==140419825 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
05/01/24 08:48:20 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/01/24 08:48:20 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/01/24 08:48:20 Note: 0 total job deferrals because of node category throttles
05/01/24 08:48:20 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/01/24 08:48:20 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/01/24 08:48:20 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/01/24 08:48:20 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:48:20 Of 5 nodes total:
05/01/24 08:48:20  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:48:20   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:48:20     1       0        0       0       0          0        1        3
05/01/24 08:48:20 0 job proc(s) currently held
05/01/24 08:48:20 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001626630624135335; EventCycleTimeCount = 24.0; EventCycleTimeMax = 0.0373389720916748; EventCycleTimeMin = 2.598762512207031E-05; EventCycleTimeStd = 0.007607286628478686; EventCycleTimeSum = 0.03903913497924805; LogProcessCycleTimeAvg = 0.0002168814341227213; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002858638763427734; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 5.984749593947778E-05; LogProcessCycleTimeSum = 0.0006506443023681641; SleepCycleTimeAvg = 5.005151202281316; SleepCycleTimeCount = 24.0; SleepCycleTimeMax = 5.006194114685059; SleepCycleTimeMin = 5.004396915435791; SleepCycleTimeStd = 0.0003334808806013267; SleepCycleTimeSum = 120.1236288547516; SubmitCycleTimeAvg = 0.001516866683959961; SubmitCycleTimeCount = 25.0; SubmitCycleTimeMax = 0.03721809387207031; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.00743779649296086; SubmitCycleTimeSum = 0.03792166709899902; ]
05/01/24 08:48:20 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/01/24 08:48:20 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001626630624135335; EventCycleTimeCount = 24.0; EventCycleTimeMax = 0.0373389720916748; EventCycleTimeMin = 2.598762512207031E-05; EventCycleTimeStd = 0.007607286628478686; EventCycleTimeSum = 0.03903913497924805; LogProcessCycleTimeAvg = 0.0002168814341227213; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002858638763427734; LogProcessCycleTimeMin = 0.0001788139343261719; LogProcessCycleTimeStd = 5.984749593947778E-05; LogProcessCycleTimeSum = 0.0006506443023681641; SleepCycleTimeAvg = 5.005151202281316; SleepCycleTimeCount = 24.0; SleepCycleTimeMax = 5.006194114685059; SleepCycleTimeMin = 5.004396915435791; SleepCycleTimeStd = 0.0003334808806013267; SleepCycleTimeSum = 120.1236288547516; SubmitCycleTimeAvg = 0.001516866683959961; SubmitCycleTimeCount = 25.0; SubmitCycleTimeMax = 0.03721809387207031; SubmitCycleTimeMin = 1.406669616699219E-05; SubmitCycleTimeStd = 0.00743779649296086; SubmitCycleTimeSum = 0.03792166709899902; ]
05/01/24 08:48:20 **** condor_scheduniv_exec.140419825.0 (condor_DAGMAN) pid 1575925 EXITING WITH STATUS 1
05/01/24 08:54:36 ******************************************************
05/01/24 08:54:36 ** condor_scheduniv_exec.140419829.0 (CONDOR_DAGMAN) STARTING UP
05/01/24 08:54:36 ** /usr/bin/condor_dagman
05/01/24 08:54:36 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/01/24 08:54:36 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/01/24 08:54:36 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/01/24 08:54:36 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/01/24 08:54:36 ** PID = 1590391
05/01/24 08:54:36 ** Log last touched 5/1 08:48:20
05/01/24 08:54:36 ******************************************************
05/01/24 08:54:36 Using config source: /etc/condor/condor_config
05/01/24 08:54:36 Using local config sources: 
05/01/24 08:54:36    /etc/condor/config.d/00-htcondor-9.0.config
05/01/24 08:54:36    /etc/condor/config.d/00-ldas
05/01/24 08:54:36    /etc/condor/config.d/02-scheduler
05/01/24 08:54:36    /etc/condor/config.d/10-security
05/01/24 08:54:36    /etc/condor/config.d/10-stash-plugin.conf
05/01/24 08:54:36    /etc/condor/config.d/15-dagman-default-append-vars
05/01/24 08:54:36    /etc/condor/config.d/30-scratch-mount
05/01/24 08:54:36    /etc/condor/config.d/40-vault-credmon.conf
05/01/24 08:54:36    /etc/condor/config.d/50-transfer-limits
05/01/24 08:54:36    /etc/condor/config.d/65-system-periodic-hold
05/01/24 08:54:36    /etc/condor/config.d/93-dagman-use-direct
05/01/24 08:54:36    /etc/condor/config.d/99-memory
05/01/24 08:54:36    /etc/condor/config.d/99-request-disk
05/01/24 08:54:36    /etc/condor/config.d/99-request-missing-units
05/01/24 08:54:36    /etc/condor/config.d/99-shared-port-descriptor
05/01/24 08:54:36    /etc/condor/config.d/99-transform
05/01/24 08:54:36    /etc/condor/condor_config.local
05/01/24 08:54:36 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/01/24 08:54:36 CLASSAD_CACHING is ENABLED
05/01/24 08:54:36 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/01/24 08:54:36 DaemonCore: No command port requested.
05/01/24 08:54:36 DAGMAN_USE_STRICT setting: 1
05/01/24 08:54:36 DAGMAN_VERBOSITY setting: 3
05/01/24 08:54:36 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/01/24 08:54:36 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/01/24 08:54:36 DAGMAN_SUBMIT_DELAY setting: 0
05/01/24 08:54:36 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/01/24 08:54:36 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/01/24 08:54:36 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/01/24 08:54:36 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/01/24 08:54:36 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/01/24 08:54:36 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/01/24 08:54:36 DAGMAN_DEFAULT_PRIORITY setting: 0
05/01/24 08:54:36 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/01/24 08:54:36 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/01/24 08:54:36 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/01/24 08:54:36 DAGMAN_RETRY_NODE_FIRST setting: False
05/01/24 08:54:36 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/01/24 08:54:36 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/01/24 08:54:36 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/01/24 08:54:36 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/01/24 08:54:36 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/01/24 08:54:36 DAGMAN_MUNGE_NODE_NAMES setting: True
05/01/24 08:54:36 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/01/24 08:54:36 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/01/24 08:54:36 DAGMAN_ALWAYS_RUN_POST setting: False
05/01/24 08:54:36 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/01/24 08:54:36 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/01/24 08:54:36 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/01/24 08:54:36 DAGMAN_ABORT_DUPLICATES setting: True
05/01/24 08:54:36 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/01/24 08:54:36 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/01/24 08:54:36 DAGMAN_AUTO_RESCUE setting: True
05/01/24 08:54:36 DAGMAN_MAX_RESCUE_NUM setting: 100
05/01/24 08:54:36 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/01/24 08:54:36 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/01/24 08:54:36 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/01/24 08:54:36 DAGMAN_MAX_JOB_HOLDS setting: 100
05/01/24 08:54:36 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/01/24 08:54:36 ALL_DEBUG setting: 
05/01/24 08:54:36 DAGMAN_DEBUG setting: 
05/01/24 08:54:36 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/01/24 08:54:36 DAGMAN_REMOVE_NODE_JOBS setting: True
05/01/24 08:54:36 DAGMAN will adjust edges after parsing
05/01/24 08:54:36 Enabling log line cache for increased NFS performance.
05/01/24 08:54:36 argv[0] == "condor_scheduniv_exec.140419829.0"
05/01/24 08:54:36 argv[1] == "-Lockfile"
05/01/24 08:54:36 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/01/24 08:54:36 argv[3] == "-Dag"
05/01/24 08:54:36 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/01/24 08:54:36 argv[5] == "-CsdVersion"
05/01/24 08:54:36 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/01/24 08:54:36 argv[7] == "-dagman"
05/01/24 08:54:36 argv[8] == "/usr/bin/condor_dagman"
05/01/24 08:54:36 argv[9] == "-AutoRescue"
05/01/24 08:54:36 argv[10] == "1"
05/01/24 08:54:36 argv[11] == "-DoRescueFrom"
05/01/24 08:54:36 argv[12] == "0"
05/01/24 08:54:36 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:54:36 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 08:54:36 Workflow batch-id: <140419829.0>
05/01/24 08:54:36 Workflow batch-name: <bbh.dag+140419829>
05/01/24 08:54:36 Workflow accounting_group: <>
05/01/24 08:54:36 Workflow accounting_group_user: <>
05/01/24 08:54:36 Warning: failed to get attribute DAGNodeName
05/01/24 08:54:36 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/01/24 08:54:36 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/01/24 08:54:36 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/01/24 08:54:36 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/01/24 08:54:36 Parsing 1 dagfiles
05/01/24 08:54:36 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/01/24 08:54:36 Adjusting edges
05/01/24 08:54:36 Found rescue DAG number 11; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue011 in combination with normal DAG file
05/01/24 08:54:36 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/01/24 08:54:36 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue011
05/01/24 08:54:36 Dag contains 5 total jobs
05/01/24 08:54:36 Bootstrapping...
05/01/24 08:54:36 Number of pre-completed nodes: 1
05/01/24 08:54:36 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:54:36 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:54:36 Of 5 nodes total:
05/01/24 08:54:36  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:54:36   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:54:36     1       0        0       0       1          3        0        0
05/01/24 08:54:36 0 job proc(s) currently held
05/01/24 08:54:36 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/01/24 08:54:36 Registering condor_event_timer...
05/01/24 08:54:37 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
05/01/24 08:54:37 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 08:54:37 Masking the events recorded in the DAGMAN workflow log
05/01/24 08:54:37 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 08:54:37 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140419829 -a DAGManJobId=140419829 -batch-name bbh.dag+140419829 -batch-id 140419829.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:54:37 From submit: Submitting job(s).
05/01/24 08:54:37 From submit: 1 job(s) submitted to cluster 140419830.
05/01/24 08:54:37 	assigned HTCondor ID (140419830.0.0)
05/01/24 08:54:37 Just submitted 1 job this cycle...
05/01/24 08:54:37 DAG status: 0 (DAG_STATUS_OK)
05/01/24 08:54:37 Of 5 nodes total:
05/01/24 08:54:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:54:37   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:54:37     1       0        1       0       0          3        0        0
05/01/24 08:54:37 0 job proc(s) currently held
05/01/24 08:54:37 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03832817077636719; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03832817077636719; SubmitCycleTimeMin = 0.03832817077636719; SubmitCycleTimeStd = 0.03832817077636719; SubmitCycleTimeSum = 0.03832817077636719; ]
05/01/24 08:54:42 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:54:42 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140419830.0.0) to (140419830.0.0)
05/01/24 08:54:42 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419830.0.0) {05/01/24 08:54:37}
05/01/24 08:54:42 Number of idle job procs: 1
05/01/24 08:55:52 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:55:52 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419830.0.0) {05/01/24 08:55:49}
05/01/24 08:55:52 Number of idle job procs: 0
05/01/24 08:56:12 Currently monitoring 1 HTCondor log file(s)
05/01/24 08:56:12 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140419830.0.0) {05/01/24 08:56:11}
05/01/24 08:56:12 Number of idle job procs: 0
05/01/24 08:56:12 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140419830.0.0) failed with status 1.
05/01/24 08:56:12 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:56:12 Of 5 nodes total:
05/01/24 08:56:12  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:56:12   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:56:12     1       0        0       0       0          0        1        3
05/01/24 08:56:12 0 job proc(s) currently held
05/01/24 08:56:12 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002107168498792146; EventCycleTimeCount = 19.0; EventCycleTimeMax = 0.0384519100189209; EventCycleTimeMin = 2.312660217285156E-05; EventCycleTimeStd = 0.008801835927489175; EventCycleTimeSum = 0.04003620147705078; LogProcessCycleTimeAvg = 0.0002203782399495443; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002739429473876953; LogProcessCycleTimeMin = 0.0001771450042724609; LogProcessCycleTimeStd = 4.921905047232563E-05; LogProcessCycleTimeSum = 0.0006611347198486328; SleepCycleTimeAvg = 5.005104980970684; SleepCycleTimeCount = 19.0; SleepCycleTimeMax = 5.005895853042603; SleepCycleTimeMin = 5.004419088363647; SleepCycleTimeStd = 0.000251214369481656; SleepCycleTimeSum = 95.09699463844299; SubmitCycleTimeAvg = 0.001955509185791016; SubmitCycleTimeCount = 20.0; SubmitCycleTimeMax = 0.03832817077636719; SubmitCycleTimeMin = 1.192092895507812E-05; SubmitCycleTimeStd = 0.008561470235586953; SubmitCycleTimeSum = 0.03911018371582031; ]
05/01/24 08:56:12 ERROR: the following job(s) failed:
05/01/24 08:56:12 ---------------------- Job ----------------------
05/01/24 08:56:12       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
05/01/24 08:56:12            Noop: false
05/01/24 08:56:12          NodeID: 1
05/01/24 08:56:12     Node Status: STATUS_ERROR    
05/01/24 08:56:12 Node return val: 1
05/01/24 08:56:12           Error: Job proc (140419830.0.0) failed with status 1
05/01/24 08:56:12 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 08:56:12  HTCondor Job ID: (140419830.0.0)
05/01/24 08:56:12 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0
05/01/24 08:56:12 ---------------------------------------	<END>
05/01/24 08:56:12 Aborting DAG...
05/01/24 08:56:12 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue012...
05/01/24 08:56:12 Removing submitted jobs...
05/01/24 08:56:12 Removing any/all submitted HTCondor jobs...
05/01/24 08:56:12 Running: /usr/bin/condor_rm -const DAGManJobId==140419829 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
05/01/24 08:56:12 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/01/24 08:56:12 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/01/24 08:56:12 Note: 0 total job deferrals because of node category throttles
05/01/24 08:56:12 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/01/24 08:56:12 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/01/24 08:56:12 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/01/24 08:56:12 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 08:56:12 Of 5 nodes total:
05/01/24 08:56:12  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 08:56:12   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 08:56:12     1       0        0       0       0          0        1        3
05/01/24 08:56:12 0 job proc(s) currently held
05/01/24 08:56:12 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002107168498792146; EventCycleTimeCount = 19.0; EventCycleTimeMax = 0.0384519100189209; EventCycleTimeMin = 2.312660217285156E-05; EventCycleTimeStd = 0.008801835927489175; EventCycleTimeSum = 0.04003620147705078; LogProcessCycleTimeAvg = 0.0002203782399495443; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002739429473876953; LogProcessCycleTimeMin = 0.0001771450042724609; LogProcessCycleTimeStd = 4.921905047232563E-05; LogProcessCycleTimeSum = 0.0006611347198486328; SleepCycleTimeAvg = 5.005104980970684; SleepCycleTimeCount = 19.0; SleepCycleTimeMax = 5.005895853042603; SleepCycleTimeMin = 5.004419088363647; SleepCycleTimeStd = 0.000251214369481656; SleepCycleTimeSum = 95.09699463844299; SubmitCycleTimeAvg = 0.001955509185791016; SubmitCycleTimeCount = 20.0; SubmitCycleTimeMax = 0.03832817077636719; SubmitCycleTimeMin = 1.192092895507812E-05; SubmitCycleTimeStd = 0.008561470235586953; SubmitCycleTimeSum = 0.03911018371582031; ]
05/01/24 08:56:12 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/01/24 08:56:12 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002107168498792146; EventCycleTimeCount = 19.0; EventCycleTimeMax = 0.0384519100189209; EventCycleTimeMin = 2.312660217285156E-05; EventCycleTimeStd = 0.008801835927489175; EventCycleTimeSum = 0.04003620147705078; LogProcessCycleTimeAvg = 0.0002203782399495443; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002739429473876953; LogProcessCycleTimeMin = 0.0001771450042724609; LogProcessCycleTimeStd = 4.921905047232563E-05; LogProcessCycleTimeSum = 0.0006611347198486328; SleepCycleTimeAvg = 5.005104980970684; SleepCycleTimeCount = 19.0; SleepCycleTimeMax = 5.005895853042603; SleepCycleTimeMin = 5.004419088363647; SleepCycleTimeStd = 0.000251214369481656; SleepCycleTimeSum = 95.09699463844299; SubmitCycleTimeAvg = 0.001955509185791016; SubmitCycleTimeCount = 20.0; SubmitCycleTimeMax = 0.03832817077636719; SubmitCycleTimeMin = 1.192092895507812E-05; SubmitCycleTimeStd = 0.008561470235586953; SubmitCycleTimeSum = 0.03911018371582031; ]
05/01/24 08:56:12 **** condor_scheduniv_exec.140419829.0 (condor_DAGMAN) pid 1590391 EXITING WITH STATUS 1
05/01/24 12:01:34 ******************************************************
05/01/24 12:01:34 ** condor_scheduniv_exec.140421626.0 (CONDOR_DAGMAN) STARTING UP
05/01/24 12:01:34 ** /usr/bin/condor_dagman
05/01/24 12:01:34 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/01/24 12:01:34 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/01/24 12:01:34 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/01/24 12:01:34 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/01/24 12:01:34 ** PID = 1928623
05/01/24 12:01:34 ** Log last touched 5/1 08:56:12
05/01/24 12:01:34 ******************************************************
05/01/24 12:01:34 Using config source: /etc/condor/condor_config
05/01/24 12:01:34 Using local config sources: 
05/01/24 12:01:34    /etc/condor/config.d/00-htcondor-9.0.config
05/01/24 12:01:34    /etc/condor/config.d/00-ldas
05/01/24 12:01:34    /etc/condor/config.d/02-scheduler
05/01/24 12:01:34    /etc/condor/config.d/10-security
05/01/24 12:01:34    /etc/condor/config.d/10-stash-plugin.conf
05/01/24 12:01:34    /etc/condor/config.d/15-dagman-default-append-vars
05/01/24 12:01:34    /etc/condor/config.d/30-scratch-mount
05/01/24 12:01:34    /etc/condor/config.d/40-vault-credmon.conf
05/01/24 12:01:34    /etc/condor/config.d/50-transfer-limits
05/01/24 12:01:34    /etc/condor/config.d/65-system-periodic-hold
05/01/24 12:01:34    /etc/condor/config.d/93-dagman-use-direct
05/01/24 12:01:34    /etc/condor/config.d/99-memory
05/01/24 12:01:34    /etc/condor/config.d/99-request-disk
05/01/24 12:01:34    /etc/condor/config.d/99-request-missing-units
05/01/24 12:01:34    /etc/condor/config.d/99-shared-port-descriptor
05/01/24 12:01:34    /etc/condor/config.d/99-transform
05/01/24 12:01:34    /etc/condor/condor_config.local
05/01/24 12:01:34 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/01/24 12:01:34 CLASSAD_CACHING is ENABLED
05/01/24 12:01:34 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/01/24 12:01:34 DaemonCore: No command port requested.
05/01/24 12:01:34 DAGMAN_USE_STRICT setting: 1
05/01/24 12:01:34 DAGMAN_VERBOSITY setting: 3
05/01/24 12:01:34 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/01/24 12:01:34 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/01/24 12:01:34 DAGMAN_SUBMIT_DELAY setting: 0
05/01/24 12:01:34 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/01/24 12:01:34 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/01/24 12:01:34 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/01/24 12:01:34 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/01/24 12:01:34 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/01/24 12:01:34 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/01/24 12:01:34 DAGMAN_DEFAULT_PRIORITY setting: 0
05/01/24 12:01:34 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/01/24 12:01:34 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/01/24 12:01:34 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/01/24 12:01:34 DAGMAN_RETRY_NODE_FIRST setting: False
05/01/24 12:01:34 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/01/24 12:01:34 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/01/24 12:01:34 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/01/24 12:01:34 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/01/24 12:01:34 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/01/24 12:01:34 DAGMAN_MUNGE_NODE_NAMES setting: True
05/01/24 12:01:34 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/01/24 12:01:34 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/01/24 12:01:34 DAGMAN_ALWAYS_RUN_POST setting: False
05/01/24 12:01:34 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/01/24 12:01:34 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/01/24 12:01:34 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/01/24 12:01:34 DAGMAN_ABORT_DUPLICATES setting: True
05/01/24 12:01:34 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/01/24 12:01:34 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/01/24 12:01:34 DAGMAN_AUTO_RESCUE setting: True
05/01/24 12:01:34 DAGMAN_MAX_RESCUE_NUM setting: 100
05/01/24 12:01:34 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/01/24 12:01:34 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/01/24 12:01:34 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/01/24 12:01:34 DAGMAN_MAX_JOB_HOLDS setting: 100
05/01/24 12:01:34 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/01/24 12:01:34 ALL_DEBUG setting: 
05/01/24 12:01:34 DAGMAN_DEBUG setting: 
05/01/24 12:01:34 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/01/24 12:01:34 DAGMAN_REMOVE_NODE_JOBS setting: True
05/01/24 12:01:34 DAGMAN will adjust edges after parsing
05/01/24 12:01:34 Enabling log line cache for increased NFS performance.
05/01/24 12:01:34 argv[0] == "condor_scheduniv_exec.140421626.0"
05/01/24 12:01:34 argv[1] == "-Lockfile"
05/01/24 12:01:34 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/01/24 12:01:34 argv[3] == "-Dag"
05/01/24 12:01:34 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/01/24 12:01:34 argv[5] == "-CsdVersion"
05/01/24 12:01:34 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/01/24 12:01:34 argv[7] == "-dagman"
05/01/24 12:01:34 argv[8] == "/usr/bin/condor_dagman"
05/01/24 12:01:34 argv[9] == "-AutoRescue"
05/01/24 12:01:34 argv[10] == "1"
05/01/24 12:01:34 argv[11] == "-DoRescueFrom"
05/01/24 12:01:34 argv[12] == "0"
05/01/24 12:01:34 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 12:01:34 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 12:01:34 Workflow batch-id: <140421626.0>
05/01/24 12:01:34 Workflow batch-name: <bbh.dag+140421626>
05/01/24 12:01:34 Workflow accounting_group: <>
05/01/24 12:01:34 Workflow accounting_group_user: <>
05/01/24 12:01:34 Warning: failed to get attribute DAGNodeName
05/01/24 12:01:34 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/01/24 12:01:34 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/01/24 12:01:34 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/01/24 12:01:34 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/01/24 12:01:34 Parsing 1 dagfiles
05/01/24 12:01:34 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/01/24 12:01:34 Adjusting edges
05/01/24 12:01:34 Found rescue DAG number 12; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue012 in combination with normal DAG file
05/01/24 12:01:34 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/01/24 12:01:34 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue012
05/01/24 12:01:34 Dag contains 5 total jobs
05/01/24 12:01:34 Bootstrapping...
05/01/24 12:01:34 Number of pre-completed nodes: 1
05/01/24 12:01:34 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:01:34 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:01:34 Of 5 nodes total:
05/01/24 12:01:34  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:01:34   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:01:34     1       0        0       0       1          3        0        0
05/01/24 12:01:34 0 job proc(s) currently held
05/01/24 12:01:34 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/01/24 12:01:34 Registering condor_event_timer...
05/01/24 12:01:35 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
05/01/24 12:01:35 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:01:35 Masking the events recorded in the DAGMAN workflow log
05/01/24 12:01:35 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 12:01:35 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140421626 -a DAGManJobId=140421626 -batch-name bbh.dag+140421626 -batch-id 140421626.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 12:01:36 From submit: Submitting job(s).
05/01/24 12:01:36 From submit: 1 job(s) submitted to cluster 140421627.
05/01/24 12:01:36 	assigned HTCondor ID (140421627.0.0)
05/01/24 12:01:36 Just submitted 1 job this cycle...
05/01/24 12:01:36 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:01:36 Of 5 nodes total:
05/01/24 12:01:36  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:01:36   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:01:36     1       0        1       0       0          3        0        0
05/01/24 12:01:36 0 job proc(s) currently held
05/01/24 12:01:36 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.05603909492492676; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.05603909492492676; SubmitCycleTimeMin = 0.05603909492492676; SubmitCycleTimeStd = 0.05603909492492676; SubmitCycleTimeSum = 0.05603909492492676; ]
05/01/24 12:01:41 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:01:41 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140421627.0.0) to (140421627.0.0)
05/01/24 12:01:41 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140421627.0.0) {05/01/24 12:01:36}
05/01/24 12:01:41 Number of idle job procs: 1
05/01/24 12:03:51 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:03:51 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140421627.0.0) {05/01/24 12:03:49}
05/01/24 12:03:51 Number of idle job procs: 0
05/01/24 12:04:01 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:04:01 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140421627.0.0) {05/01/24 12:03:59}
05/01/24 12:04:01 Number of idle job procs: 0
05/01/24 12:04:01 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140421627.0.0) failed with status 1.
05/01/24 12:04:01 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 12:04:01 Of 5 nodes total:
05/01/24 12:04:01  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:04:01   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:04:01     1       0        0       0       0          0        1        3
05/01/24 12:04:01 0 job proc(s) currently held
05/01/24 12:04:01 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002062411143861968; EventCycleTimeCount = 29.0; EventCycleTimeMax = 0.05615806579589844; EventCycleTimeMin = 3.004074096679688E-05; EventCycleTimeStd = 0.01040594030643508; EventCycleTimeSum = 0.05980992317199707; LogProcessCycleTimeAvg = 0.0002353191375732422; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003018379211425781; LogProcessCycleTimeMin = 0.0002009868621826172; LogProcessCycleTimeStd = 5.761694633430384E-05; LogProcessCycleTimeSum = 0.0007059574127197266; SleepCycleTimeAvg = 5.004832999459628; SleepCycleTimeCount = 29.0; SleepCycleTimeMax = 5.005752086639404; SleepCycleTimeMin = 5.00098705291748; SleepCycleTimeStd = 0.0008620427774722152; SleepCycleTimeSum = 145.1401569843292; SubmitCycleTimeAvg = 0.00194705327351888; SubmitCycleTimeCount = 30.0; SubmitCycleTimeMax = 0.05603909492492676; SubmitCycleTimeMin = 1.811981201171875E-05; SubmitCycleTimeStd = 0.01021737561266268; SubmitCycleTimeSum = 0.05841159820556641; ]
05/01/24 12:04:01 ERROR: the following job(s) failed:
05/01/24 12:04:01 ---------------------- Job ----------------------
05/01/24 12:04:01       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0
05/01/24 12:04:01            Noop: false
05/01/24 12:04:01          NodeID: 1
05/01/24 12:04:01     Node Status: STATUS_ERROR    
05/01/24 12:04:01 Node return val: 1
05/01/24 12:04:01           Error: Job proc (140421627.0.0) failed with status 1
05/01/24 12:04:01 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 12:04:01  HTCondor Job ID: (140421627.0.0)
05/01/24 12:04:01 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0 WAITING: 0 CHILDREN: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0
05/01/24 12:04:01 ---------------------------------------	<END>
05/01/24 12:04:01 Aborting DAG...
05/01/24 12:04:01 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue013...
05/01/24 12:04:01 Removing submitted jobs...
05/01/24 12:04:01 Removing any/all submitted HTCondor jobs...
05/01/24 12:04:01 Running: /usr/bin/condor_rm -const DAGManJobId==140421626 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
05/01/24 12:04:01 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/01/24 12:04:01 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/01/24 12:04:01 Note: 0 total job deferrals because of node category throttles
05/01/24 12:04:01 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/01/24 12:04:01 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/01/24 12:04:01 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/01/24 12:04:01 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/01/24 12:04:01 Of 5 nodes total:
05/01/24 12:04:01  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:04:01   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:04:01     1       0        0       0       0          0        1        3
05/01/24 12:04:01 0 job proc(s) currently held
05/01/24 12:04:01 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002062411143861968; EventCycleTimeCount = 29.0; EventCycleTimeMax = 0.05615806579589844; EventCycleTimeMin = 3.004074096679688E-05; EventCycleTimeStd = 0.01040594030643508; EventCycleTimeSum = 0.05980992317199707; LogProcessCycleTimeAvg = 0.0002353191375732422; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003018379211425781; LogProcessCycleTimeMin = 0.0002009868621826172; LogProcessCycleTimeStd = 5.761694633430384E-05; LogProcessCycleTimeSum = 0.0007059574127197266; SleepCycleTimeAvg = 5.004832999459628; SleepCycleTimeCount = 29.0; SleepCycleTimeMax = 5.005752086639404; SleepCycleTimeMin = 5.00098705291748; SleepCycleTimeStd = 0.0008620427774722152; SleepCycleTimeSum = 145.1401569843292; SubmitCycleTimeAvg = 0.00194705327351888; SubmitCycleTimeCount = 30.0; SubmitCycleTimeMax = 0.05603909492492676; SubmitCycleTimeMin = 1.811981201171875E-05; SubmitCycleTimeStd = 0.01021737561266268; SubmitCycleTimeSum = 0.05841159820556641; ]
05/01/24 12:04:01 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/01/24 12:04:01 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.002062411143861968; EventCycleTimeCount = 29.0; EventCycleTimeMax = 0.05615806579589844; EventCycleTimeMin = 3.004074096679688E-05; EventCycleTimeStd = 0.01040594030643508; EventCycleTimeSum = 0.05980992317199707; LogProcessCycleTimeAvg = 0.0002353191375732422; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003018379211425781; LogProcessCycleTimeMin = 0.0002009868621826172; LogProcessCycleTimeStd = 5.761694633430384E-05; LogProcessCycleTimeSum = 0.0007059574127197266; SleepCycleTimeAvg = 5.004832999459628; SleepCycleTimeCount = 29.0; SleepCycleTimeMax = 5.005752086639404; SleepCycleTimeMin = 5.00098705291748; SleepCycleTimeStd = 0.0008620427774722152; SleepCycleTimeSum = 145.1401569843292; SubmitCycleTimeAvg = 0.00194705327351888; SubmitCycleTimeCount = 30.0; SubmitCycleTimeMax = 0.05603909492492676; SubmitCycleTimeMin = 1.811981201171875E-05; SubmitCycleTimeStd = 0.01021737561266268; SubmitCycleTimeSum = 0.05841159820556641; ]
05/01/24 12:04:01 **** condor_scheduniv_exec.140421626.0 (condor_DAGMAN) pid 1928623 EXITING WITH STATUS 1
05/01/24 12:11:36 ******************************************************
05/01/24 12:11:36 ** condor_scheduniv_exec.140421628.0 (CONDOR_DAGMAN) STARTING UP
05/01/24 12:11:36 ** /usr/bin/condor_dagman
05/01/24 12:11:36 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/01/24 12:11:36 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/01/24 12:11:36 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/01/24 12:11:36 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/01/24 12:11:36 ** PID = 1946587
05/01/24 12:11:36 ** Log last touched 5/1 12:04:01
05/01/24 12:11:36 ******************************************************
05/01/24 12:11:36 Using config source: /etc/condor/condor_config
05/01/24 12:11:36 Using local config sources: 
05/01/24 12:11:36    /etc/condor/config.d/00-htcondor-9.0.config
05/01/24 12:11:36    /etc/condor/config.d/00-ldas
05/01/24 12:11:36    /etc/condor/config.d/02-scheduler
05/01/24 12:11:36    /etc/condor/config.d/10-security
05/01/24 12:11:36    /etc/condor/config.d/10-stash-plugin.conf
05/01/24 12:11:36    /etc/condor/config.d/15-dagman-default-append-vars
05/01/24 12:11:36    /etc/condor/config.d/30-scratch-mount
05/01/24 12:11:36    /etc/condor/config.d/40-vault-credmon.conf
05/01/24 12:11:36    /etc/condor/config.d/50-transfer-limits
05/01/24 12:11:36    /etc/condor/config.d/65-system-periodic-hold
05/01/24 12:11:36    /etc/condor/config.d/93-dagman-use-direct
05/01/24 12:11:36    /etc/condor/config.d/99-memory
05/01/24 12:11:36    /etc/condor/config.d/99-request-disk
05/01/24 12:11:36    /etc/condor/config.d/99-request-missing-units
05/01/24 12:11:36    /etc/condor/config.d/99-shared-port-descriptor
05/01/24 12:11:36    /etc/condor/config.d/99-transform
05/01/24 12:11:36    /etc/condor/condor_config.local
05/01/24 12:11:36 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/01/24 12:11:36 CLASSAD_CACHING is ENABLED
05/01/24 12:11:36 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/01/24 12:11:36 DaemonCore: No command port requested.
05/01/24 12:11:36 DAGMAN_USE_STRICT setting: 1
05/01/24 12:11:36 DAGMAN_VERBOSITY setting: 3
05/01/24 12:11:36 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/01/24 12:11:36 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/01/24 12:11:36 DAGMAN_SUBMIT_DELAY setting: 0
05/01/24 12:11:36 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/01/24 12:11:36 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/01/24 12:11:36 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/01/24 12:11:36 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/01/24 12:11:36 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/01/24 12:11:36 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/01/24 12:11:36 DAGMAN_DEFAULT_PRIORITY setting: 0
05/01/24 12:11:36 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/01/24 12:11:36 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/01/24 12:11:36 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/01/24 12:11:36 DAGMAN_RETRY_NODE_FIRST setting: False
05/01/24 12:11:36 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/01/24 12:11:36 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/01/24 12:11:36 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/01/24 12:11:36 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/01/24 12:11:36 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/01/24 12:11:36 DAGMAN_MUNGE_NODE_NAMES setting: True
05/01/24 12:11:36 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/01/24 12:11:36 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/01/24 12:11:36 DAGMAN_ALWAYS_RUN_POST setting: False
05/01/24 12:11:36 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/01/24 12:11:36 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/01/24 12:11:36 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/01/24 12:11:36 DAGMAN_ABORT_DUPLICATES setting: True
05/01/24 12:11:36 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/01/24 12:11:36 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/01/24 12:11:36 DAGMAN_AUTO_RESCUE setting: True
05/01/24 12:11:36 DAGMAN_MAX_RESCUE_NUM setting: 100
05/01/24 12:11:36 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/01/24 12:11:36 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/01/24 12:11:36 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/01/24 12:11:36 DAGMAN_MAX_JOB_HOLDS setting: 100
05/01/24 12:11:36 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/01/24 12:11:36 ALL_DEBUG setting: 
05/01/24 12:11:36 DAGMAN_DEBUG setting: 
05/01/24 12:11:36 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/01/24 12:11:36 DAGMAN_REMOVE_NODE_JOBS setting: True
05/01/24 12:11:36 DAGMAN will adjust edges after parsing
05/01/24 12:11:36 Enabling log line cache for increased NFS performance.
05/01/24 12:11:36 argv[0] == "condor_scheduniv_exec.140421628.0"
05/01/24 12:11:36 argv[1] == "-Lockfile"
05/01/24 12:11:36 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/01/24 12:11:36 argv[3] == "-Dag"
05/01/24 12:11:36 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/01/24 12:11:36 argv[5] == "-CsdVersion"
05/01/24 12:11:36 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/01/24 12:11:36 argv[7] == "-dagman"
05/01/24 12:11:36 argv[8] == "/usr/bin/condor_dagman"
05/01/24 12:11:36 argv[9] == "-AutoRescue"
05/01/24 12:11:36 argv[10] == "1"
05/01/24 12:11:36 argv[11] == "-DoRescueFrom"
05/01/24 12:11:36 argv[12] == "0"
05/01/24 12:11:36 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 12:11:36 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/01/24 12:11:36 Workflow batch-id: <140421628.0>
05/01/24 12:11:36 Workflow batch-name: <bbh.dag+140421628>
05/01/24 12:11:36 Workflow accounting_group: <>
05/01/24 12:11:36 Workflow accounting_group_user: <>
05/01/24 12:11:36 Warning: failed to get attribute DAGNodeName
05/01/24 12:11:36 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/01/24 12:11:36 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/01/24 12:11:36 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/01/24 12:11:36 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/01/24 12:11:36 Parsing 1 dagfiles
05/01/24 12:11:36 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/01/24 12:11:36 Adjusting edges
05/01/24 12:11:36 Found rescue DAG number 13; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue013 in combination with normal DAG file
05/01/24 12:11:36 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/01/24 12:11:36 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue013
05/01/24 12:11:36 Dag contains 5 total jobs
05/01/24 12:11:36 Bootstrapping...
05/01/24 12:11:36 Number of pre-completed nodes: 1
05/01/24 12:11:36 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:11:36 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:11:36 Of 5 nodes total:
05/01/24 12:11:36  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:11:36   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:11:36     1       0        0       0       1          3        0        0
05/01/24 12:11:36 0 job proc(s) currently held
05/01/24 12:11:36 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/01/24 12:11:36 Registering condor_event_timer...
05/01/24 12:11:37 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job(s)...
05/01/24 12:11:37 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:11:37 Masking the events recorded in the DAGMAN workflow log
05/01/24 12:11:37 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 12:11:37 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a My.DAGManJobId=140421628 -a DAGManJobId=140421628 -batch-name bbh.dag+140421628 -batch-id 140421628.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw -a models=--models' 'mass:variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift -a vt_models=--vt-models' 'mass:variable_qmin.variable_qmin.two_component_primary_mass_ratio_variable_qmin' '--vt-models' 'redshift:gwpopulation.models.redshift.PowerLawRedshift DAG_STATUS=0 FAILED_COUNT=0 My.KeepClaimIdle=20 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/collection:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis.sub
05/01/24 12:11:37 From submit: Submitting job(s).
05/01/24 12:11:37 From submit: 1 job(s) submitted to cluster 140421629.
05/01/24 12:11:37 	assigned HTCondor ID (140421629.0.0)
05/01/24 12:11:37 Just submitted 1 job this cycle...
05/01/24 12:11:37 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:11:37 Of 5 nodes total:
05/01/24 12:11:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:11:37   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:11:37     1       0        1       0       0          3        0        0
05/01/24 12:11:37 0 job proc(s) currently held
05/01/24 12:11:37 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03506898880004883; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03506898880004883; SubmitCycleTimeMin = 0.03506898880004883; SubmitCycleTimeStd = 0.03506898880004883; SubmitCycleTimeSum = 0.03506898880004883; ]
05/01/24 12:11:42 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:11:42 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 from (140421629.0.0) to (140421629.0.0)
05/01/24 12:11:42 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140421629.0.0) {05/01/24 12:11:37}
05/01/24 12:11:42 Number of idle job procs: 1
05/01/24 12:14:32 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:14:32 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140421629.0.0) {05/01/24 12:14:30}
05/01/24 12:14:32 Number of idle job procs: 0
05/01/24 12:24:33 601 seconds since last log event
05/01/24 12:24:33 Pending DAG nodes:
05/01/24 12:24:33   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0, HTCondor ID 140421629, status STATUS_SUBMITTED
05/01/24 12:31:18 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:31:18 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 (140421629.0.0) {05/01/24 12:31:15}
05/01/24 12:31:18 Number of idle job procs: 0
05/01/24 12:31:18 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job proc (140421629.0.0) completed successfully.
05/01/24 12:31:18 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 job completed
05/01/24 12:31:18 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:31:18 Of 5 nodes total:
05/01/24 12:31:18  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:31:18   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:31:18     2       0        0       0       3          0        0        0
05/01/24 12:31:18 0 job proc(s) currently held
05/01/24 12:31:18 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0002940610303717145; EventCycleTimeCount = 236.0; EventCycleTimeMax = 0.03519415855407715; EventCycleTimeMin = 2.408027648925781E-05; EventCycleTimeStd = 0.002316451492222627; EventCycleTimeSum = 0.06939840316772461; LogProcessCycleTimeAvg = 0.0002216498057047526; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003001689910888672; LogProcessCycleTimeMin = 0.0001778602600097656; LogProcessCycleTimeStd = 6.815032890050843E-05; LogProcessCycleTimeSum = 0.0006649494171142578; SleepCycleTimeAvg = 5.004919265286397; SleepCycleTimeCount = 236.0; SleepCycleTimeMax = 5.006057024002075; SleepCycleTimeMin = 5.001029014587402; SleepCycleTimeStd = 0.0006572546079004393; SleepCycleTimeSum = 1181.16094660759; SubmitCycleTimeAvg = 0.0002206739997058981; SubmitCycleTimeCount = 237.0; SubmitCycleTimeMax = 0.03506898880004883; SubmitCycleTimeMin = 1.311302185058594E-05; SubmitCycleTimeStd = 0.002279526041324203; SubmitCycleTimeSum = 0.05229973793029785; ]
05/01/24 12:31:23 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 job(s)...
05/01/24 12:31:23 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:31:23 Masking the events recorded in the DAGMAN workflow log
05/01/24 12:31:23 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 12:31:23 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 -a My.DAGManJobId=140421628 -a DAGManJobId=140421628 -batch-name bbh.dag+140421628 -batch-id 140421628.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw DAG_STATUS=0 FAILED_COUNT=0 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot.sub
05/01/24 12:31:23 From submit: Submitting job(s).
05/01/24 12:31:23 From submit: 1 job(s) submitted to cluster 140421630.
05/01/24 12:31:23 	assigned HTCondor ID (140421630.0.0)
05/01/24 12:31:23 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 job(s)...
05/01/24 12:31:23 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:31:23 Masking the events recorded in the DAGMAN workflow log
05/01/24 12:31:23 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 12:31:23 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 -a My.DAGManJobId=140421628 -a DAGManJobId=140421628 -batch-name bbh.dag+140421628 -batch-id 140421628.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 DAG_STATUS=0 FAILED_COUNT=0 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary.sub
05/01/24 12:31:24 From submit: Submitting job(s).
05/01/24 12:31:24 From submit: 1 job(s) submitted to cluster 140421631.
05/01/24 12:31:24 	assigned HTCondor ID (140421631.0.0)
05/01/24 12:31:24 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 job(s)...
05/01/24 12:31:24 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/01/24 12:31:24 Masking the events recorded in the DAGMAN workflow log
05/01/24 12:31:24 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/01/24 12:31:24 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 -a My.DAGManJobId=140421628 -a DAGManJobId=140421628 -batch-name bbh.dag+140421628 -batch-id 140421628.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 -a label=bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw DAG_STATUS=0 FAILED_COUNT=0 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format.sub
05/01/24 12:31:24 From submit: Submitting job(s).
05/01/24 12:31:24 From submit: 1 job(s) submitted to cluster 140421632.
05/01/24 12:31:24 	assigned HTCondor ID (140421632.0.0)
05/01/24 12:31:24 Just submitted 3 jobs this cycle...
05/01/24 12:31:24 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:31:24 Of 5 nodes total:
05/01/24 12:31:24  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:31:24   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:31:24     2       0        3       0       0          0        0        0
05/01/24 12:31:24 0 job proc(s) currently held
05/01/24 12:31:24 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0002950867520102971; EventCycleTimeCount = 237.0; EventCycleTimeMax = 0.03519415855407715; EventCycleTimeMin = 2.408027648925781E-05; EventCycleTimeStd = 0.00231159248115492; EventCycleTimeSum = 0.06993556022644043; LogProcessCycleTimeAvg = 0.0002216498057047526; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0003001689910888672; LogProcessCycleTimeMin = 0.0001778602600097656; LogProcessCycleTimeStd = 6.815032890050843E-05; LogProcessCycleTimeSum = 0.0006649494171142578; SleepCycleTimeAvg = 5.00491982874488; SleepCycleTimeCount = 237.0; SleepCycleTimeMax = 5.006057024002075; SleepCycleTimeMin = 5.001029014587402; SleepCycleTimeStd = 0.0006559180023536774; SleepCycleTimeSum = 1186.165999412537; SubmitCycleTimeAvg = 0.001085734167018858; SubmitCycleTimeCount = 238.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 1.311302185058594E-05; SubmitCycleTimeStd = 0.01353797023431284; SubmitCycleTimeSum = 0.2584047317504883; ]
05/01/24 12:31:29 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:31:29 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 from (140421630.0.0) to (140421630.0.0)
05/01/24 12:31:29 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 (140421630.0.0) {05/01/24 12:31:23}
05/01/24 12:31:29 Number of idle job procs: 1
05/01/24 12:31:29 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 from (140421631.0.0) to (140421631.0.0)
05/01/24 12:31:29 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 12:31:24}
05/01/24 12:31:29 Number of idle job procs: 2
05/01/24 12:31:29 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 from (140421632.0.0) to (140421632.0.0)
05/01/24 12:31:29 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 (140421632.0.0) {05/01/24 12:31:24}
05/01/24 12:31:29 Number of idle job procs: 3
05/01/24 12:31:29 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 (140421630.0.0) {05/01/24 12:31:24}
05/01/24 12:31:29 Number of idle job procs: 2
05/01/24 12:32:19 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:32:19 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 12:32:18}
05/01/24 12:32:19 Number of idle job procs: 1
05/01/24 12:32:24 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:32:24 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 (140421632.0.0) {05/01/24 12:32:20}
05/01/24 12:32:24 Number of idle job procs: 0
05/01/24 12:32:24 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 (140421630.0.0) {05/01/24 12:32:20}
05/01/24 12:32:24 Number of idle job procs: 0
05/01/24 12:32:24 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 job proc (140421630.0.0) completed successfully.
05/01/24 12:32:24 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/plot:0 job completed
05/01/24 12:32:24 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:32:24 Of 5 nodes total:
05/01/24 12:32:24  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:32:24   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:32:24     3       0        2       0       0          0        0        0
05/01/24 12:32:24 0 job proc(s) currently held
05/01/24 12:32:24 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.001127782116932084; EventCycleTimeCount = 249.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 2.408027648925781E-05; EventCycleTimeStd = 0.01324680827822256; EventCycleTimeSum = 0.2808177471160889; LogProcessCycleTimeAvg = 0.0002569754918416341; LogProcessCycleTimeCount = 6.0; LogProcessCycleTimeMax = 0.0004069805145263672; LogProcessCycleTimeMin = 0.0001778602600097656; LogProcessCycleTimeStd = 8.781800262750265E-05; LogProcessCycleTimeSum = 0.001541852951049805; SleepCycleTimeAvg = 5.004923426961324; SleepCycleTimeCount = 249.0; SleepCycleTimeMax = 5.006057024002075; SleepCycleTimeMin = 5.001029014587402; SleepCycleTimeStd = 0.0006429006417247359; SleepCycleTimeSum = 1246.22593331337; SubmitCycleTimeAvg = 0.001034764289855957; SubmitCycleTimeCount = 250.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 1.311302185058594E-05; SubmitCycleTimeStd = 0.01320968441860979; SubmitCycleTimeSum = 0.2586910724639893; ]
05/01/24 12:39:04 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:39:04 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 12:39:01}
05/01/24 12:39:04 Number of idle job procs: 1
05/01/24 12:39:04 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 12:39:01}
05/01/24 12:39:04   Hold reason: Error from slot1_4@node1754.cluster.ldas.cit: Job has gone over cgroup memory limit of 1024 megabytes. Peak usage: 1024 megabytes.  Consider resubmitting with a higher request_memory.
05/01/24 12:39:04 Number of idle job procs: 1
05/01/24 12:39:04 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:39:04 Of 5 nodes total:
05/01/24 12:39:04  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:39:04   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:39:04     3       0        2       0       0          0        0        0
05/01/24 12:39:04 1 job proc(s) currently held
05/01/24 12:39:04 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0008934776109040327; EventCycleTimeCount = 329.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 2.408027648925781E-05; EventCycleTimeStd = 0.01152760067881759; EventCycleTimeSum = 0.2939541339874268; LogProcessCycleTimeAvg = 0.0002583776201520647; LogProcessCycleTimeCount = 7.0; LogProcessCycleTimeMax = 0.0004069805145263672; LogProcessCycleTimeMin = 0.0001778602600097656; LogProcessCycleTimeStd = 8.02522880327767E-05; LogProcessCycleTimeSum = 0.001808643341064453; SleepCycleTimeAvg = 5.004941938858265; SleepCycleTimeCount = 329.0; SleepCycleTimeMax = 5.006057024002075; SleepCycleTimeMin = 5.000968933105469; SleepCycleTimeStd = 0.0006208611712584345; SleepCycleTimeSum = 1646.625897884369; SubmitCycleTimeAvg = 0.0008045788967248165; SubmitCycleTimeCount = 330.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 1.311302185058594E-05; SubmitCycleTimeStd = 0.01149943152553016; SubmitCycleTimeSum = 0.2655110359191895; ]
05/01/24 12:49:05 601 seconds since last log event
05/01/24 12:49:05 Pending DAG nodes:
05/01/24 12:49:05   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0, HTCondor ID 140421632, status STATUS_SUBMITTED
05/01/24 12:49:05   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 12:55:00 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:55:00 Event: ULOG_JOB_RELEASED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 12:54:57}
05/01/24 12:55:00 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:55:00 Of 5 nodes total:
05/01/24 12:55:00  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:55:00   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:55:00     3       0        2       0       0          0        0        0
05/01/24 12:55:00 0 job proc(s) currently held
05/01/24 12:55:00 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006368531630589412; EventCycleTimeCount = 520.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 2.408027648925781E-05; EventCycleTimeStd = 0.009173701203640311; EventCycleTimeSum = 0.3311636447906494; LogProcessCycleTimeAvg = 0.0002397000789642334; LogProcessCycleTimeCount = 8.0; LogProcessCycleTimeMax = 0.0004069805145263672; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 9.11656333408516E-05; LogProcessCycleTimeSum = 0.001917600631713867; SleepCycleTimeAvg = 5.00490483549925; SleepCycleTimeCount = 520.0; SleepCycleTimeMax = 5.006057024002075; SleepCycleTimeMin = 5.000083923339844; SleepCycleTimeStd = 0.0007131526828474225; SleepCycleTimeSum = 2602.55051445961; SubmitCycleTimeAvg = 0.0005499209186165896; SubmitCycleTimeCount = 521.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 1.311302185058594E-05; SubmitCycleTimeStd = 0.009153767354042793; SubmitCycleTimeSum = 0.2865087985992432; ]
05/01/24 12:56:15 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:56:15 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 12:56:15}
05/01/24 12:56:15 Number of idle job procs: 0
05/01/24 12:56:25 Currently monitoring 1 HTCondor log file(s)
05/01/24 12:56:25 Event: ULOG_JOB_TERMINATED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 (140421632.0.0) {05/01/24 12:56:21}
05/01/24 12:56:25 Number of idle job procs: 0
05/01/24 12:56:25 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 job proc (140421632.0.0) completed successfully.
05/01/24 12:56:25 Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/common_format:0 job completed
05/01/24 12:56:25 DAG status: 0 (DAG_STATUS_OK)
05/01/24 12:56:25 Of 5 nodes total:
05/01/24 12:56:25  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 12:56:25   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 12:56:25     4       0        1       0       0          0        0        0
05/01/24 12:56:25 0 job proc(s) currently held
05/01/24 12:56:25 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006210368882788404; EventCycleTimeCount = 537.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 2.408027648925781E-05; EventCycleTimeStd = 0.009027518276879377; EventCycleTimeSum = 0.3334968090057373; LogProcessCycleTimeAvg = 0.0002564668655395508; LogProcessCycleTimeCount = 10.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.000107789871955408; LogProcessCycleTimeSum = 0.002564668655395508; SleepCycleTimeAvg = 5.004906514503436; SleepCycleTimeCount = 537.0; SleepCycleTimeMax = 5.006057024002075; SleepCycleTimeMin = 5.000083923339844; SleepCycleTimeStd = 0.0007076841873919594; SleepCycleTimeSum = 2687.634798288345; SubmitCycleTimeAvg = 0.0005350294609495255; SubmitCycleTimeCount = 538.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 1.311302185058594E-05; SubmitCycleTimeStd = 0.009008123414959646; SubmitCycleTimeSum = 0.2878458499908447; ]
05/01/24 13:06:26 601 seconds since last log event
05/01/24 13:06:26 Pending DAG nodes:
05/01/24 13:06:26   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 13:15:21 Currently monitoring 1 HTCondor log file(s)
05/01/24 13:15:21 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 13:15:19}
05/01/24 13:15:21 Number of idle job procs: 1
05/01/24 13:15:21 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 13:15:19}
05/01/24 13:15:21   Hold reason: Error from slot1_17@node2199.cluster.ldas.cit: Job has gone over cgroup memory limit of 4096 megabytes. Peak usage: 4096 megabytes.  Consider resubmitting with a higher request_memory.
05/01/24 13:15:21 Number of idle job procs: 1
05/01/24 13:15:21 DAG status: 0 (DAG_STATUS_OK)
05/01/24 13:15:21 Of 5 nodes total:
05/01/24 13:15:21  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 13:15:21   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 13:15:21     4       0        1       0       0          0        0        0
05/01/24 13:15:21 1 job proc(s) currently held
05/01/24 13:15:21 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0004929541293239094; EventCycleTimeCount = 764.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 1.478195190429688E-05; EventCycleTimeStd = 0.007573502066831361; EventCycleTimeSum = 0.3766169548034668; LogProcessCycleTimeAvg = 0.0002488873221657493; LogProcessCycleTimeCount = 11.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.0001053030631171556; LogProcessCycleTimeSum = 0.002737760543823242; SleepCycleTimeAvg = 5.004887004173239; SleepCycleTimeCount = 764.0; SleepCycleTimeMax = 5.006211996078491; SleepCycleTimeMin = 5.000083923339844; SleepCycleTimeStd = 0.0007443712454610732; SleepCycleTimeSum = 3823.733671188354; SubmitCycleTimeAvg = 0.0004051401724223218; SubmitCycleTimeCount = 765.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 5.960464477539062E-06; SubmitCycleTimeStd = 0.007555899444213146; SubmitCycleTimeSum = 0.3099322319030762; ]
05/01/24 13:16:06 Currently monitoring 1 HTCondor log file(s)
05/01/24 13:16:06 Event: ULOG_JOB_RELEASED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 13:16:05}
05/01/24 13:16:06 DAG status: 0 (DAG_STATUS_OK)
05/01/24 13:16:06 Of 5 nodes total:
05/01/24 13:16:06  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 13:16:06   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 13:16:06     4       0        1       0       0          0        0        0
05/01/24 13:16:06 0 job proc(s) currently held
05/01/24 13:16:06 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0004886325549955972; EventCycleTimeCount = 773.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 1.478195190429688E-05; EventCycleTimeStd = 0.007529343608991081; EventCycleTimeSum = 0.3777129650115967; LogProcessCycleTimeAvg = 0.0002391537030537923; LogProcessCycleTimeCount = 12.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.0001059131170658955; LogProcessCycleTimeSum = 0.002869844436645508; SleepCycleTimeAvg = 5.004888308156199; SleepCycleTimeCount = 773.0; SleepCycleTimeMax = 5.006211996078491; SleepCycleTimeMin = 5.000083923339844; SleepCycleTimeStd = 0.0007408682723298707; SleepCycleTimeSum = 3868.778662204742; SubmitCycleTimeAvg = 0.0004012960488174005; SubmitCycleTimeCount = 774.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 5.960464477539062E-06; SubmitCycleTimeStd = 0.007511875712034772; SubmitCycleTimeSum = 0.310603141784668; ]
05/01/24 13:17:21 Currently monitoring 1 HTCondor log file(s)
05/01/24 13:17:21 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 13:17:17}
05/01/24 13:17:21 Number of idle job procs: 0
05/01/24 13:27:22 601 seconds since last log event
05/01/24 13:27:22 Pending DAG nodes:
05/01/24 13:27:22   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 13:37:23 1202 seconds since last log event
05/01/24 13:37:23 Pending DAG nodes:
05/01/24 13:37:23   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 13:47:23 1802 seconds since last log event
05/01/24 13:47:23 Pending DAG nodes:
05/01/24 13:47:23   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 13:57:24 2403 seconds since last log event
05/01/24 13:57:24 Pending DAG nodes:
05/01/24 13:57:24   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 14:07:24 3003 seconds since last log event
05/01/24 14:07:24 Pending DAG nodes:
05/01/24 14:07:24   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 14:17:24 3603 seconds since last log event
05/01/24 14:17:24 Pending DAG nodes:
05/01/24 14:17:24   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 14:27:25 4204 seconds since last log event
05/01/24 14:27:25 Pending DAG nodes:
05/01/24 14:27:25   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 14:37:25 4804 seconds since last log event
05/01/24 14:37:25 Pending DAG nodes:
05/01/24 14:37:25   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 14:47:26 5405 seconds since last log event
05/01/24 14:47:26 Pending DAG nodes:
05/01/24 14:47:26   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 14:57:26 6005 seconds since last log event
05/01/24 14:57:26 Pending DAG nodes:
05/01/24 14:57:26   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 15:07:27 6606 seconds since last log event
05/01/24 15:07:27 Pending DAG nodes:
05/01/24 15:07:27   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 15:17:28 7207 seconds since last log event
05/01/24 15:17:28 Pending DAG nodes:
05/01/24 15:17:28   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 15:27:28 7807 seconds since last log event
05/01/24 15:27:28 Pending DAG nodes:
05/01/24 15:27:28   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 15:37:29 8408 seconds since last log event
05/01/24 15:37:29 Pending DAG nodes:
05/01/24 15:37:29   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 15:47:29 9008 seconds since last log event
05/01/24 15:47:29 Pending DAG nodes:
05/01/24 15:47:29   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 15:57:30 9609 seconds since last log event
05/01/24 15:57:30 Pending DAG nodes:
05/01/24 15:57:30   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 16:07:31 10210 seconds since last log event
05/01/24 16:07:31 Pending DAG nodes:
05/01/24 16:07:31   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 16:17:31 10810 seconds since last log event
05/01/24 16:17:31 Pending DAG nodes:
05/01/24 16:17:31   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 16:27:32 11411 seconds since last log event
05/01/24 16:27:32 Pending DAG nodes:
05/01/24 16:27:32   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 16:37:33 12012 seconds since last log event
05/01/24 16:37:33 Pending DAG nodes:
05/01/24 16:37:33   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 16:47:33 12612 seconds since last log event
05/01/24 16:47:33 Pending DAG nodes:
05/01/24 16:47:33   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 16:57:33 13212 seconds since last log event
05/01/24 16:57:33 Pending DAG nodes:
05/01/24 16:57:33   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 17:07:34 13813 seconds since last log event
05/01/24 17:07:34 Pending DAG nodes:
05/01/24 17:07:34   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 17:17:34 14413 seconds since last log event
05/01/24 17:17:34 Pending DAG nodes:
05/01/24 17:17:34   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 17:27:35 15014 seconds since last log event
05/01/24 17:27:35 Pending DAG nodes:
05/01/24 17:27:35   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 17:37:35 15614 seconds since last log event
05/01/24 17:37:35 Pending DAG nodes:
05/01/24 17:37:35   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 17:47:35 16214 seconds since last log event
05/01/24 17:47:35 Pending DAG nodes:
05/01/24 17:47:35   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 17:57:36 16815 seconds since last log event
05/01/24 17:57:36 Pending DAG nodes:
05/01/24 17:57:36   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 18:07:36 17415 seconds since last log event
05/01/24 18:07:36 Pending DAG nodes:
05/01/24 18:07:36   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 18:17:37 18016 seconds since last log event
05/01/24 18:17:37 Pending DAG nodes:
05/01/24 18:17:37   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 18:27:37 18616 seconds since last log event
05/01/24 18:27:37 Pending DAG nodes:
05/01/24 18:27:37   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 18:37:37 19216 seconds since last log event
05/01/24 18:37:37 Pending DAG nodes:
05/01/24 18:37:37   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 18:47:38 19817 seconds since last log event
05/01/24 18:47:38 Pending DAG nodes:
05/01/24 18:47:38   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 18:50:18 Currently monitoring 1 HTCondor log file(s)
05/01/24 18:50:18 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 18:50:17}
05/01/24 18:50:18 Number of idle job procs: 1
05/01/24 18:50:18 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/01/24 18:50:17}
05/01/24 18:50:18   Hold reason: Error from slot1_28@node832.cluster.ldas.cit: Job has gone over cgroup memory limit of 16000 megabytes. Peak usage: 16002 megabytes.  Consider resubmitting with a higher request_memory.
05/01/24 18:50:18 Number of idle job procs: 1
05/01/24 18:50:18 DAG status: 0 (DAG_STATUS_OK)
05/01/24 18:50:18 Of 5 nodes total:
05/01/24 18:50:18  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/01/24 18:50:18   ===     ===      ===     ===     ===        ===      ===      ===
05/01/24 18:50:18     4       0        1       0       0          0        0        0
05/01/24 18:50:18 1 job proc(s) currently held
05/01/24 18:50:18 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0002815666557854688; EventCycleTimeCount = 4780.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 1.192092895507812E-05; EventCycleTimeStd = 0.004056349108824969; EventCycleTimeSum = 1.345888614654541; LogProcessCycleTimeAvg = 0.000246150153023856; LogProcessCycleTimeCount = 14.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.0001110190685467956; LogProcessCycleTimeSum = 0.003446102142333984; SleepCycleTimeAvg = 5.00405853378224; SleepCycleTimeCount = 4780.0; SleepCycleTimeMax = 5.017884016036987; SleepCycleTimeMin = 4.003684043884277; SleepCycleTimeStd = 0.02895119086650445; SleepCycleTimeSum = 23919.39979147911; SubmitCycleTimeAvg = 0.0001398235453494147; SubmitCycleTimeCount = 4781.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 5.006790161132812E-06; SubmitCycleTimeStd = 0.003038731785008751; SubmitCycleTimeSum = 0.6684963703155518; ]
05/01/24 19:00:19 601 seconds since last log event
05/01/24 19:00:19 Pending DAG nodes:
05/01/24 19:00:19   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 19:10:19 1201 seconds since last log event
05/01/24 19:10:19 Pending DAG nodes:
05/01/24 19:10:19   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 19:20:20 1802 seconds since last log event
05/01/24 19:20:20 Pending DAG nodes:
05/01/24 19:20:20   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 19:30:20 2402 seconds since last log event
05/01/24 19:30:20 Pending DAG nodes:
05/01/24 19:30:20   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 19:40:21 3003 seconds since last log event
05/01/24 19:40:21 Pending DAG nodes:
05/01/24 19:40:21   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 19:50:22 3604 seconds since last log event
05/01/24 19:50:22 Pending DAG nodes:
05/01/24 19:50:22   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 20:00:22 4204 seconds since last log event
05/01/24 20:00:22 Pending DAG nodes:
05/01/24 20:00:22   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 20:10:23 4805 seconds since last log event
05/01/24 20:10:23 Pending DAG nodes:
05/01/24 20:10:23   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 20:20:23 5405 seconds since last log event
05/01/24 20:20:23 Pending DAG nodes:
05/01/24 20:20:23   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 20:30:24 6006 seconds since last log event
05/01/24 20:30:24 Pending DAG nodes:
05/01/24 20:30:24   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 20:40:25 6607 seconds since last log event
05/01/24 20:40:25 Pending DAG nodes:
05/01/24 20:40:25   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 20:50:25 7207 seconds since last log event
05/01/24 20:50:25 Pending DAG nodes:
05/01/24 20:50:25   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 21:00:26 7808 seconds since last log event
05/01/24 21:00:26 Pending DAG nodes:
05/01/24 21:00:26   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 21:10:27 8409 seconds since last log event
05/01/24 21:10:27 Pending DAG nodes:
05/01/24 21:10:27   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 21:20:27 9009 seconds since last log event
05/01/24 21:20:27 Pending DAG nodes:
05/01/24 21:20:27   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 21:30:28 9610 seconds since last log event
05/01/24 21:30:28 Pending DAG nodes:
05/01/24 21:30:28   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 21:40:29 10211 seconds since last log event
05/01/24 21:40:29 Pending DAG nodes:
05/01/24 21:40:29   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 21:50:29 10811 seconds since last log event
05/01/24 21:50:29 Pending DAG nodes:
05/01/24 21:50:29   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 22:00:30 11412 seconds since last log event
05/01/24 22:00:30 Pending DAG nodes:
05/01/24 22:00:30   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 22:10:31 12013 seconds since last log event
05/01/24 22:10:31 Pending DAG nodes:
05/01/24 22:10:31   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 22:20:32 12614 seconds since last log event
05/01/24 22:20:32 Pending DAG nodes:
05/01/24 22:20:32   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 22:30:32 13214 seconds since last log event
05/01/24 22:30:32 Pending DAG nodes:
05/01/24 22:30:32   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 22:40:33 13815 seconds since last log event
05/01/24 22:40:33 Pending DAG nodes:
05/01/24 22:40:33   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 22:50:34 14416 seconds since last log event
05/01/24 22:50:34 Pending DAG nodes:
05/01/24 22:50:34   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 23:00:34 15016 seconds since last log event
05/01/24 23:00:34 Pending DAG nodes:
05/01/24 23:00:34   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 23:10:35 15617 seconds since last log event
05/01/24 23:10:35 Pending DAG nodes:
05/01/24 23:10:35   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 23:20:36 16218 seconds since last log event
05/01/24 23:20:36 Pending DAG nodes:
05/01/24 23:20:36   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 23:30:36 16818 seconds since last log event
05/01/24 23:30:36 Pending DAG nodes:
05/01/24 23:30:36   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 23:40:37 17419 seconds since last log event
05/01/24 23:40:37 Pending DAG nodes:
05/01/24 23:40:37   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/01/24 23:50:38 18020 seconds since last log event
05/01/24 23:50:38 Pending DAG nodes:
05/01/24 23:50:38   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 00:00:39 18621 seconds since last log event
05/02/24 00:00:39 Pending DAG nodes:
05/02/24 00:00:39   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 00:10:39 19221 seconds since last log event
05/02/24 00:10:39 Pending DAG nodes:
05/02/24 00:10:39   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 00:20:40 19822 seconds since last log event
05/02/24 00:20:40 Pending DAG nodes:
05/02/24 00:20:40   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 00:30:40 20422 seconds since last log event
05/02/24 00:30:40 Pending DAG nodes:
05/02/24 00:30:40   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 00:40:41 21023 seconds since last log event
05/02/24 00:40:41 Pending DAG nodes:
05/02/24 00:40:41   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 00:50:42 21624 seconds since last log event
05/02/24 00:50:42 Pending DAG nodes:
05/02/24 00:50:42   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 01:00:42 22224 seconds since last log event
05/02/24 01:00:42 Pending DAG nodes:
05/02/24 01:00:42   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 01:10:43 22825 seconds since last log event
05/02/24 01:10:43 Pending DAG nodes:
05/02/24 01:10:43   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 01:20:44 23426 seconds since last log event
05/02/24 01:20:44 Pending DAG nodes:
05/02/24 01:20:44   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 01:30:44 24026 seconds since last log event
05/02/24 01:30:44 Pending DAG nodes:
05/02/24 01:30:44   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 01:40:45 24627 seconds since last log event
05/02/24 01:40:45 Pending DAG nodes:
05/02/24 01:40:45   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 01:50:45 25227 seconds since last log event
05/02/24 01:50:45 Pending DAG nodes:
05/02/24 01:50:45   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 02:00:46 25828 seconds since last log event
05/02/24 02:00:46 Pending DAG nodes:
05/02/24 02:00:46   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 02:10:47 26429 seconds since last log event
05/02/24 02:10:47 Pending DAG nodes:
05/02/24 02:10:47   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 02:20:47 27029 seconds since last log event
05/02/24 02:20:47 Pending DAG nodes:
05/02/24 02:20:47   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 02:30:48 27630 seconds since last log event
05/02/24 02:30:48 Pending DAG nodes:
05/02/24 02:30:48   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 02:40:50 28232 seconds since last log event
05/02/24 02:40:50 Pending DAG nodes:
05/02/24 02:40:50   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 02:50:52 28834 seconds since last log event
05/02/24 02:50:52 Pending DAG nodes:
05/02/24 02:50:52   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 03:00:53 29435 seconds since last log event
05/02/24 03:00:53 Pending DAG nodes:
05/02/24 03:00:53   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 03:10:53 30035 seconds since last log event
05/02/24 03:10:53 Pending DAG nodes:
05/02/24 03:10:53   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 03:20:54 30636 seconds since last log event
05/02/24 03:20:54 Pending DAG nodes:
05/02/24 03:20:54   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 03:30:55 31237 seconds since last log event
05/02/24 03:30:55 Pending DAG nodes:
05/02/24 03:30:55   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 03:40:56 31838 seconds since last log event
05/02/24 03:40:56 Pending DAG nodes:
05/02/24 03:40:56   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 03:50:57 32439 seconds since last log event
05/02/24 03:50:57 Pending DAG nodes:
05/02/24 03:50:57   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 04:00:59 33041 seconds since last log event
05/02/24 04:00:59 Pending DAG nodes:
05/02/24 04:00:59   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 04:10:59 33641 seconds since last log event
05/02/24 04:10:59 Pending DAG nodes:
05/02/24 04:10:59   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 04:20:59 34241 seconds since last log event
05/02/24 04:20:59 Pending DAG nodes:
05/02/24 04:20:59   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 04:31:00 34842 seconds since last log event
05/02/24 04:31:00 Pending DAG nodes:
05/02/24 04:31:00   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 04:41:01 35443 seconds since last log event
05/02/24 04:41:01 Pending DAG nodes:
05/02/24 04:41:01   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 04:51:01 36043 seconds since last log event
05/02/24 04:51:01 Pending DAG nodes:
05/02/24 04:51:01   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 05:01:02 36644 seconds since last log event
05/02/24 05:01:02 Pending DAG nodes:
05/02/24 05:01:02   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 05:11:02 37244 seconds since last log event
05/02/24 05:11:02 Pending DAG nodes:
05/02/24 05:11:02   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 05:21:03 37845 seconds since last log event
05/02/24 05:21:03 Pending DAG nodes:
05/02/24 05:21:03   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 05:31:04 38446 seconds since last log event
05/02/24 05:31:04 Pending DAG nodes:
05/02/24 05:31:04   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 05:41:04 39046 seconds since last log event
05/02/24 05:41:04 Pending DAG nodes:
05/02/24 05:41:04   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 05:51:05 39647 seconds since last log event
05/02/24 05:51:05 Pending DAG nodes:
05/02/24 05:51:05   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 06:01:05 40247 seconds since last log event
05/02/24 06:01:05 Pending DAG nodes:
05/02/24 06:01:05   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 06:11:05 40847 seconds since last log event
05/02/24 06:11:05 Pending DAG nodes:
05/02/24 06:11:05   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 06:21:06 41448 seconds since last log event
05/02/24 06:21:06 Pending DAG nodes:
05/02/24 06:21:06   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 06:31:07 42049 seconds since last log event
05/02/24 06:31:07 Pending DAG nodes:
05/02/24 06:31:07   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 06:41:07 42649 seconds since last log event
05/02/24 06:41:07 Pending DAG nodes:
05/02/24 06:41:07   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 06:51:08 43250 seconds since last log event
05/02/24 06:51:08 Pending DAG nodes:
05/02/24 06:51:08   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 07:01:08 43850 seconds since last log event
05/02/24 07:01:08 Pending DAG nodes:
05/02/24 07:01:08   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140421631, status STATUS_SUBMITTED
05/02/24 07:03:24 Currently monitoring 1 HTCondor log file(s)
05/02/24 07:03:24 Event: ULOG_JOB_RELEASED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/02/24 07:03:23}
05/02/24 07:03:24 DAG status: 0 (DAG_STATUS_OK)
05/02/24 07:03:24 Of 5 nodes total:
05/02/24 07:03:24  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/02/24 07:03:24   ===     ===      ===     ===     ===        ===      ===      ===
05/02/24 07:03:24     4       0        1       0       0          0        0        0
05/02/24 07:03:24 0 job proc(s) currently held
05/02/24 07:03:24 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006800651936908192; EventCycleTimeCount = 13567.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 1.001358032226562E-05; EventCycleTimeStd = 0.004405195952518167; EventCycleTimeSum = 9.226444482803345; LogProcessCycleTimeAvg = 0.0002525965372721354; LogProcessCycleTimeCount = 15.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.0001098553494461281; LogProcessCycleTimeSum = 0.003788948059082031; SleepCycleTimeAvg = 5.004585133240658; SleepCycleTimeCount = 13567.0; SleepCycleTimeMax = 5.028310060501099; SleepCycleTimeMin = 4.002476930618286; SleepCycleTimeStd = 0.02428845394405128; SleepCycleTimeSum = 67897.20650267601; SubmitCycleTimeAvg = 0.0004088113541310688; SubmitCycleTimeCount = 13568.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 5.006790161132812E-06; SubmitCycleTimeStd = 0.003005665401197525; SubmitCycleTimeSum = 5.546752452850342; ]
05/02/24 07:05:04 Currently monitoring 1 HTCondor log file(s)
05/02/24 07:05:04 Event: ULOG_EXECUTE for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140421631.0.0) {05/02/24 07:05:03}
05/02/24 07:05:04 Number of idle job procs: 0
05/02/24 07:12:42 Received SIGUSR1
05/02/24 07:12:42 Aborting DAG...
05/02/24 07:12:42 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue014...
05/02/24 07:12:42 Removing submitted jobs...
05/02/24 07:12:42 Removing any/all submitted HTCondor jobs...
05/02/24 07:12:42 Running: /usr/bin/condor_rm -const DAGManJobId==140421628 -reason DAG' 'Removed:' 'User' 'removed' 'scheduler' 'job' 'from' 'queue.
05/02/24 07:12:42 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/02/24 07:12:42 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/02/24 07:12:42 Note: 0 total job deferrals because of node category throttles
05/02/24 07:12:42 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/02/24 07:12:42 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/02/24 07:12:42 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/02/24 07:12:42 DAG status: 4 (DAG_STATUS_RM)
05/02/24 07:12:42 Of 5 nodes total:
05/02/24 07:12:42  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/02/24 07:12:42   ===     ===      ===     ===     ===        ===      ===      ===
05/02/24 07:12:42     4       0        1       0       0          0        0        0
05/02/24 07:12:42 0 job proc(s) currently held
05/02/24 07:12:42 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006758561564150658; EventCycleTimeCount = 13679.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 1.001358032226562E-05; EventCycleTimeStd = 0.004387564674294274; EventCycleTimeSum = 9.245036363601685; LogProcessCycleTimeAvg = 0.0002461820840835571; LogProcessCycleTimeCount = 16.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.0001091877952755599; LogProcessCycleTimeSum = 0.003938913345336914; SleepCycleTimeAvg = 5.004588051591113; SleepCycleTimeCount = 13678.0; SleepCycleTimeMax = 5.028310060501099; SleepCycleTimeMin = 4.002476930618286; SleepCycleTimeStd = 0.02418975507851514; SleepCycleTimeSum = 68452.75536966324; SubmitCycleTimeAvg = 0.0004060971335157228; SubmitCycleTimeCount = 13679.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 5.006790161132812E-06; SubmitCycleTimeStd = 0.002993622237005312; SubmitCycleTimeSum = 5.555002689361572; ]
05/02/24 07:12:42 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/02/24 07:12:42 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0006758561564150658; EventCycleTimeCount = 13679.0; EventCycleTimeMax = 0.2062501907348633; EventCycleTimeMin = 1.001358032226562E-05; EventCycleTimeStd = 0.004387564674294274; EventCycleTimeSum = 9.245036363601685; LogProcessCycleTimeAvg = 0.0002461820840835571; LogProcessCycleTimeCount = 16.0; LogProcessCycleTimeMax = 0.0004560947418212891; LogProcessCycleTimeMin = 0.0001089572906494141; LogProcessCycleTimeStd = 0.0001091877952755599; LogProcessCycleTimeSum = 0.003938913345336914; SleepCycleTimeAvg = 5.004588051591113; SleepCycleTimeCount = 13678.0; SleepCycleTimeMax = 5.028310060501099; SleepCycleTimeMin = 4.002476930618286; SleepCycleTimeStd = 0.02418975507851514; SleepCycleTimeSum = 68452.75536966324; SubmitCycleTimeAvg = 0.0004060971335157228; SubmitCycleTimeCount = 13679.0; SubmitCycleTimeMax = 0.2061049938201904; SubmitCycleTimeMin = 5.006790161132812E-06; SubmitCycleTimeStd = 0.002993622237005312; SubmitCycleTimeSum = 5.555002689361572; ]
05/02/24 07:12:42 **** condor_scheduniv_exec.140421628.0 (condor_DAGMAN) pid 1946587 EXITING WITH STATUS 2
05/03/24 10:46:33 ******************************************************
05/03/24 10:46:33 ** condor_scheduniv_exec.140446153.0 (CONDOR_DAGMAN) STARTING UP
05/03/24 10:46:33 ** /usr/bin/condor_dagman
05/03/24 10:46:33 ** SubsystemInfo: name=DAGMAN type=DAGMAN(9) class=CLIENT(2)
05/03/24 10:46:33 ** Configuration: subsystem:DAGMAN local:<NONE> class:CLIENT
05/03/24 10:46:33 ** $CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $
05/03/24 10:46:33 ** $CondorPlatform: x86_64_AlmaLinux8 $
05/03/24 10:46:33 ** PID = 2987439
05/03/24 10:46:33 ** Log last touched 5/2 07:12:42
05/03/24 10:46:33 ******************************************************
05/03/24 10:46:33 Using config source: /etc/condor/condor_config
05/03/24 10:46:33 Using local config sources: 
05/03/24 10:46:33    /etc/condor/config.d/00-htcondor-9.0.config
05/03/24 10:46:33    /etc/condor/config.d/00-ldas
05/03/24 10:46:33    /etc/condor/config.d/02-scheduler
05/03/24 10:46:33    /etc/condor/config.d/10-security
05/03/24 10:46:33    /etc/condor/config.d/10-stash-plugin.conf
05/03/24 10:46:33    /etc/condor/config.d/15-dagman-default-append-vars
05/03/24 10:46:33    /etc/condor/config.d/30-scratch-mount
05/03/24 10:46:33    /etc/condor/config.d/40-vault-credmon.conf
05/03/24 10:46:33    /etc/condor/config.d/50-transfer-limits
05/03/24 10:46:33    /etc/condor/config.d/65-system-periodic-hold
05/03/24 10:46:33    /etc/condor/config.d/93-dagman-use-direct
05/03/24 10:46:33    /etc/condor/config.d/99-memory
05/03/24 10:46:33    /etc/condor/config.d/99-request-disk
05/03/24 10:46:33    /etc/condor/config.d/99-request-missing-units
05/03/24 10:46:33    /etc/condor/config.d/99-shared-port-descriptor
05/03/24 10:46:33    /etc/condor/config.d/99-transform
05/03/24 10:46:33    /etc/condor/condor_config.local
05/03/24 10:46:33 config Macros = 167, Sorted = 167, StringBytes = 7879, TablesBytes = 6180
05/03/24 10:46:33 CLASSAD_CACHING is ENABLED
05/03/24 10:46:33 Daemon Log is logging: D_ALWAYS D_ERROR D_STATUS
05/03/24 10:46:33 DaemonCore: No command port requested.
05/03/24 10:46:33 DAGMAN_USE_STRICT setting: 1
05/03/24 10:46:33 DAGMAN_VERBOSITY setting: 3
05/03/24 10:46:33 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/03/24 10:46:33 DAGMAN_DEBUG_CACHE_ENABLE setting: True
05/03/24 10:46:33 DAGMAN_SUBMIT_DELAY setting: 0
05/03/24 10:46:33 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/03/24 10:46:33 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/03/24 10:46:33 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 100
05/03/24 10:46:33 DAGMAN_AGGRESSIVE_SUBMIT setting: False
05/03/24 10:46:33 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/03/24 10:46:33 DAGMAN_QUEUE_UPDATE_INTERVAL setting: 300
05/03/24 10:46:33 DAGMAN_DEFAULT_PRIORITY setting: 0
05/03/24 10:46:33 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/03/24 10:46:33 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/03/24 10:46:33 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/03/24 10:46:33 DAGMAN_RETRY_NODE_FIRST setting: False
05/03/24 10:46:33 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/03/24 10:46:33 DAGMAN_MAX_JOBS_SUBMITTED setting: 12000
05/03/24 10:46:33 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/03/24 10:46:33 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/03/24 10:46:33 DAGMAN_MAX_HOLD_SCRIPTS setting: 20
05/03/24 10:46:33 DAGMAN_MUNGE_NODE_NAMES setting: True
05/03/24 10:46:33 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/03/24 10:46:33 DAGMAN_SUBMIT_DEPTH_FIRST setting: True
05/03/24 10:46:33 DAGMAN_ALWAYS_RUN_POST setting: False
05/03/24 10:46:33 DAGMAN_CONDOR_SUBMIT_EXE setting: /usr/bin/condor_submit
05/03/24 10:46:33 DAGMAN_USE_DIRECT_SUBMIT setting: False
05/03/24 10:46:33 DAGMAN_DEFAULT_APPEND_VARS setting: True
05/03/24 10:46:33 DAGMAN_ABORT_DUPLICATES setting: True
05/03/24 10:46:33 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/03/24 10:46:33 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/03/24 10:46:33 DAGMAN_AUTO_RESCUE setting: True
05/03/24 10:46:33 DAGMAN_MAX_RESCUE_NUM setting: 100
05/03/24 10:46:33 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/03/24 10:46:33 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/03/24 10:46:33 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/03/24 10:46:33 DAGMAN_MAX_JOB_HOLDS setting: 100
05/03/24 10:46:33 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/03/24 10:46:33 ALL_DEBUG setting: 
05/03/24 10:46:33 DAGMAN_DEBUG setting: 
05/03/24 10:46:33 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/03/24 10:46:33 DAGMAN_REMOVE_NODE_JOBS setting: True
05/03/24 10:46:33 DAGMAN will adjust edges after parsing
05/03/24 10:46:33 Enabling log line cache for increased NFS performance.
05/03/24 10:46:33 argv[0] == "condor_scheduniv_exec.140446153.0"
05/03/24 10:46:33 argv[1] == "-Lockfile"
05/03/24 10:46:33 argv[2] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock"
05/03/24 10:46:33 argv[3] == "-Dag"
05/03/24 10:46:33 argv[4] == "/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag"
05/03/24 10:46:33 argv[5] == "-CsdVersion"
05/03/24 10:46:33 argv[6] == "$CondorVersion: 23.5.2 2024-03-14 BuildID: 720591 PackageID: 23.5.2-1 GitSHA: af5f6620 $"
05/03/24 10:46:33 argv[7] == "-dagman"
05/03/24 10:46:33 argv[8] == "/usr/bin/condor_dagman"
05/03/24 10:46:33 argv[9] == "-AutoRescue"
05/03/24 10:46:33 argv[10] == "1"
05/03/24 10:46:33 argv[11] == "-DoRescueFrom"
05/03/24 10:46:33 argv[12] == "0"
05/03/24 10:46:33 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/03/24 10:46:33 Can't open directory "/etc/condor/passwords.d" as PRIV_ROOT, errno: 13 (Permission denied)
05/03/24 10:46:33 Workflow batch-id: <140446153.0>
05/03/24 10:46:33 Workflow batch-name: <bbh.dag+140446153>
05/03/24 10:46:33 Workflow accounting_group: <>
05/03/24 10:46:33 Workflow accounting_group_user: <>
05/03/24 10:46:33 Warning: failed to get attribute DAGNodeName
05/03/24 10:46:33 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/03/24 10:46:33 Default node log file is: </home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log>
05/03/24 10:46:33 DAG Lockfile will be written to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.lock
05/03/24 10:46:33 DAG Input file is /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag
05/03/24 10:46:33 Parsing 1 dagfiles
05/03/24 10:46:33 Parsing /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag ...
05/03/24 10:46:33 Adjusting edges
05/03/24 10:46:33 Found rescue DAG number 14; running /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue014 in combination with normal DAG file
05/03/24 10:46:33 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
05/03/24 10:46:33 USING RESCUE DAG /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue014
05/03/24 10:46:33 Dag contains 5 total jobs
05/03/24 10:46:33 Bootstrapping...
05/03/24 10:46:33 Number of pre-completed nodes: 4
05/03/24 10:46:33 MultiLogFiles: truncating log file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/03/24 10:46:33 DAG status: 0 (DAG_STATUS_OK)
05/03/24 10:46:33 Of 5 nodes total:
05/03/24 10:46:33  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/03/24 10:46:33   ===     ===      ===     ===     ===        ===      ===      ===
05/03/24 10:46:33     4       0        0       0       1          0        0        0
05/03/24 10:46:33 0 job proc(s) currently held
05/03/24 10:46:33 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeCount = 0.0; SubmitCycleTimeSum = 0.0; ]
05/03/24 10:46:33 Registering condor_event_timer...
05/03/24 10:46:34 Submitting HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 job(s)...
05/03/24 10:46:34 Adding a DAGMan workflow log /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log
05/03/24 10:46:34 Masking the events recorded in the DAGMAN workflow log
05/03/24 10:46:34 Mask for workflow log is 0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36
05/03/24 10:46:34 submitting: /usr/bin/condor_submit -a dag_node_name=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 -a My.DAGManJobId=140446153 -a DAGManJobId=140446153 -batch-name bbh.dag+140446153 -batch-id 140446153.0 -a submit_event_notes' '=' 'DAG' 'Node:' '/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 -a dagman_log=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.nodes.log -a My.DAGManNodesMask="0,1,2,4,5,7,8,9,10,11,12,13,16,17,24,27,35,36" JOB=/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 DAG_STATUS=0 FAILED_COUNT=0 -a notification=never My.DAGParentNodeNames="/home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0" /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary.sub
05/03/24 10:46:34 From submit: Submitting job(s).
05/03/24 10:46:34 From submit: 1 job(s) submitted to cluster 140446154.
05/03/24 10:46:34 	assigned HTCondor ID (140446154.0.0)
05/03/24 10:46:34 Just submitted 1 job this cycle...
05/03/24 10:46:34 DAG status: 0 (DAG_STATUS_OK)
05/03/24 10:46:34 Of 5 nodes total:
05/03/24 10:46:34  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/03/24 10:46:34   ===     ===      ===     ===     ===        ===      ===      ===
05/03/24 10:46:34     4       0        1       0       0          0        0        0
05/03/24 10:46:34 0 job proc(s) currently held
05/03/24 10:46:34 DAGMan Runtime Statistics: [ EventCycleTimeCount = 0.0; EventCycleTimeSum = 0.0; LogProcessCycleTimeCount = 0.0; LogProcessCycleTimeSum = 0.0; SleepCycleTimeCount = 0.0; SleepCycleTimeSum = 0.0; SubmitCycleTimeAvg = 0.03402996063232422; SubmitCycleTimeCount = 1.0; SubmitCycleTimeMax = 0.03402996063232422; SubmitCycleTimeMin = 0.03402996063232422; SubmitCycleTimeStd = 0.03402996063232422; SubmitCycleTimeSum = 0.03402996063232422; ]
05/03/24 10:46:39 Currently monitoring 1 HTCondor log file(s)
05/03/24 10:46:39 Reassigning the id of job /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 from (140446154.0.0) to (140446154.0.0)
05/03/24 10:46:39 Event: ULOG_SUBMIT for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140446154.0.0) {05/03/24 10:46:34}
05/03/24 10:46:39 Number of idle job procs: 1
05/03/24 10:47:29 Currently monitoring 1 HTCondor log file(s)
05/03/24 10:47:29 Event: ULOG_SHADOW_EXCEPTION for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140446154.0.0) {05/03/24 10:47:24}
05/03/24 10:47:29 Number of idle job procs: 1
05/03/24 10:47:29 Event: ULOG_JOB_HELD for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140446154.0.0) {05/03/24 10:47:24}
05/03/24 10:47:29   Hold reason: Transfer input files failure at access point ldas-pcdev2 while sending files to execution point slot1_9@node917.cluster.ldas.cit. Details: Error from slot1_9@node917.cluster.ldas.cit: SHADOW at 10.14.0.160 failed to send file(s) to <10.14.4.167:38767>: |Error: reading from file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/result/bbh_mass_two_component_primary_mass_ratio_variable_qmin_redshift_powerlaw_result.hdf5: (errno 2) No such file or directory; STARTER failed to receive file(s) from <10.14.0.160:9618>
05/03/24 10:47:29 Number of idle job procs: 1
05/03/24 10:47:29 DAG status: 0 (DAG_STATUS_OK)
05/03/24 10:47:29 Of 5 nodes total:
05/03/24 10:47:29  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/03/24 10:47:29   ===     ===      ===     ===     ===        ===      ===      ===
05/03/24 10:47:29     4       0        1       0       0          0        0        0
05/03/24 10:47:29 1 job proc(s) currently held
05/03/24 10:47:29 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.003169840032404119; EventCycleTimeCount = 11.0; EventCycleTimeMax = 0.03415703773498535; EventCycleTimeMin = 3.314018249511719E-05; EventCycleTimeStd = 0.01027751909957422; EventCycleTimeSum = 0.03486824035644531; LogProcessCycleTimeAvg = 0.0002034902572631836; LogProcessCycleTimeCount = 2.0; LogProcessCycleTimeMax = 0.0002629756927490234; LogProcessCycleTimeMin = 0.0001440048217773438; LogProcessCycleTimeStd = 8.412510962774449E-05; LogProcessCycleTimeSum = 0.0004069805145263672; SleepCycleTimeAvg = 5.004451708360151; SleepCycleTimeCount = 11.0; SleepCycleTimeMax = 5.005132913589478; SleepCycleTimeMin = 5.002945899963379; SleepCycleTimeStd = 0.0008653577240367624; SleepCycleTimeSum = 55.04896879196167; SubmitCycleTimeAvg = 0.002872546513875326; SubmitCycleTimeCount = 12.0; SubmitCycleTimeMax = 0.03402996063232422; SubmitCycleTimeMin = 1.978874206542969E-05; SubmitCycleTimeStd = 0.009812194906903512; SubmitCycleTimeSum = 0.03447055816650391; ]
05/03/24 10:57:29 600 seconds since last log event
05/03/24 10:57:29 Pending DAG nodes:
05/03/24 10:57:29   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140446154, status STATUS_SUBMITTED
05/03/24 11:07:29 1200 seconds since last log event
05/03/24 11:07:29 Pending DAG nodes:
05/03/24 11:07:29   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140446154, status STATUS_SUBMITTED
05/03/24 11:17:30 1801 seconds since last log event
05/03/24 11:17:30 Pending DAG nodes:
05/03/24 11:17:30   Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0, HTCondor ID 140446154, status STATUS_SUBMITTED
05/03/24 11:27:00 Currently monitoring 1 HTCondor log file(s)
05/03/24 11:27:00 Event: ULOG_JOB_ABORTED for HTCondor Node /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0 (140446154.0.0) {05/03/24 11:26:56}
05/03/24 11:27:00 Number of idle job procs: 0
05/03/24 11:27:00 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/03/24 11:27:00 Of 5 nodes total:
05/03/24 11:27:00  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/03/24 11:27:00   ===     ===      ===     ===     ===        ===      ===      ===
05/03/24 11:27:00     4       0        0       0       0          0        1        0
05/03/24 11:27:00 0 job proc(s) currently held
05/03/24 11:27:00 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0002067305378078185; EventCycleTimeCount = 485.0; EventCycleTimeMax = 0.03415703773498535; EventCycleTimeMin = 1.978874206542969E-05; EventCycleTimeStd = 0.001635321244282864; EventCycleTimeSum = 0.100264310836792; LogProcessCycleTimeAvg = 0.000194390614827474; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002629756927490234; LogProcessCycleTimeMin = 0.0001440048217773438; LogProcessCycleTimeStd = 6.15380168051694E-05; LogProcessCycleTimeSum = 0.0005831718444824219; SleepCycleTimeAvg = 5.002818378959734; SleepCycleTimeCount = 485.0; SleepCycleTimeMax = 5.006168127059937; SleepCycleTimeMin = 4.004133939743042; SleepCycleTimeStd = 0.0454491081743135; SleepCycleTimeSum = 2426.366913795471; SubmitCycleTimeAvg = 0.0001155402925279405; SubmitCycleTimeCount = 486.0; SubmitCycleTimeMax = 0.03402996063232422; SubmitCycleTimeMin = 1.120567321777344E-05; SubmitCycleTimeStd = 0.001543018922875239; SubmitCycleTimeSum = 0.0561525821685791; ]
05/03/24 11:27:00 ERROR: the following job(s) failed:
05/03/24 11:27:00 ---------------------- Job ----------------------
05/03/24 11:27:00       Node Name: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary:0
05/03/24 11:27:00            Noop: false
05/03/24 11:27:00          NodeID: 3
05/03/24 11:27:00     Node Status: STATUS_ERROR    
05/03/24 11:27:00 Node return val: -1002
05/03/24 11:27:00           Error: HTCondor reported ULOG_JOB_ABORTED event for job proc (140446154.0.0)
05/03/24 11:27:00 Job Submit File: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/summary.sub
05/03/24 11:27:00  HTCondor Job ID: (140446154.0.0)
05/03/24 11:27:00 PARENTS: /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/analysis:0 WAITING: 0 CHILDREN: 
05/03/24 11:27:00 ---------------------------------------	<END>
05/03/24 11:27:00 Aborting DAG...
05/03/24 11:27:00 Writing Rescue DAG to /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.rescue015...
05/03/24 11:27:00 Removing submitted jobs...
05/03/24 11:27:00 Removing any/all submitted HTCondor jobs...
05/03/24 11:27:00 Running: /usr/bin/condor_rm -const DAGManJobId==140446153 -reason DAG' 'Abort:' 'DAG' 'is' 'exiting' 'and' 'writing' 'rescue' 'file.
05/03/24 11:27:00 Note: 0 total job deferrals because of -MaxJobs limit (12000)
05/03/24 11:27:00 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/03/24 11:27:00 Note: 0 total job deferrals because of node category throttles
05/03/24 11:27:00 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/03/24 11:27:00 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/03/24 11:27:00 Note: 0 total HOLD script deferrals because of -MaxHold limit (20) or DEFER
05/03/24 11:27:00 DAG status: 2 (DAG_STATUS_NODE_FAILED)
05/03/24 11:27:00 Of 5 nodes total:
05/03/24 11:27:00  Done     Pre   Queued    Post   Ready   Un-Ready   Failed   Futile
05/03/24 11:27:00   ===     ===      ===     ===     ===        ===      ===      ===
05/03/24 11:27:00     4       0        0       0       0          0        1        0
05/03/24 11:27:00 0 job proc(s) currently held
05/03/24 11:27:00 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0002067305378078185; EventCycleTimeCount = 485.0; EventCycleTimeMax = 0.03415703773498535; EventCycleTimeMin = 1.978874206542969E-05; EventCycleTimeStd = 0.001635321244282864; EventCycleTimeSum = 0.100264310836792; LogProcessCycleTimeAvg = 0.000194390614827474; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002629756927490234; LogProcessCycleTimeMin = 0.0001440048217773438; LogProcessCycleTimeStd = 6.15380168051694E-05; LogProcessCycleTimeSum = 0.0005831718444824219; SleepCycleTimeAvg = 5.002818378959734; SleepCycleTimeCount = 485.0; SleepCycleTimeMax = 5.006168127059937; SleepCycleTimeMin = 4.004133939743042; SleepCycleTimeStd = 0.0454491081743135; SleepCycleTimeSum = 2426.366913795471; SubmitCycleTimeAvg = 0.0001155402925279405; SubmitCycleTimeCount = 486.0; SubmitCycleTimeMax = 0.03402996063232422; SubmitCycleTimeMin = 1.120567321777344E-05; SubmitCycleTimeStd = 0.001543018922875239; SubmitCycleTimeSum = 0.0561525821685791; ]
05/03/24 11:27:00 Wrote metrics file /home/storm.colloms/O4a_population/test_gwpopulationpipe/O4a_variablem2min/submit/bbh.dag.metrics.
05/03/24 11:27:00 DAGMan Runtime Statistics: [ EventCycleTimeAvg = 0.0002067305378078185; EventCycleTimeCount = 485.0; EventCycleTimeMax = 0.03415703773498535; EventCycleTimeMin = 1.978874206542969E-05; EventCycleTimeStd = 0.001635321244282864; EventCycleTimeSum = 0.100264310836792; LogProcessCycleTimeAvg = 0.000194390614827474; LogProcessCycleTimeCount = 3.0; LogProcessCycleTimeMax = 0.0002629756927490234; LogProcessCycleTimeMin = 0.0001440048217773438; LogProcessCycleTimeStd = 6.15380168051694E-05; LogProcessCycleTimeSum = 0.0005831718444824219; SleepCycleTimeAvg = 5.002818378959734; SleepCycleTimeCount = 485.0; SleepCycleTimeMax = 5.006168127059937; SleepCycleTimeMin = 4.004133939743042; SleepCycleTimeStd = 0.0454491081743135; SleepCycleTimeSum = 2426.366913795471; SubmitCycleTimeAvg = 0.0001155402925279405; SubmitCycleTimeCount = 486.0; SubmitCycleTimeMax = 0.03402996063232422; SubmitCycleTimeMin = 1.120567321777344E-05; SubmitCycleTimeStd = 0.001543018922875239; SubmitCycleTimeSum = 0.0561525821685791; ]
05/03/24 11:27:00 **** condor_scheduniv_exec.140446153.0 (condor_DAGMAN) pid 2987439 EXITING WITH STATUS 1
